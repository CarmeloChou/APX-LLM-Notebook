# BLIP

[Bootstrapping Language-Image Pre-training](./Paper/BLIP Bootstrapping Language-Image Pre-training for Unified Vision-Language Understanding and Generation.pdf)

BLIP 是一个能**同时理解与生成**的多模态预训练模型，通过创新的架构设计和数据清洗策略，在多种视觉语言任务上达到SOTA性能。

## 多模态混合编码器-解码器架构

BLIP 没有像 CLIP 那样只做**编码**，而是统一了**三种功能**于一体：

| 模型模式            | 结构                    | 功能       | 类比         |
| ------------------- | ----------------------- | ---------- | ------------ |
| **单模态编码器**    | 文本编码器              | 文本理解   | 阅读理解专家 |
| **图像-文本编码器** | 图像编码器 + 跨注意力   | 多模态理解 | 图文分析师   |
| **图像-文本解码器** | 图像编码器 + 自回归解码 | 文本生成   | 图片解说员   |

![](.\Image\BLIP2.JPG)

**核心组件 MED**：通过共享参数，一个模型实现三种功能。

## 自举数据清洗

**核心问题**：互联网图文对噪声大、质量低

**BLIP解决方案**：自举过滤三步法

![](./Image/BLIP1.jpg)

```
1. 用BLIP为网络图片生成描述
2. 用BLIP过滤掉噪声图文对
3. 用清洗后的数据重新训练BLIP
```

## 模型架构

```python
class BLIP:
    # 视觉编码器
    vision_encoder= Vision Transformer()
    
    # 文本编码器
    text_encoder = BertEncoder()
    
    # 文本解码器
    text_decoder = BertDecoder()
    
    # 共享的跨模态注意力层
    cross_attention = CrossAttention()
```

## 与CLIP的关键差异

BLIP 同时进行**三个任务**：

1. **图像-文本对比学习**（ITC）
   - 类似CLIP，对齐图像和文本特征
   - 但使用更精细的匹配策略
2. **图像-文本匹配**（ITM）
   - 二分类任务：判断图文是否匹配
   - 使用难负样本挖掘策略
3. **语言建模**（LM）
   - 基于图像的文本生成
   - 训练解码器生成描述

| 维度         | CLIP               | BLIP                    |
| ------------ | ------------------ | ----------------------- |
| **核心能力** | 对比学习，图文对齐 | 理解+生成，双向任务     |
| **架构**     | 双塔编码器         | 编码器-解码器统一体     |
| **训练目标** | 单一的对比损失     | ITC + ITM + LM 多任务   |
| **生成能力** | ❌ 无               | ✅ 有（图像描述、VQA等） |
| **数据使用** | 直接使用噪声数据   | 自举清洗高质量数据      |
| **应用范围** | 检索、分类         | 检索、描述、问答、对话  |