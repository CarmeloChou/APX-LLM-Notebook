# MultModel概览

多模态检索是一种能够处理文本、图像、视频、音频等多种模态数据的检索技术，通过整合不同形式的信息，提供更全面和精准的检索能力。以下是多模态检索涉及的核心技术。

多模态为解决不同模态之间的理解问题，需要形成一套通用的“语言模型”，即将不同数据的向量空间映射到同一向量空间中。![](E:\DATA\LLM\APX-LLM-Notebook\MultiModel\Image\模态融合.png)

- 可通过配对数据进行训练：比如视频与字幕，图片与配文
- 自监督学习法：CLIP
- 基于LLM的统一解码

## 特征处理技术

特征处理是将原始多模态数据转换为计算机可理解的向量表示的过程，包括数据预处理、特征提取和特征表示三个核心环节。

| 处理阶段       | 文本处理                                        | 图像处理                                   | 音频处理                           | 视频处理                       |
| :------------- | :---------------------------------------------- | :----------------------------------------- | :--------------------------------- | :----------------------------- |
| **数据预处理** | 分词、去停用词、词嵌入（Word2Vec, GloVe, BERT） | 缩放、裁剪、颜色标准化                     | 声音分段、特征提取（MFCC, 频谱图） | 帧提取、时间序列对齐           |
| **特征提取**   | 深度模型（BERT, GPT）提取上下文语义             | CNN 提取视觉特征，Vision Transformer (ViT) | 声学模型（CNN, RNN）提取时频特征   | 3D CNN, LSTM 提取时空特征      |
| **特征表示**   | 语义向量，支持长文本编码                        | 视觉特征向量，支持多分辨率输入             | 音频特征向量，支持频谱与时序分析   | 时空特征向量，支持动态内容建模 |

## 模态融合技术

| 融合方式              | 技术原理                                               | 核心机制                               | 适用场景                                   | 优势                                                 |
| :-------------------- | :----------------------------------------------------- | :------------------------------------- | :----------------------------------------- | :--------------------------------------------------- |
| **早期融合**          | 在输入层或特征提取阶段直接融合多模态原始数据或浅层特征 | 特征拼接、加权平均、特征级联           | 模态间高度相关、任务相对简单的场景         | 实现简单、计算效率高、可捕捉底层关联                 |
| **晚期融合**          | 分别独立处理各模态，在决策或输出层进行结果融合         | 投票机制、概率融合、分数加权           | 模态独立性较强、需分别进行复杂推理的任务   | 灵活性高、模态处理可独立优化、容错性好               |
| **联合嵌入**          | 将不同模态数据映射到一个共同的语义向量空间             | 对比学习、三元组损失、跨模态对齐损失   | 跨模态检索、图文匹配、零样本学习           | 语义对齐效果好、支持跨模态直接相似度计算、泛化能力强 |
| **注意力机制**        | 动态计算不同模态或模态内不同部分的重要性权重           | 自注意力、跨模态注意力、多头注意力     | 复杂多模态交互、长序列理解、细粒度关联任务 | 可解释性强、能动态聚焦关键信息、处理长程依赖         |
| **多模态Transformer** | 使用 Transformer 架构统一建模多模态输入序列的交互      | 跨模态编码器、共享自注意力层、位置编码 | 需要深度理解跨模态上下文关系的复杂任务     | 强大的上下文建模能力、支持端到端训练、性能优越       |

## 主流多模态表征模型

| 模型名称           | 发布机构     | 核心特点                                                     | 技术架构                                    | 主要能力                                       |
| :----------------- | :----------- | :----------------------------------------------------------- | :------------------------------------------ | :--------------------------------------------- |
| **CLIP**           | OpenAI       | 通过对比学习实现大规模图文对齐，支持强大的零样本迁移能力     | 双塔编码器（图像ViT/CNN + 文本Transformer） | 图文检索、零样本图像分类、跨模态理解           |
| **BLIP**           | Salesforce   | 统一理解和生成任务，通过自举方式生成噪声数据并进行过滤，提升模型能力 | 多模态混合编码器-解码器 (MED)               | 图文检索、视觉问答 (VQA)、图像描述生成         |
| **BLIP-2**         | Salesforce   | 引入轻量级Q-Former连接视觉与语言模型，高效利用大规模预训练模型 | ViT + Q-Former + 冻结大语言模型 (LLM)       | 高效视觉语言理解与生成、指令跟随、低资源适配   |
| **InstructBLIP**   | Salesforce   | 基于BLIP-2，引入指令感知的视觉特征提取，提升模型对自然语言指令的理解与响应能力 | Q-Former + 指令感知视觉编码 + LLM           | 指令驱动的多模态任务、零样本任务泛化、复杂推理 |
| **Qwen2-VL**       | 阿里巴巴     | 专注于多语言和长视频理解，支持超长上下文（128K）的视觉语言任务 | ViT + 跨注意力机制 + Qwen LLM               | 中英文图文/视频理解、复杂文档解析、长序列建模  |
| **GME**            | 阿里巴巴     | 通用多模态嵌入模型，针对复杂文档理解与多模态检索优化，支持动态分辨率输入 | 基于Qwen2-VL优化的统一模态编码架构          | 视觉文档检索、图文组合检索、高精度跨模态匹配   |
| **VISTA**          | BAAI         | 轻量级模型，专门优化"文本+图像"组合查询的混合模态检索场景    | 轻量化双流/单流编码架构                     | 混合模态检索、快速响应、计算效率高             |
| **LLaVA**          | Microsoft    | 通过简单的投影层连接视觉编码器与大语言模型，实现高效的视觉对话能力 | ViT + 线性投影层 + LLaMA/Vicuna等LLM        | 视觉对话、视觉问答、多模态指令跟随             |
| **MiniGPT-4**      | 香港中文大学 | 轻量化设计，通过单线性投影层连接视觉与语言模型，降低训练与部署成本 | ViT + 单线性层 + Vicuna LLM                 | 图像理解、创意写作、简易多模态对话             |
| **Gemini 2.5 Pro** | Google       | 超长上下文原生多模态模型，采用专家混合 (MoE) 架构，支持复杂推理与长视频理解 | 原生多模态Transformer + MoE                 | 多模态生成、长视频/长文档理解、复杂多步推理    |

## 应用场景分类

| 应用领域     | 典型场景                                                | 技术需求                                       | 核心模型                        | 价值体现                                             |
| :----------- | :------------------------------------------------------ | :--------------------------------------------- | :------------------------------ | :--------------------------------------------------- |
| **电商搜索** | 以图搜商品、文本搜商品、图文组合检索                    | 跨模态语义对齐、细粒度属性匹配、个性化推荐     | CLIP, GME, BLIP                 | 提升转化率与客单价，优化搜索准确率与用户体验         |
| **医疗诊断** | 医学影像与报告联合分析、辅助诊断、病理研究              | 高精度细粒度识别、跨模态可解释性、领域知识融合 | BLIP-2, Qwen2-VL, 领域定制模型  | 提高诊断准确率与效率，助力早期筛查与医学研究         |
| **教育学习** | 图文教材理解、交互式智能问答、个性化学习路径            | 多模态知识推理、内容生成、自适应交互           | LLaVA, InstructBLIP, 教育大模型 | 实现个性化教学，提升学习 engagement 与效果           |
| **智能客服** | 多轮图文对话、产品问题排查、远程视频指导                | 多模态对话状态跟踪、意图识别、上下文理解       | InstructBLIP, Qwen2-VL          | 提升客服自动化水平与问题解决率，降低人力成本         |
| **内容管理** | 多媒体内容库检索、自动化标签与摘要、违规内容审核        | 大规模跨模态检索、多标签分类、敏感信息识别     | BLIP, VISTA, CLIP               | 实现内容高效组织与管理，保障平台安全与合规           |
| **金融分析** | 财报/票据图像解析、新闻与市场数据关联分析、风险报告生成 | 文档结构理解、表格识别、多源信息关联           | GME, LayoutLM, 金融风控模型     | 提升数据分析自动化程度与风险识别时效性               |
| **社交媒体** | 热点内容发现、多模态情感分析、个性化内容推荐            | 趋势挖掘、用户兴趣建模、内容深度理解           | BLIP, CLIP, 推荐系统            | 增强用户粘性，优化内容分发效率与商业变现             |
| **创意设计** | 文生图创意启发、设计素材检索、多模态方案生成            | 创意概念理解、风格迁移、跨模态生成             | MiniGPT-4, 文生图模型, AIGC工具 | 加速创意进程，丰富设计表达，降低创作门槛             |
| **工业质检** | 缺陷图像自动检测与分类、质检报告生成、过程监控          | 高精度视觉检测、缺陷模式识别、异常关联分析     | 专用视觉模型, Qwen2-VL          | 提升质检效率与一致性，实现产品质量追溯与优化         |
| **视频理解** | 长视频内容摘要、片段检索、行为与事件分析                | 时空特征建模、长序列理解、高效检索             | Qwen2-VL, 视频理解专用模型      | 解锁海量视频数据价值，赋能内容创作、安防、体育分析等 |

```cpp
class Vector{
    public:
    int* arr;
    int capacity;
    int num;
    
    public:
    Vector(int capacity = 10): capacity(capacity), num(0){
        arr = new int[capacity];
    }
    
    Vector(int* arr, int size): arr(arr), capacity(size), num(size){}
    Vector(const Vector& other) {

        capacity = other.capathty;
        num = other.num;
        // 深拷贝：分配新内存，复制数据
    arr = new int[capacity];  // ✅
    
    // 复制元素
    for (int i = 0; i < num; ++i) {
        arr[i] = other.arr[i];
    }
    Vector(Vector&& other){
        arr = other.arr;
        other.arr = nullptr;
        capacity = other.capacity;
        other.capacity = 0;
        num = other.num;
        other.num = 0
    }
    ~Vector(){
        delete[] arr;
    }
}
```

