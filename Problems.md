# PreTrain

# PostTrain

## Fine-Tunning

### Lora

1. LoRA中为什么要对A、B其中一个矩阵初始化为0？
2. LoRA中r和α的超参数有什么作用？



# Agent

## Agent函数调用如何又快又准/如何保证Function Call准确率，工具多了会不会乱调？参数会不会填错？

- 思路：如何量化正确率、工具调用为什么出错、怎么系统化优化、用项目回答
- 工具一多，模型就会出错，如果不做限制，选错一个函数、填错一个参数，整个链路可能直接挂掉。Schema设计不清晰，函数名模糊、参数名相似，含糊不清
- prompt上下文有歧义。工具链太长、系统说明不够准确、User输入含糊：“查一下明天的天气”，“查一下明天杭州的天气”
- 模型采样策略太高。设置温度0.8，让其自由发挥，结果可能是函数名拼错、JSON拼坏、参数缺失
- 没有防御机制。即使调用错误、JSON格式不对、工具返回异常，系统也没有：Schema校验、retry、reflection、fallback

Function Call的准确率问题，根源在于**系统设计，而非模型能力**。核心矛盾是要求大模型在充满**不确定性**的上下文（如工具繁多、描述模糊）中做出**确定性**的决策。因此，提升准确率的关键是建立一套**工程化体系**来消除不确定性。

### 问题根源（四大核心因素）

1. **Schema设计不严谨**：函数名、参数名存在歧义是最大元凶（例如同时存在 `searchFlight`和 `flightSearch`），导致模型“脑补”。
2. **Prompt约束不足**：系统提示词未明确规则（如“必须追问缺失参数”），上下文工具过多，导致模型决策混乱。
3. **采样策略过于随机**：将聊天场景的高温度设置（如 `temperature=0.7`）用于需要精确执行的Function Call，会诱发模型幻觉。
4. **缺乏运行时防御机制**：没有参数校验、错误重试（Retry/Reflection）等安全网，导致一次错误就造成整个流程失败。

### 系统性解决措施

| 优化维度         | 核心目标         | 关键措施                                                     |
| ---------------- | ---------------- | ------------------------------------------------------------ |
| **🛣️ 动态路由**   | **减少干扰**     | 先通过意图识别过滤无关工具，大幅降低模型选错工具的概率。     |
| **📋 严谨设计**   | **消除歧义**     | Schema描述明确写入行为约束（如“用户未提供时必须追问”）；Prompt中强制要求模型“不得猜测”。 |
| **⚙️ 校验与重试** | **构建安全网**   | 在调用前后校验参数完整性、格式及API返回状态，失败时自动重试或让模型反思修正（Reflection）。 |
| **🧠 规划与记忆** | **保障多轮稳定** | 复杂任务强制模型先规划（Plan-and-Execute），再逐步执行；通过记忆机制记录关键信息，避免参数混淆 |

1. 
