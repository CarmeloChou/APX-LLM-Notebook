# PreTrain

# PostTrain

## Fine-Tunning

### Lora

1. LoRA中为什么要对A、B其中一个矩阵初始化为0？
2. LoRA中r和α的超参数有什么作用？



