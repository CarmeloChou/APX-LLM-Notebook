# k8s集群

Kubernetes (k8s) 集群就像一个**高度自动化的公司团队**。这个“团队”能够帮你管理和运行大量的容器化应用，并且具备**自愈、弹性伸缩和高效调度**的能力。下面这个表格能帮你快速抓住核心概念。

| 核心概念                   | 作用                                                         | 一个不太严谨的比方                                           |
| -------------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| **集群 (Cluster)**         | 将多台机器（节点）的资源汇聚成一个强大的**统一计算资源池**。 | 将公司里所有的电脑整合成一台性能极强的“超级电脑”。           |
| **控制节点 (Master Node)** | 集群的**大脑**，负责指挥和决策，例如决定把任务分配给谁，确保应用按预期运行。 | 公司的**管理层和调度中心**，不具体干活，但负责派活和监控进度。 |
| **工作节点 (Worker Node)** | 集群的**双手**，是实际执行计算任务、运行你业务应用的机器。   | 公司的**执行员工**，接收指令并完成任务。                     |
| **Pod**                    | Kubernetes 可以进行管理和调度的**最小单元**，一个 Pod 内可以运行一个或多个紧密关联的容器。 | 分配给员工的一个**具体项目任务包**，里面包含了完成这个任务所需的所有工具和说明。 |

## 💁 什么是集群节点

节点是构成 Kubernetes 集群的个体机器（可以是物理服务器或虚拟机）。它们根据职责不同分为两种角色：

- **控制节点 (Master Node)**：它是集群的“大脑”和“神经中枢”，负责接收用户指令、做出决策（比如把应用调度到哪个节点运行）、维护集群的期望状态。为了保证高可用，生产环境通常会有多个 Master 节点 。
- **工作节点 (Worker Node)**：它们是真正“干活”的节点，负责运行你的应用程序容器。每个工作节点上都会运行几个关键组件 ：
  - **kubelet**：负责与管理节点通信，并按照指令启动、停止和管理 Pod。
  - **kube-proxy**：负责处理节点上的网络规则，实现服务发现和负载均衡。
  - **容器运行时**：如 Docker 或 containerd，负责拉取镜像、启动和停止容器等底层操作。

## 🔄 任务如何分配到不同节点

任务的分配过程由控制节点上的 **kube-scheduler** 组件智能完成，主要包括以下几步 ：

1. **资源过滤**：当你提交一个需要运行的应用（例如，一个包含 3 个副本的 Deployment）时，kube-scheduler 会首先检查所有工作节点，过滤掉那些不满足条件的节点（例如资源不足、节点有污点等）。
2. **节点打分**：然后，调度器会为剩余的可用的节点打分。评分基于一系列策略，比如优先选择资源空闲的节点、避免将多个副本集中到同一个节点等。
3. **绑定节点**：调度器会选出分数最高的节点，并将这个决定（“将这个 Pod 运行在 A 节点上”）通知给 API Server。随后，该节点上的 kubelet 就会接收到指令，开始拉取镜像并运行 Pod。

## ⚙️ 线性工作流在集群中的运行

对于**线性工作流**（即任务中的步骤必须一个接一个地顺序执行，前一个步骤的输出是后一个步骤的输入），将其拆分到不同节点上运行，**主要目的通常不是为了加速单个任务的执行，而是为了提高系统的整体吞吐量和资源利用率**。

想象一下，你有一个视频转码服务，每个视频都需要经过“解码 -> 处理 -> 编码”这三个线性步骤。虽然单个视频的转码时间并不能通过拆分步骤到不同节点而缩短，但你可以这样做：

- 设置三个不同的部署（Deployment），分别专门负责解码、处理和编码。
- 在这些部署前使用 **Kubernetes Service** 为它们提供一个稳定的访问入口 。
- 当一个视频转码请求到来时，它会被依次发送给解码、处理、编码服务。虽然单个视频的流转时间不变，但由于每个步骤都有专门的一组 Pod（可能分布在不同节点上）来处理，你的系统现在可以**同时处理成千上万个视频转码请求**，而不会在某个步骤上形成瓶颈。这就是**通过并行化处理多个任务来实现效率提升**。

对于一些可以被分解成多个独立子任务的复杂计算，可以使用像 **Job** 或 **CronJob** 这样的 Kubernetes 工作负载对象来管理 。每个子任务作为一个独立的 Pod 运行，所有 Pod 执行成功后，整个任务才算完成。这种方式依然利用了集群的分布式特性。

## 💎 简单来说

Kubernetes 集群的核心价值在于，它让你像使用一台机器一样使用一个机器集群。对于线性工作流，Kubernetes 的优势不在于缩短单个任务的执行时间，而在于通过**将工作流的各个阶段微服务化、水平扩展每个阶段的处理能力**，从而极大地提升系统处理海量线性任务的**整体吞吐量和可靠性**。
