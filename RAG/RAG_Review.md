# RAG概览

**RAG** 是 **检索增强生成** 的简称，其核心思想是：**在生成答案之前，先从外部知识库中检索相关信息，并将这些信息作为上下文提供给大模型，从而生成更准确、更可信、更及时的回答。**

- **检索**：从海量文档、数据库或网络中查找与问题最相关的信息片段。
- **增强**：将检索到的信息与用户问题一起，作为“增强”的提示词输入给大模型。
- **生成**：大模型基于检索到的“证据”和自身知识，生成最终答案。

**核心价值**：它解决了大模型的两大核心痛点——**“幻觉”** 和 **“知识过时/封闭”**。

## **RAG 系统三大核心组件**

| 组件          | 作用                                                         | 常用技术/工具                                                |
| :------------ | :----------------------------------------------------------- | :----------------------------------------------------------- |
| **1. 检索器** | 负责从知识库中“大海捞针”，找到最相关的信息片段。             | 向量检索（核心）、关键词检索（如BM25）、混合检索。常用向量数据库：Chroma, Pinecone, Weaviate, Qdrant, Milvus。 |
| **2. 生成器** | 核心的“大脑”，负责阅读理解检索到的信息，并组织语言生成最终答案。 | 各类大语言模型，如 GPT-4, Claude, Llama, 文心一言，通义千问等。 |
| **3. 知识库** | 存储和索引所有外部知识的“仓库”，是检索的来源。               | 向量数据库（存储非结构化文本的核心）、传统数据库（存储结构化元数据）、图数据库（存储关系）。 |

## **技术演进与高级 RAG**

为解决基础 RAG 的挑战，业界发展出了 **“高级 RAG”** 技术：

1. **检索优化**：
   - **查询重写/扩展**：自动优化用户问题，使其更易于检索。
   - **混合检索**：结合向量检索（语义）和关键词检索（字面），取长补短。
   - **重排序**：对初步检索结果进行二次精排，选出最相关的几个。
2. **索引优化**：
   - **智能分块**：根据文档结构（标题、段落）或语义进行更合理的分割。
   - **多向量索引**：为同一文本块创建多个角度的摘要或问题索引。
3. **生成优化**：
   - **提示工程**：设计更好的提示词模板，指导模型更好地利用上下文。
   - **思维链**：要求模型“逐步推理”，提升复杂问题的回答质量。

## 主要RAG方法分类与总结

### 按检索与生成流程分类（基础范式）

| 方法名称         | 核心流程                                                     | 优点                                                   | 缺点/挑战                                                    |
| :--------------- | :----------------------------------------------------------- | :----------------------------------------------------- | :----------------------------------------------------------- |
| **Naive RAG**    | **索引** -> **检索** -> **生成**。最经典的范式，一次性检索固定数量的文档片段，直接输入模型生成。 | 实现简单， pipeline 清晰，是大多数应用的基础。         | 检索质量直接决定生成上限；“垃圾进，垃圾出”；上下文长度有限，可能丢失全局信息。 |
| **Advanced RAG** | 在Naive流程前后增加**优化步骤**，如查询重写、句子窗口、自动提示工程、检索后重排等。 | 显著提升检索精度和上下文相关性，是目前主流生产级方案。 | 增加系统复杂度和延迟。                                       |
| **Modular RAG**  | 将RAG流程模块化、可编排。引入更多技术，如**查询路由**、**多步检索**、**多路径检索**、**递归检索**、**智能体调度**等。 | 极度灵活，能处理复杂任务，性能潜力大。                 | 设计复杂，对架构和工程实现要求高。                           |

###  按检索的“粒度”与策略分类

| 方法名称              | 核心思想                                                     | 适用场景                                   |
| :-------------------- | :----------------------------------------------------------- | :----------------------------------------- |
| **块检索/片段检索**   | 将文档切分为固定大小的块（如512 tokens），检索最相关的块。   | 通用场景，简单文档问答。                   |
| **句子窗口检索**      | 检索核心句子，并将其前后若干句子作为上下文一起喂给模型。     | 需要保持局部语境连贯性的场景。             |
| **细粒度检索**        | 检索对象是实体、关系或更小的语义单元。                       | 知识图谱增强，需要精准事实回答。           |
| **摘要索引检索**      | 为长文档生成摘要，先检索相关摘要，再定位到原文。             | 处理超长文档（如书籍、长报告），降低噪声。 |
| **分层检索/递归检索** | 先检索粗粒度摘要或标题，再对选中的文档进行细粒度检索。       | 处理大量、多层级文档集合。                 |
| **混合检索**          | ==结合**稠密向量检索**（语义相似）和**稀疏向量检索**（关键词匹配，如BM25）。== | 兼顾语义匹配和精确词匹配，提高召回率。     |
| **多跳检索**          | 针对复杂问题，进行多轮交替检索与推理，逐步收集信息。         | 复杂问答，需要连接多个信息点。             |

###  按索引与生成优化技术分类

| 方法名称                | 核心思想                                                     | 目标                                      |
| :---------------------- | :----------------------------------------------------------- | :---------------------------------------- |
| **查询重写/扩展**       | 利用LLM将用户查询重写、扩展或生成假设性答案，以优化检索查询。 | 提升查询意图与文档语义的匹配度。          |
| **检索后重排**          | 使用更强大的交叉编码器模型或LLM，对初步检索结果进行相关性重排序。 | 提升top结果的精准度，筛选出最相关的片段。 |
| **HyDE**                | 让LLM根据查询生成一个假设性答案/文档，然后用这个生成的文本来检索真实相关文档。 | 在向量空间对齐查询和文档，解决表述鸿沟。  |
| **RAG-Fusion**          | 生成多个相关查询，并行检索，合并去重结果后再生成。           | 拓宽检索视野，获得更全面的信息。          |
| **Step-Back Prompting** | 让LLM先从问题中抽象出更一般的概念或原则，先检索这个“背景知识”，再具体回答。 | 提升复杂问题的推理和泛化能力。            |

## 主流RAG方法对比罗列表

| 维度/方法    | Naive RAG                | Advanced RAG (HyDE+重排+混合)    | Modular RAG (智能体化)      |
| :----------- | :----------------------- | :------------------------------- | :-------------------------- |
| **核心特点** | 端到端，检索即用         | 检索前后优化，提升质量           | 模块化编排，动态流程        |
| **复杂度**   | 低                       | 中                               | 高                          |
| **检索质量** | 一般，依赖分块和嵌入模型 | 高，综合多种优化                 | 极高，可自适应任务          |
| **生成质量** | 受限于检索结果           | 稳定可靠                         | 潜力最大，可能最准          |
| **可解释性** | 中等（有来源）           | 高（有优化步骤可分析）           | 高但复杂（有决策路径）      |
| **适用场景** | 概念验证、简单问答       | 企业级知识库、生产系统           | 复杂分析、研究、开放式探索  |
| **典型技术** | FAISS + LangChain简单链  | 查询扩展、Cohere重排器、混合搜索 | 智能体路由、ReAct、多步推理 |

## 其他重要的相关RAG技术与趋势

1. **Self-RAG / 反思式RAG**：
   - 让LLM在生成过程中自我评估，判断是否需要检索、检索到的文档是否相关、生成的内容是否得到支持。可动态控制检索行为，生成更精准、诚实的答案。
2. **RAG与智能体结合**：
   - RAG作为智能体的“记忆”或“知识工具”。智能体可以主动规划、调用RAG，进行多轮交互和复杂任务分解（如AutoGen, ChatDev）。
3. **生成增强检索**：
   - 不仅仅是“检索->生成”，也可以是“生成->检索”。例如，先生成大纲或关键点，再针对性地检索填充。
4. **RAG的评估体系**：
   - **上下文相关性**、**答案忠实度**、**答案相关性**成为核心评估指标。工具如RAGAS、TruLens、ARES帮助自动化评估。
5. ==**超越文本：多模态RAG**==：
   - 检索对象从文本扩展到图片、表格、音频、视频。使用多模态嵌入模型（**如CLIP**）进行统一检索，生成多模态答案。
6. **长期记忆与持续学习**：
   - RAG系统与对话历史结合，构建用户个性化的长期记忆，实现持续、连贯的个性化交互。
7. **端到端优化**：
   - 研究如何联合优化检索器（Retriever）和生成器（Generator）的模型参数，而不仅仅是拼接，如**RAG-end2end** 和 **REPLUG** 等研究方向。