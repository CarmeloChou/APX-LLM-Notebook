# Google 5 Days AI Agents Intensive Course

https://www.kaggle.com/code/kaggle5daysofai/day-2a-agent-tools

## Day1 ä»‹ç»ADKåŸºæœ¬è°ƒç”¨

ä¸»è¦ä»‹ç»apiè°ƒç”¨æ–¹æ³•ï¼Œå°è¯•ä½¿ç”¨google searchçš„toolæ¥è§£å†³å¤§æ¨¡åž‹çš„å®žæ—¶æ€§é—®é¢˜ã€‚

## Day1b agentæž¶æž„

å¤šagent ç³»ç»Ÿ

```python
# Research Agent: Its job is to use the google_search tool and present findings.
research_agent = Agent(
    name="ResearchAgent",
    model=Gemini(
        model="gemini-2.5-flash-lite",
        retry_options=retry_config
    ),
    instruction="""You are a specialized research agent. Your only job is to use the
    google_search tool to find 2-3 pieces of relevant information on the given topic and present the findings with citations.""",
    tools=[google_search],
    output_key="research_findings",  # The result of this agent will be stored in the session state with this key.
)

print("âœ… research_agent created.")
```

```python
# Summarizer Agent: Its job is to summarize the text it receives.
summarizer_agent = Agent(
    name="SummarizerAgent",
    model=Gemini(
        model="gemini-2.5-flash-lite",
        retry_options=retry_config
    ),
    # The instruction is modified to request a bulleted list for a clear output format.
    instruction="""Read the provided research findings: {research_findings}
Create a concise summary as a bulleted list with 3-5 key points.""",
    output_key="final_summary",
)

print("âœ… summarizer_agent created.")
```

æ ¹agent

```pyhton
# Root Coordinator: Orchestrates the workflow by calling the sub-agents as tools.
root_agent = Agent(
    name="ResearchCoordinator",
    model=Gemini(
        model="gemini-2.5-flash-lite",
        retry_options=retry_config
    ),
    # This instruction tells the root agent HOW to use its tools (which are the other agents).
    instruction="""You are a research coordinator. Your goal is to answer the user's query by orchestrating a workflow.
1. First, you MUST call the `ResearchAgent` tool to find relevant information on the topic provided by the user.
2. Next, after receiving the research findings, you MUST call the `SummarizerAgent` tool to create a concise summary.
3. Finally, present the final summary clearly to the user as your response.""",
    # We wrap the sub-agents in `AgentTool` to make them callable tools for the root agent.
    tools=[AgentTool(research_agent), AgentTool(summarizer_agent)],
)

print("âœ… root_agent created.")
```

### ä¸²è¡Œå·¥ä½œæµ

![](./Image/sequential-agent.png)

```py
# Outline Agent: Creates the initial blog post outline.
outline_agent = Agent(
    name="OutlineAgent",
    model=Gemini(
        model="gemini-2.5-flash-lite",
        retry_options=retry_config
    ),
    instruction="""Create a blog outline for the given topic with:
    1. A catchy headline
    2. An introduction hook
    3. 3-5 main sections with 2-3 bullet points for each
    4. A concluding thought""",
    output_key="blog_outline",  # The result of this agent will be stored in the session state with this key.
)

print("âœ… outline_agent created.")
```

```py
# Writer Agent: Writes the full blog post based on the outline from the previous agent.
writer_agent = Agent(
    name="WriterAgent",
    model=Gemini(
        model="gemini-2.5-flash-lite",
        retry_options=retry_config
    ),
    # The `{blog_outline}` placeholder automatically injects the state value from the previous agent's output.
    instruction="""Following this outline strictly: {blog_outline}
    Write a brief, 200 to 300-word blog post with an engaging and informative tone.""",
    output_key="blog_draft",  # The result of this agent will be stored with this key.
)

print("âœ… writer_agent created.")
```

```py
# Editor Agent: Edits and polishes the draft from the writer agent.
editor_agent = Agent(
    name="EditorAgent",
    model=Gemini(
        model="gemini-2.5-flash-lite",
        retry_options=retry_config
    ),
    # This agent receives the `{blog_draft}` from the writer agent's output.
    instruction="""Edit this draft: {blog_draft}
    Your task is to polish the text by fixing any grammatical errors, improving the flow and sentence structure, and enhancing overall clarity.""",
    output_key="final_blog",  # This is the final output of the entire pipeline.
)

print("âœ… editor_agent created.")
```

```py
root_agent = SequentialAgent(
    name="BlogPipeline",
    sub_agents=[outline_agent, writer_agent, editor_agent],
)

print("âœ… Sequential Agent created.")
```

```py
runner = InMemoryRunner(agent=root_agent)
response = await runner.run_debug(
    "Write a blog post about the benefits of multi-agent systems for software developers"
)
```



### å¹¶è¡Œå·¥ä½œæµ

![](./Image/parallel-agent.png)

```python
# Tech Researcher: Focuses on AI and ML trends.
tech_researcher = Agent(
    name="TechResearcher",
    model=Gemini(
        model="gemini-2.5-flash-lite",
        retry_options=retry_config
    ),
    instruction="""Research the latest AI/ML trends. Include 3 key developments,
the main companies involved, and the potential impact. Keep the report very concise (100 words).""",
    tools=[google_search],
    output_key="tech_research",  # The result of this agent will be stored in the session state with this key.
)

print("âœ… tech_researcher created.")
```

```py
# Health Researcher: Focuses on medical breakthroughs.
health_researcher = Agent(
    name="HealthResearcher",
    model=Gemini(
        model="gemini-2.5-flash-lite",
        retry_options=retry_config
    ),
    instruction="""Research recent medical breakthroughs. Include 3 significant advances,
their practical applications, and estimated timelines. Keep the report concise (100 words).""",
    tools=[google_search],
    output_key="health_research",  # The result will be stored with this key.
)

print("âœ… health_researcher created.")
```

```python
# Finance Researcher: Focuses on fintech trends.
finance_researcher = Agent(
    name="FinanceResearcher",
    model=Gemini(
        model="gemini-2.5-flash-lite",
        retry_options=retry_config
    ),
    instruction="""Research current fintech trends. Include 3 key trends,
their market implications, and the future outlook. Keep the report concise (100 words).""",
    tools=[google_search],
    output_key="finance_research",  # The result will be stored with this key.
)

print("âœ… finance_researcher created.")
```

```python
# The AggregatorAgent runs *after* the parallel step to synthesize the results.
aggregator_agent = Agent(
    name="AggregatorAgent",
    model=Gemini(
        model="gemini-2.5-flash-lite",
        retry_options=retry_config
    ),
    # It uses placeholders to inject the outputs from the parallel agents, which are now in the session state.
    instruction="""Combine these three research findings into a single executive summary:

    **Technology Trends:**
    {tech_research}
    
    **Health Breakthroughs:**
    {health_research}
    
    **Finance Innovations:**
    {finance_research}
    
    Your summary should highlight common themes, surprising connections, and the most important key takeaways from all three reports. The final summary should be around 200 words.""",
    output_key="executive_summary",  # This will be the final output of the entire system.
)

print("âœ… aggregator_agent created.")
```

### å¾ªçŽ¯å·¥ä½œæµ

![](./Image/loop-agent.png)

1. **Writer Agent** - Writes a draft of a short story
2. **Critic Agent** - Reviews and critiques the short story to suggest improvements

```py
# This agent runs ONCE at the beginning to create the first draft.
initial_writer_agent = Agent(
    name="InitialWriterAgent",
    model=Gemini(
        model="gemini-2.5-flash-lite",
        retry_options=retry_config
    ),
    instruction="""Based on the user's prompt, write the first draft of a short story (around 100-150 words).
    Output only the story text, with no introduction or explanation.""",
    output_key="current_story",  # Stores the first draft in the state.
)

print("âœ… initial_writer_agent created.")
```

```py
# This agent's only job is to provide feedback or the approval signal. It has no tools.
critic_agent = Agent(
    name="CriticAgent",
    model=Gemini(
        model="gemini-2.5-flash-lite",
        retry_options=retry_config
    ),
    instruction="""You are a constructive story critic. Review the story provided below.
    Story: {current_story}
    
    Evaluate the story's plot, characters, and pacing.
    - If the story is well-written and complete, you MUST respond with the exact phrase: "APPROVED"
    - Otherwise, provide 2-3 specific, actionable suggestions for improvement.""",
    output_key="critique",  # Stores the feedback in the state.
)

print("âœ… critic_agent created.")
```

```py
# This is the function that the RefinerAgent will call to exit the loop.
def exit_loop():
    """Call this function ONLY when the critique is 'APPROVED', indicating the story is finished and no more changes are needed."""
    return {"status": "approved", "message": "Story approved. Exiting refinement loop."}


print("âœ… exit_loop function created.")
```

```py
# This agent refines the story based on critique OR calls the exit_loop function.
refiner_agent = Agent(
    name="RefinerAgent",
    model=Gemini(
        model="gemini-2.5-flash-lite",
        retry_options=retry_config
    ),
    instruction="""You are a story refiner. You have a story draft and critique.
    
    Story Draft: {current_story}
    Critique: {critique}
    
    Your task is to analyze the critique.
    - IF the critique is EXACTLY "APPROVED", you MUST call the `exit_loop` function and nothing else.
    - OTHERWISE, rewrite the story draft to fully incorporate the feedback from the critique.""",
    output_key="current_story",  # It overwrites the story with the new, refined version.
    tools=[
        FunctionTool(exit_loop)
    ],  # The tool is now correctly initialized with the function reference.
)

print("âœ… refiner_agent created.")
```

```py
# The LoopAgent contains the agents that will run repeatedly: Critic -> Refiner.
story_refinement_loop = LoopAgent(
    name="StoryRefinementLoop",
    sub_agents=[critic_agent, refiner_agent],
    max_iterations=2,  # Prevents infinite loops
)

# The root agent is a SequentialAgent that defines the overall workflow: Initial Write -> Refinement Loop.
root_agent = SequentialAgent(
    name="StoryPipeline",
    sub_agents=[initial_writer_agent, story_refinement_loop],
)

print("âœ… Loop and Sequential Agents created.")
```

```py
runner = InMemoryRunner(agent=root_agent)
response = await runner.run_debug(
    "Write a short story about a lighthouse keeper who discovers a mysterious, glowing map"
)
```



## Day2 ä»‹ç»agent tools

Toolå®šä¹‰ï¼š

- python å‡½æ•°

  - å­—å…¸è¿”å›žå€¼ï¼š{â€œstatusâ€: â€œsuccessâ€, â€œdataâ€: ...} or {â€œstatusâ€: â€œerrorâ€, â€œerror_messageâ€:...}
  - æ¸…æ™°çš„æŒ‡ä»¤ï¼šllmä½¿ç”¨æ¸…æ™°çš„æŒ‡ä»¤åŽ»ç†è§£åº”è¯¥è°ƒç”¨ä»€ä¹ˆtools
  - æš—ç¤ºæŒ‡ä»¤ï¼šè®©adkç”Ÿæˆåˆé€‚çš„ç›®æ ‡æ ¼å¼ï¼ˆstrã€dictã€etcï¼‰
  - é”™è¯¯å¤„ç†ï¼šç»“æž„åŒ–é”™è¯¯å“åº”å¸®åŠ©LLMåˆé€‚å¤„ç†é”™è¯¯

  ```python
  def get_fee_for_payment_method(method: str) -> dict:
      fee_database = {
          "platinum credit card": 0.02,  # 2%
          "gold debit card": 0.035,  # 3.5%
          "bank transfer": 0.01,  # 1%
      }
      
      fee = fee_database.get(method.lower())
      if fee is not None:
          return {"status": "success", "fee_percentage": fee}
      else:`
          return {
              "status": "error",
              "error_message": f"Payment method '{method}' not found",
          }
          
  print("âœ… Fee lookup function created")
  print(f"ðŸ’³ Test: {get_fee_for_payment_method('platinum credit card')}")
  
  ```

  ```python
  def get_exchange_rate(base_currency: str, target_currency: str) -> dict:
      """Looks up and returns the exchange rate between two currencies.
  
      Args:
          base_currency: The ISO 4217 currency code of the currency you
                         are converting from (e.g., "USD").
          target_currency: The ISO 4217 currency code of the currency you
                           are converting to (e.g., "EUR").
  
      Returns:
          Dictionary with status and rate information.
          Success: {"status": "success", "rate": 0.93}
          Error: {"status": "error", "error_message": "Unsupported currency pair"}
      """
  
      # Static data simulating a live exchange rate API
      # In production, this would call something like: requests.get("api.exchangerates.com")
      rate_database = {
          "usd": {
              "eur": 0.93,  # Euro
              "jpy": 157.50,  # Japanese Yen
              "inr": 83.58,  # Indian Rupee
          }
      }
  
      # Input validation and processing
      base = base_currency.lower()
      target = target_currency.lower()
  
      # Return structured result with status
      rate = rate_database.get(base, {}).get(target)
      if rate is not None:
          return {"status": "success", "rate": rate}
      else:
          return {
              "status": "error",
              "error_message": f"Unsupported currency pair: {base_currency}/{target_currency}",
          }
  
  
  print("âœ… Exchange rate function created")
  print(f"ðŸ’± Test: {get_exchange_rate('USD', 'EUR')}")
  ```

  Now let's create our currency agent. Pay attention to how the agent's instructions reference the tools:

  **Key Points:**

  - The `tools=[]` list tells the agent which functions it can use
  - Instructions reference tools by their exact function names (e.g., `get_fee_for_payment_method()`)
  - The agent uses these names to decide when and how to call each tool

  ```python
  # Currency agent with custom function tools
  currency_agent = LlmAgent(
      name="currency_agent",
      model=Gemini(model="gemini-2.5-flash-lite", retry_options=retry_config),
      instruction="""You are a smart currency conversion assistant.
  
      For currency conversion requests:
      1. Use `get_fee_for_payment_method()` to find transaction fees
      2. Use `get_exchange_rate()` to get currency conversion rates
      3. Check the "status" field in each tool's response for errors
      4. Calculate the final amount after fees based on the output from `get_fee_for_payment_method` and `get_exchange_rate` methods and provide a clear breakdown.
      5. First, state the final converted amount.
          Then, explain how you got that result by showing the intermediate amounts. Your explanation must include: the fee percentage and its
          value in the original currency, the amount remaining after the fee, and the exchange rate used for the final conversion.
  
      If any tool returns status "error", explain the issue to the user clearly.
      """,
      tools=[get_fee_for_payment_method, get_exchange_rate],
  )
  
  print("âœ… Currency agent created with custom function tools")
  print("ðŸ”§ Available tools:")
  print("  â€¢ get_fee_for_payment_method - Looks up company fee structure")
  print("  â€¢ get_exchange_rate - Gets current exchange rates")
  ```

  LLMså¤§å¤šä¸æ“…é•¿è®¡ç®—ï¼Œéœ€è¦è°ƒç”¨python codeç¡®ä¿ç»“æžœæ­£ç¡®ã€‚

  ```python
  calculation_agent = LlmAgent(
      name="CalculationAgent",
      model=Gemini(model="gemini-2.5-flash-lite", retry_options=retry_config),
      instruction="""You are a specialized calculator that ONLY responds with Python code. You are forbidden from providing any text, explanations, or conversational responses.
   
       Your task is to take a request for a calculation and translate it into a single block of Python code that calculates the answer.
       
       **RULES:**
      1.  Your output MUST be ONLY a Python code block.
      2.  Do NOT write any text before or after the code block.
      3.  The Python code MUST calculate the result.
      4.  The Python code MUST print the final result to stdout.
      5.  You are PROHIBITED from performing the calculation yourself. Your only job is to generate the code that will perform the calculation.
     
      Failure to follow these rules will result in an error.
         """,
      code_executor=BuiltInCodeExecutor(),  # Use the built-in Code Executor Tool. This gives the agent code execution capabilities
  )
  ```

  Agent Tools å’Œ Sub-Agentsçš„åŒºåˆ«

  Agent Toolsï¼šAè°ƒç”¨Bä½œä¸ºå·¥å…·ï¼›Bçš„åº”ç­”è¿”å›žAï¼›Aä¿æŒåŽŸæœ‰å¯¹è¯ï¼›

  Sub-Agentsï¼šAå°†æŽ§åˆ¶æƒå®Œå…¨è½¬ç§»ç»™Bï¼›BæŽ¥æ”¶å¹¶å¤„ç†æœªæ¥çš„ç”¨æˆ·è¾“å…¥ï¼›Aé€€å‡ºå¾ªçŽ¯

### ADK tool ç±»åž‹

- è‡ªå®šä¹‰å·¥å…·ï¼šä¸ºç‰¹å®šéœ€è¦æž„å»ºçš„è‡ªå®šä¹‰å·¥å…·
  - å‡½æ•°å·¥å…·ï¼špythonå‡½æ•°
  - é•¿æœŸå‡½æ•°å·¥å…·ï¼šç‰¹å®šæ—¶é—´ä½¿ç”¨çš„å‡½æ•°æ“ä½œï¼Œå¦‚æ–‡ä»¶æ“ä½œ
  - ä»£ç†å·¥å…·ï¼šå…¶ä»–çš„ä»£ç†
  - MCPå·¥å…·ï¼šMCPæœåŠ¡ä¸­çš„å·¥å…·
  - OpenAPIå·¥å…·ï¼šç‰¹å®šAPIä¸­ç”Ÿæˆçš„å·¥å…·

![](D:\001-Coding\DATA\APX-LLM-Notebook\Agent\Image\custom_tool.JPG)

- åµŒå…¥å·¥å…·ï¼šADKä¸­å·²ç»åµŒå…¥çš„å·¥å…·
  - Gemini  Tools: æå‡Geminièƒ½åŠ›çš„å·¥å…·ï¼Œå¦‚google_research
  - è°·æ­Œäº‘å·¥å…·: google äº‘æ•´åˆçš„å·¥å…·
  - ç¬¬ä¸‰æ–¹å·¥å…·ï¼šçŽ°æœ‰çš„å·¥å…·ç”Ÿæ€ä½“ç³»

![](./Image/build_in.jpg)

### MCP

é“¾æŽ¥å¤–éƒ¨ç³»ç»Ÿçš„ç¤¾åŒºå·¥å…·é›†çš„å¼€æºæ ‡å‡†ã€‚å¯ä»¥å®žçŽ°ï¼š

- ä»Žæ•°æ®åº“ã€apisã€æœåŠ¡ä¸­è®¿é—®å®žæ—¶çš„å¤–éƒ¨æ•°æ®
- é€šè¿‡æ ‡å‡†æŽ¥å£ä½¿ç”¨ç¤¾åŒºæž„å»ºçš„å·¥å…·
- é€šè¿‡é“¾æŽ¥å¤šç§ç‰¹åˆ¶æœåŠ¡æ¥å¢žå¼ºæ¨¡åž‹èƒ½åŠ›

MCPå¦‚ä½•å‘æŒ¥ä½œç”¨ï¼šå°†è‡ªå·±çš„ä»£ç†è¿žæŽ¥åˆ°å¤–éƒ¨å¯æä¾›å·¥å…·çš„MCPæœåŠ¡ã€‚

- MCPæœåŠ¡ï¼šæä¾›ç‰¹å®šå·¥å…·ï¼Œå¦‚å›¾ç‰‡ç”Ÿæˆã€æ•°æ®åº“è®¿é—®
- MCPä»£ç†ï¼šä½¿ç”¨è¿™äº›å·¥å…·çš„è‡ªå·±çš„agent
- æ‰€æœ‰æœåŠ¡å·¥ä½œæ–¹å¼ç›¸åŒï¼šæ ‡å‡†äº¤äº’æŽ¥å£
- æ¨¡åž‹æž¶æž„![](./Image/MCP_architecture.jpg)

____

**1. æŒ‘é€‰MCPæœåŠ¡**

æœ¬æ¬¡demoä½¿ç”¨Everything MCP Serverâ€”â€”ä¸€ä¸ªä¸ºMCPè®¾è®¡çš„npmåº“ï¼Œæä¾›getTinyImageå·¥å…·ï¼Œè¿”å›žç®€å•çš„æµ‹è¯•å›¾åƒã€‚è¿˜å¯ä»¥ä½¿ç”¨å…¶ä»–çš„MCPæœåŠ¡ï¼Œæ¯”å¦‚è°·æ­Œåœ°å›¾ã€Slcakã€DIscordç­‰ç­‰ã€‚

**2. åˆ›å»ºMCPå·¥å…·é›†**

MCPå·¥å…·é›†ç”¨æ¥æ•´åˆä½¿ç”¨MCPæœåŠ¡çš„ADKä»£ç†ã€‚ä½¿ç”¨npxï¼ˆNode package runnerï¼‰è¿è¡ŒMCPæœåŠ¡ã€é“¾æŽ¥åˆ°@modelcontextprotocol/server-everythingã€ä»…ä½¿ç”¨getTInyImageå·¥å…·ã€‚

```python
# MCP integration with Everything Server
mcp_image_server = McpToolset(
    connection_params=StdioConnectionParams(
        server_params=StdioServerParameters(
            command="npx",  # Run MCP server via npx
            args=[
                "-y",  # Argument for npx to auto-confirm install
                "@modelcontextprotocol/server-everything",
            ],
            tool_filter=["getTinyImage"],
        ),
        timeout=30,
    )
)

print("âœ… MCP Tool created")
```

èƒŒåŽçš„é€»è¾‘ï¼š

1. æœåŠ¡å¯åŠ¨:ADK runs `npx -y @modelcontextprotocol/server-everything`
2. å»ºç«‹è¿žæŽ¥:Establishes stdio communication channel
3. å·¥å…·æ£€ç´¢:Server tells ADK: "I provide getTinyImage" functionality
4. æ•´åˆ:Tools appear in agent's tool list automatically
5. è¿è¡Œ: When agent calls `getTinyImage()`, ADK forwards to MCP server
6. åº”ç­”:Server result is returned to agent seamlessly

**3. å°†MCPå·¥å…·æ•´åˆåˆ°ä»£ç†ä¸­**

## DAY3 a-ä¼šè¯

ä¼šè¯æ˜¯å¯¹è¯çš„å®¹å™¨ï¼Œå®ƒä»¥**æ—¶é—´é¡ºåº**å°è£…å¯¹è¯åŽ†å²ï¼Œå¹¶è®°å½•å•ä¸ªè¿žç»­å¯¹è¯ä¸­çš„æ‰€æœ‰å·¥å…·äº¤äº’å’Œå“åº”ã€‚ä¼šè¯ä¸Ž**ç‰¹å®šç”¨æˆ·å’Œæ™ºèƒ½ä½“**ç»‘å®šï¼Œä¸ä¸Žå…¶ä»–ç”¨æˆ·å…±äº«ã€‚åŒæ ·ï¼Œä¸€ä¸ªæ™ºèƒ½ä½“çš„ä¼šè¯åŽ†å²ä¹Ÿ**ä¸ä¸Žå…¶ä»–æ™ºèƒ½ä½“å…±äº«**ã€‚

**ä¼šè¯äº‹ä»¶ï¼ˆSession.Eventsï¼‰**

è™½ç„¶ä¼šè¯æ˜¯å¯¹è¯çš„å®¹å™¨ï¼Œä½†**äº‹ä»¶**æ‰æ˜¯å¯¹è¯çš„æž„å»ºæ¨¡å—ã€‚

**äº‹ä»¶ç¤ºä¾‹**ï¼š

- **ç”¨æˆ·è¾“å…¥**ï¼šæ¥è‡ªç”¨æˆ·çš„æ¶ˆæ¯ï¼ˆæ–‡æœ¬ã€éŸ³é¢‘ã€å›¾åƒç­‰ï¼‰
- **æ™ºèƒ½ä½“å“åº”**ï¼šæ™ºèƒ½ä½“å¯¹ç”¨æˆ·çš„å›žå¤
- **å·¥å…·è°ƒç”¨**ï¼šæ™ºèƒ½ä½“å†³å®šä½¿ç”¨å¤–éƒ¨å·¥å…·æˆ– API
- **å·¥å…·è¾“å‡º**ï¼šä»Žå·¥å…·è°ƒç”¨è¿”å›žçš„æ•°æ®ï¼Œæ™ºèƒ½ä½“ç”¨å®ƒæ¥ç»§ç»­æŽ¨ç†

**{} ä¼šè¯çŠ¶æ€ï¼ˆSession.Stateï¼‰**

**session.state** æ˜¯æ™ºèƒ½ä½“çš„**è‰ç¨¿æœ¬**ï¼Œå®ƒå­˜å‚¨å’Œæ›´æ–°å¯¹è¯è¿‡ç¨‹ä¸­æ‰€éœ€çš„åŠ¨æ€ç»†èŠ‚ã€‚æ‚¨å¯ä»¥å°†å…¶è§†ä¸ºä¸€ä¸ªå…¨å±€çš„**{é”®, å€¼}** å¯¹å­˜å‚¨ï¼Œå¯¹æ‰€æœ‰**å­æ™ºèƒ½ä½“å’Œå·¥å…·**éƒ½å¯ç”¨ã€‚

------------

sessionå¯¹è¯å¹¶ä¸æ˜¯æ°¸ä¹…ä¿å­˜çš„ï¼Œå½“å¯¹è¯é—å¤±çš„æ—¶å€™ï¼Œæ¨¡åž‹ä¼šé—å¿˜è¿‡åŽ»çš„å¯¹è¯ã€‚ä¸ºå¼¥è¡¥è¿™ä¸ªé—®é¢˜ï¼Œéœ€è¦å€ŸåŠ©æ•°æ®åº“ã€‚ã€‚ã€‚

é€‰æ‹©æ­£ç¡®çš„sessionservice

| Service                    | Use Case              | Persistence         | Best For             |
| -------------------------- | --------------------- | ------------------- | -------------------- |
| **InMemorySessionService** | Development & Testing | âŒ Lost on restart   | Quick prototypes     |
| **DatabaseSessionService** | Self-managed apps     | âœ… Survives restarts | Small to medium apps |
| **Agent Engine Sessions**  | Production on GCP     | âœ… Fully managed     | Enterprise scale     |

ä½¿ç”¨sqliteå‡çº§databasesessionservice

```python
# Step 1: Create the same agent (notice we use LlmAgent this time)
chatbot_agent = LlmAgent(
    model=Gemini(model="gemini-2.5-flash-lite", retry_options=retry_config),
    name="text_chat_bot",
    description="A text chatbot with persistent memory",
)

# Step 2: Switch to DatabaseSessionService
# SQLite database will be created automatically
db_url = "sqlite:///my_agent_data.db"  # Local SQLite file
session_service = DatabaseSessionService(db_url=db_url)

# Step 3: Create a new runner with persistent storage
runner = Runner(agent=chatbot_agent, app_name=APP_NAME, session_service=session_service)

print("âœ… Upgraded to persistent sessions!")
print(f"   - Database: my_agent_data.db")
print(f"   - Sessions will survive restarts!")
```

ä½¿ç”¨æ•°æ®åº“ä¹‹åŽï¼Œagentå¯ä»¥è®°å½•å¯¹è¯ï¼Œä½†ä¸åŒäº‹ä»¶ä¹‹é—´ï¼Œå¯¹è¯ä¿¡æ¯æ˜¯ä¸å…±äº«ï¼Œç›¸äº’éš”ç¦»çš„

```python
await run_session(
    runner,
    ["What is the capital of India?", "Hello! What is my name?"],
    "test-db-session-01",
)
```

![](D:\001-Coding\DATA\APX-LLM-Notebook\Agent\Image\session1.JPG)

```python
await run_session(
    runner, ["Hello! What is my name?"], "test-db-session-02"
)  # Note, we are using new session name
```

![](D:\001-Coding\DATA\APX-LLM-Notebook\Agent\Image\session2.JPG)

ä¼šè¯æ•°æ®æ˜¯å¦‚ä½•å­˜å‚¨åœ¨æ•°æ®åº“ä¸­çš„ï¼Ÿ

```python
import sqlite3

def check_data_in_db():
    with sqlite3.connect("my_agent_data.db") as connection:
        cursor = connection.cursor()
        result = cursor.execute(
            "select app_name, session_id, author, content from events"
        )
        print([_[0] for _ in result.description])
        for each in result.fetchall():
            print(each)


check_data_in_db()
```

![](D:\001-Coding\DATA\APX-LLM-Notebook\Agent\Image\session3.JPG)

ä¹‹å‰çš„å¯¹è¯ä¿¡æ¯å¯ä»¥å¿«é€Ÿå­˜å‚¨åœ¨æ•°æ®åº“ä¸­ï¼Œå¯¹äºŽå¤æ‚çš„ä»»åŠ¡ï¼Œé•¿çš„ä¸Šä¸‹æ–‡å¯ä»¥å˜å¾—éžå¸¸å¤§ï¼Œå¯¼è‡´è¿è¡Œé€Ÿåº¦å‡æ…¢å¹¶ä¸”æ›´é«˜çš„è®¡ç®—å¼€é”€ã€‚æˆ‘ä»¬å¯ä»¥é€šè¿‡è‡ªåŠ¨æ€»ç»“è¿‡åŽ»çš„å†…å®¹ï¼Œå‡å°‘ä¸Šä¸‹æ–‡çš„å­˜å‚¨å¤æ‚åº¦ã€‚

ä¼šè¯é»˜è®¤éš”ç¦»ä¿¡æ¯å…±äº«ï¼Œä½†å¦‚æžœä½¿ç”¨useridåˆ™å¯ä»¥åœ¨ä¸åŒä¼šè¯ä¹‹é—´å½¢æˆä¿¡æ¯äº¤å‰ã€‚

```python
# Check the state of the new session
session = await session_service.get_session(
    app_name=APP_NAME, user_id=USER_ID, session_id="new-isolated-session"
)

print("New Session State:")
print(session.state)

# Note: Depending on implementation, you might see shared state here.
# This is where the distinction between session-specific and user-specific state becomes important.
```

## Day3b-ä»£ç†è®°å¿†

è®°å¿†æ˜¯ä¸€ç§ä¸ºä»£ç†æä¾›é•¿æœŸçŸ¥è¯†å­˜å‚¨çš„æœåŠ¡ï¼Œå…³é”®åŒºåˆ«åœ¨äºŽï¼š

- ä¼šè¯ï¼šçŸ­æœŸè®°å¿†ï¼Œå•ä¸€çš„å¯¹è¯
- è®°å¿†ï¼šé•¿æœŸçš„çŸ¥è¯†å‚¨å¤‡ï¼Œå¯åœ¨ä¸åŒå¯¹è¯ä¸­äº¤å‰ä½¿ç”¨

ä¼šè¯å°±åƒæ˜¯åº”ç”¨çŠ¶æ€ï¼Œæ˜¯æš‚æ—¶çš„ï¼›è€Œè®°å¿†åˆ™åƒæ˜¯æ•°æ®åº“ï¼Œæ˜¯æ°¸ä¹…çš„ã€‚

ä¸ºä»€ä¹ˆéœ€è¦è®°å¿†ï¼Ÿè®°å¿†æä¾›å¯¹è¯æ‰€æ²¡æœ‰çš„èƒ½åŠ›

| Capability                    | What It Means                                      | Example                                                      |
| :---------------------------- | :------------------------------------------------- | :----------------------------------------------------------- |
| **Cross-Conversation Recall** | Access information from any past conversation      | "What preferences has this user mentioned across all chats?" |
| **Intelligent Extraction**    | LLM-powered consolidation extracts key facts       | Stores "allergic to peanuts" instead of 50 raw messages      |
| **Semantic Search**           | Meaning-based retrieval, not just keyword matching | Query "preferred hue" matches "favorite color is blue"       |
| **Persistent Storage**        | Survives application restarts                      | Build knowledge that grows over time                         |

---

**åˆå§‹åŒ–è®°å¿†æœåŠ¡**

![](D:\001-Coding\DATA\APX-LLM-Notebook\Agent\Image\Memory.JPG)

```python
memory_service = (
    InMemoryMemoryService()
)  # ADK's built-in Memory Service for development and testing
```

æ·»åŠ è®°å¿†æœåŠ¡åˆ°agent

```python
# Define constants used throughout the notebook
APP_NAME = "MemoryDemoApp"
USER_ID = "demo_user"

# Create agent
user_agent = LlmAgent(
    model=Gemini(model="gemini-2.5-flash-lite", retry_options=retry_config),
    name="MemoryDemoAgent",
    instruction="Answer user questions in simple words.",
)

print("âœ… Agent created")
```

åˆ›å»ºrunner

```python
# Create Session Service
session_service = InMemorySessionService()  # Handles conversations

# Create runner with BOTH services
runner = Runner(
    agent=user_agent,
    app_name="MemoryDemoApp",
    session_service=session_service,
    memory_service=memory_service,  # Memory service is now available!
)

print("âœ… Agent and Runner created with memory support!")
```

å°†memory_service æ·»åŠ åˆ°Runnerä¸­ä½¿å¾—agentå¯ä»¥ä½¿ç”¨è®°å¿†åŠŸèƒ½ï¼Œä½†å¹¶éžè‡ªåŠ¨å®žçŽ°ï¼Œéœ€è¦æ˜¾å¼è°ƒç”¨ï¼š

1. **Ingest data** using `add_session_to_memory()`
2. **Enable retrieval** by giving your agent memory tools (`load_memory` or `preload_memory`)

ä½¿ç”¨è®°å¿†ç®¡ç†æœåŠ¡ï¼Œå¦‚Vertex AI Memory Bank å¯ä»¥è®©å¯¹è¯è¿›è¡Œæ™ºèƒ½æå–ä¿¡æ¯ï¼Œä»…ä»…InMemoryMemoryServiceä¸å…·æœ‰æå–åŠŸèƒ½

```python
# User tells agent about their favorite color
await run_session(
    runner,
    "My favorite color is blue-green. Can you write a Haiku about it?",
    "conversation-01",  # Session ID
)

session = await session_service.get_session(
    app_name=APP_NAME, user_id=USER_ID, session_id="conversation-01"
)

# Let's see what's in the session
print("ðŸ“ Session contains:")
for event in session.events:
    text = (
        event.content.parts[0].text[:60]
        if event.content and event.content.parts
        else "(empty)"
    )
    print(f"  {event.content.role}: {text}...")
# å°†ä¼šè¯æ·»åŠ åˆ°è®°å¿†    
# This is the key method!
await memory_service.add_session_to_memory(session)

print("âœ… Session added to memory!")
```

### **æ¿€æ´»agentçš„è®°å¿†æ£€ç´¢åŠŸèƒ½**

agentsä¸èƒ½ç›´æŽ¥è®¿é—®è®°å¿†æœåŠ¡ï¼Œä»–ä»¬éœ€è¦ä½¿ç”¨å·¥å…·æ¥è°ƒç”¨è®°å¿†æœåŠ¡ã€‚

ADKæä¾›ä¸¤ç§å†…åœ¨å·¥å…·æ¥ä½¿ç”¨è®°å¿†æ£€ç´¢ï¼š

- load_memory(Reactive)
  - Agent decides when to search memory
  - Only retrieves when the agent thinks it's needed
  - More efficient (saves tokens)
  - Risk: Agent might forget to search
- preload_memory(Proactive)
  - Automatically searches before every turn
  - Memory always available to the agent
  - Guaranteed context, but less efficient
  - Searches even when not needed

```python
# Create agent
user_agent = LlmAgent(
    model=Gemini(model="gemini-2.5-flash-lite", retry_options=retry_config),
    name="MemoryDemoAgent",
    instruction="Answer user questions in simple words. Use load_memory tool if you need to recall past conversations.",
    tools=[
        load_memory
    ],  # Agent now has access to Memory and can search it whenever it decides to!
)

print("âœ… Agent with load_memory tool created.")
```

```python
# Create a new runner with the updated agent
runner = Runner(
    agent=user_agent,
    app_name=APP_NAME,
    session_service=session_service,
    memory_service=memory_service,
)

await run_session(runner, "What is my favorite color?", "color-test")
```

sk-xVIOEZ266vo9ObNUOqRdBBfSgSYaVduCUoh2aZm3sbckXAVD

**è‡ªåŠ©è®°å¿†æ£€ç´¢åŠŸèƒ½**

è®°å¿†æ£€ç´¢åŠŸèƒ½å¯ä»¥ç›´æŽ¥åœ¨ä»£ç ä¸­å®žçŽ°ï¼Œä¸»è¦ç”¨äºŽï¼š

- debuggingä¸Šä¸‹æ–‡è®°å¿†
- ç®€åŽ†åˆ†æžé¢æ¿
- åˆ›å»ºè‡ªå®šä¹‰çš„è®°å¿†ç®¡ç†UIs

`search_memory()`æ–¹æ³•è¾“å…¥ä¸€ä¸ªæ–‡æœ¬è¯·æ±‚ï¼Œè¿”å›žä¸€ä¸ªè®°å¿†æœå¯»çš„åº”ç­”

```python
# Search for color preferences
search_response = await memory_service.search_memory(
    app_name=APP_NAME, user_id=USER_ID, query="joke"
)

print("ðŸ” Search Results:")
print(f"  Found {len(search_response.memories)} relevant memories")
print()

for memory in search_response.memories:
    if memory.content and memory.content.parts:
        text = memory.content.parts[0].text[:80]
        print(f"  [{memory.author}]: {text}...")
```

**è®°å¿†æ£€ç´¢æ˜¯å¦‚ä½•èµ·ä½œç”¨çš„**

**InMemoryMemoryService(æœ¬notebookä¸­):**

- **æ–¹æ³•**ï¼šå…³é”®è¯åŒ¹é…
- **ç¤ºä¾‹**ï¼š"favorite color"ï¼ˆæœ€å–œæ¬¢çš„é¢œè‰²ï¼‰èƒ½å¤ŸåŒ¹é…ï¼Œå› ä¸ºå­˜åœ¨è¿™äº›ç¡®åˆ‡çš„å•è¯
- **å±€é™æ€§**ï¼š"preferred hue"ï¼ˆåçˆ±çš„è‰²è°ƒï¼‰å°†æ— æ³•åŒ¹é…

**VertexAiMemoryBankServiceï¼ˆç¬¬5å¤©å°†ä»‹ç»çš„ï¼‰ï¼š**

- **æ–¹æ³•**ï¼šé€šè¿‡åµŒå…¥å‘é‡è¿›è¡Œè¯­ä¹‰æœç´¢
- **ç¤ºä¾‹**ï¼š"preferred hue"ï¼ˆåçˆ±çš„è‰²è°ƒï¼‰**èƒ½å¤Ÿ**åŒ¹é…"favorite color"ï¼ˆæœ€å–œæ¬¢çš„é¢œè‰²ï¼‰
- **ä¼˜åŠ¿**ï¼šç†è§£è¯­ä¹‰å«ä¹‰ï¼Œè€Œä¸ä»…ä»…æ˜¯å…³é”®è¯åŒ¹é…

### è‡ªåŠ¨è®°å¿†å­˜å‚¨

ç›®å‰æˆ‘ä»¬ä½¿ç”¨äº†`add_session_to_memory()`å°†æ•°æ®è½¬åŒ–ä¸ºé•¿æœŸè®°å¿†ã€‚ç”Ÿäº§ç³»ç»Ÿéœ€è¦å°†è¿™ä¸ªè¡Œä¸ºè‡ªåŠ¨åŒ–ã€‚

#### å›žè°ƒ

**æƒ³è±¡å›žè°ƒåŠŸèƒ½åœ¨ä»£ç†çš„ç”Ÿå‘½å‘¨æœŸä¸­æ˜¯äº‹ä»¶ç›‘å¬å™¨ã€‚**å½“ä¸€ä¸ªä»£ç†æŠ›å‡ºä¸€ä¸ªè¯·æ±‚ï¼Œå®ƒä¼šç»åŽ†ä¸åŒçš„é˜¶æ®µï¼šæŽ¥å—è¾“å…¥ï¼Œè°ƒç”¨llmï¼Œè°ƒç”¨å·¥å…·ï¼Œç”Ÿæˆå›žåº”ã€‚å¬å›žå¯ä»¥åœ¨æ¯ä¸ªé˜¶æ®µè‡ªå®šä¹‰é€»è¾‘è€Œä¸éœ€è¦ä¿®æ”¹ä»£ç†çš„æ ¸å¿ƒä»£ç 

å¯ç”¨çš„å›žè°ƒç±»åž‹ï¼š

- **before_agent_callback** â†’ åœ¨ä»£ç†å¼€å§‹å¤„ç†è¯·æ±‚**ä¹‹å‰**è¿è¡Œ
- **after_agent_callback** â†’ åœ¨ä»£ç†å®Œæˆæœ¬æ¬¡æ‰§è¡Œ**ä¹‹åŽ**è¿è¡Œ
- **before_tool_callback** / **after_tool_callback** â†’ å›´ç»•å·¥å…·è°ƒç”¨ï¼ˆè°ƒç”¨å‰/åŽï¼‰
- **before_model_callback** / **after_model_callback** â†’ å›´ç»• LLM è°ƒç”¨ï¼ˆè°ƒç”¨å‰/åŽï¼‰
- **on_model_error_callback** â†’ å½“å‘ç”Ÿé”™è¯¯æ—¶è¿è¡Œ

å¸¸è§ä½¿ç”¨åœºæ™¯ï¼š

- **æ—¥å¿—è®°å½•ä¸Žå¯è§‚æµ‹æ€§**ï¼ˆè¿½è¸ªä»£ç†è¡Œä¸ºï¼‰
- **è‡ªåŠ¨æ•°æ®æŒä¹…åŒ–**ï¼ˆå¦‚ä¿å­˜åˆ°è®°å¿†ç³»ç»Ÿï¼‰
- **è‡ªå®šä¹‰éªŒè¯æˆ–è¿‡æ»¤**
- **æ€§èƒ½ç›‘æŽ§**

**è‡ªåŠ¨è®°å¿†å­˜å‚¨çš„å›žè°ƒ**

```python
async def auto_save_to_memory(callback_context):
    """Automatically save session to memory after each agent turn."""
    await callback_context._invocation_context.memory_service.add_session_to_memory(
        callback_context._invocation_context.session
    )


print("âœ… Callback created.")
```

```python
# Agent with automatic memory saving
auto_memory_agent = LlmAgent(
    model=Gemini(model="gemini-2.5-flash-lite", retry_options=retry_config),
    name="AutoMemoryAgent",
    instruction="Answer user questions.",
    tools=[preload_memory],
    after_agent_callback=auto_save_to_memory,  # Saves after each turn!
)

print("âœ… Agent created with automatic memory saving!")
```

```python
# Create a runner for the auto-save agent
# This connects our automated agent to the session and memory services
auto_runner = Runner(
    agent=auto_memory_agent,  # Use the agent with callback + preload_memory
    app_name=APP_NAME,
    session_service=session_service,  # Same services from Section 3
    memory_service=memory_service,
)

print("âœ… Runner created.")
```

```python
# Test 1: Tell the agent about a gift (first conversation)
# The callback will automatically save this to memory when the turn completes
await run_session(
    auto_runner,
    "I gifted a new toy to my nephew on his 1st birthday!",
    "auto-save-test",
)

# Test 2: Ask about the gift in a NEW session (second conversation)
# The agent should retrieve the memory using preload_memory and answer correctly
await run_session(
    auto_runner,
    "What did I gift my nephew?",
    "auto-save-test-2",  # Different session ID - proves memory works across sessions!
)
```

ä½•æ—¶å­˜å‚¨ï¼Ÿ

| Timing                  | Implementation                | Best For                           |
| ----------------------- | ----------------------------- | ---------------------------------- |
| **After every turn**    | `after_agent_callback`        | Real-time memory updates           |
| **End of conversation** | Manual call when session ends | Batch processing, reduce API calls |
| **Periodic intervals**  | Timer-based background job    | Long-running conversations         |

### è®°å¿†æ•´åˆ

åŽŸå§‹å­˜å‚¨çš„å±€é™æ€§

æˆ‘ä»¬ç›®å‰å­˜å‚¨çš„å†…å®¹ï¼š

- æ¯æ¡ç”¨æˆ·æ¶ˆæ¯
- æ¯æ¡ä»£ç†å“åº”
- æ¯ä¸ªå·¥å…·è°ƒç”¨

å­˜åœ¨çš„é—®é¢˜ï¼š

```
ä¼šè¯ï¼š50æ¡æ¶ˆæ¯ = 10,000ä¸ªtoken
è®°å¿†ï¼šå­˜å‚¨æ‰€æœ‰50æ¡æ¶ˆæ¯
æœç´¢ï¼šè¿”å›žå…¨éƒ¨50æ¡æ¶ˆæ¯ â†’ ä»£ç†å¿…é¡»å¤„ç†10,000ä¸ªtoken
```

è¿™ç§æ–¹æ¡ˆä¸å¯æ‰©å±•ã€‚æˆ‘ä»¬éœ€è¦**è®°å¿†æ•´åˆ**ã€‚

#### ä»€ä¹ˆæ˜¯è®°å¿†æ•´åˆ

æŠ›å¼ƒå¯¹è¯å™ªéŸ³ï¼Œåªæå–æœ€é‡è¦çš„å› ç´ 

**efore (Raw Storage):**

```
User: "My favorite color is BlueGreen. I also like purple. 
       Actually, I prefer BlueGreen most of the time."
Agent: "Great! I'll remember that."
User: "Thanks!"
Agent: "You're welcome!"

â†’ Stores ALL 4 messages (redundant, verbose)
```

**After (Consolidation):**

```
Extracted Memory: "User's favorite color: BlueGreen"

â†’ Stores 1 concise fact
```

**Benefits:** Less storage, faster retrieval, more accurate answers.

#### è®°å¿†æ•´åˆå¦‚ä½•ç”Ÿæ•ˆ

**The pipeline:**

```
1. Raw Session Events
   â†“
2. LLM analyzes conversation
   â†“
3. Extracts key facts
   â†“
4. Stores concise memories
   â†“
5. Merges with existing memories (deduplication)
```

**Example transformation:**

```
Input:  "I'm allergic to peanuts. I can't eat anything with nuts."

Output: Memory {
  allergy: "peanuts, tree nuts"
  severity: "avoid completely"
}
```

Natural language â†’ Structured, actionable data.ç»“æž„åŒ–ã€å¯æ“ä½œçš„æ•°æ®

#### è®°å¿†æ•´åˆçš„è¿›é˜¶

**å…³é”®è¦ç‚¹ï¼šæ‰˜ç®¡è®°å¿†æœåŠ¡ä¼šè‡ªåŠ¨å¤„ç†è®°å¿†æ•´åˆã€‚**

**ä½ ä½¿ç”¨ç›¸åŒçš„APIï¼š**

```
add_session_to_memory() â† ç›¸åŒçš„æ–¹æ³•
search_memory() â† ç›¸åŒçš„æ–¹æ³•
```

**åŒºåˆ«åœ¨äºŽåŽå°å¤„ç†æ–¹å¼ï¼š**

- **InMemoryMemoryService**ï¼šå­˜å‚¨åŽŸå§‹äº‹ä»¶
- **VertexAiMemoryBankService**ï¼šå­˜å‚¨å‰æ™ºèƒ½æ•´åˆè®°å¿†

**ðŸ“š äº†è§£æ›´å¤šï¼š**

- Vertex AI Memory Bankï¼šè®°å¿†æ•´åˆæŒ‡å— â†’ ä½ å°†åœ¨ç¬¬5å¤©æŽ¢ç´¢è¿™ä¸ªåŠŸèƒ½ï¼

## Day4a Agent observability

- å­¦ä¹ å¦‚ä½•ç»™agentæ·»åŠ è§‚å¯Ÿèƒ½åŠ›
- å­¦ä¹ å¦‚ä½•è¯„ä¼°agentçš„å·¥ä½œçŠ¶å†µ

ä»€ä¹ˆæ˜¯agentè§‚å¯Ÿèƒ½åŠ›ï¼Ÿä¸Žå…¶ä»–çš„è½¯ä»¶ä¸åŒï¼Œai agentä¼šå‡ºä¸€äº›å¥‡æ€ªçš„é—®é¢˜ã€‚æ¯”å¦‚ï¼š

```
User: "Find quantum computing papers"
Agent: "I cannot help with that request."
You: ðŸ˜­ WHY?? Is it the prompt? Missing tools? API error?
```

agentè§‚å¯Ÿèƒ½åŠ›å¯ä»¥è®©ä½ çš„agentå†³ç­–å¯è§†åŒ–ï¼Œä½ å¯ä»¥çœ‹åˆ°å‘é€åˆ°llmçš„æŒ‡ä»¤ä»¥åŠæç¤ºè¯ï¼Œä»€ä¹ˆå·¥å…·æ˜¯å¯ç”¨çš„ï¼Œæ¨¡åž‹æ˜¯å¦‚ä½•ç”Ÿæ•ˆçš„ï¼Œä»¥åŠé”™è¯¯å‘ç”Ÿåœ¨å“ªé‡Œã€‚

```
DEBUG Log: LLM Request shows "Functions: []" (no tools!)
You: ðŸŽ¯ Aha! Missing google_search tool - easy fix!
```

Agent Observabilityçš„åŸºç¡€åŠŸèƒ½

- æ—¥å¿—ï¼šæ—¥å¿—æ˜¯å•ä¸ªäº‹ä»¶çš„è®°å½•ï¼Œå‘ŠçŸ¥åœ¨ç‰¹å®šæ—¶åˆ»å‘ç”Ÿäº†ä»€ä¹ˆã€‚

- è¿½è¸ªï¼šè¿½è¸ªå°†æ—¥å¿—ä¸²è”æˆå®Œæ•´æ•…äº‹ï¼Œé€šè¿‡æ­ç¤ºå…¨æ­¥éª¤åºåˆ—å±•ç¤ºæœ€ç»ˆç»“æžœçš„äº§ç”ŸåŽŸå› ã€‚

- æŒ‡æ ‡ï¼šæŒ‡æ ‡æ˜¯æ±‡æ€»æ€§æ•°å€¼ï¼ˆå¦‚å¹³å‡å€¼ä¸Žé”™è¯¯çŽ‡ï¼‰ï¼Œç”¨äºŽåæ˜ æ™ºèƒ½ä½“çš„æ•´ä½“è¿è¡ŒçŠ¶å†µã€‚

![](./Image/observability-intro.png)

- ä½¿ç”¨TraceåŠŸèƒ½debug
- ä½¿ç”¨æœ¬åœ°æ—¥å¿—debug

```python
import logging
import os

# Clean up any previous logs
for log_file in ["logger.log", "web.log", "tunnel.log"]:
    if os.path.exists(log_file):
        os.remove(log_file)
        print(f"ðŸ§¹ Cleaned up {log_file}")

# Configure logging with DEBUG log level.
logging.basicConfig(
    filename="logger.log",
    level=logging.DEBUG,
    format="%(filename)s:%(lineno)s %(levelname)s:%(message)s",
)

print("âœ… Logging configured")
```

### åœ¨äº§å“ä¸­è®°å½•

- é—®é¢˜1ï¼šäº§å“éƒ¨ç½²ã€‚å¦‚ä½•åœ¨å·²éƒ¨ç½²çš„äº§å“ä¸Šdebugï¼Ÿ
- é—®é¢˜2ï¼šè‡ªåŠ¨åŒ–ç³»ç»Ÿã€‚åœ¨çŽ°æœ‰ç®¡çº¿ä¸Šï¼Œagentä¸€å¤©è·‘1000æ¬¡ã€‚å¦‚ä½•è‡ªåŠ¨åŒ–æµ‹è¯•å„éƒ¨åˆ†çš„è€—æ—¶ï¼Ÿè€Œä¸æ˜¯å¯¹æ¯ä¸ªçŽ¯èŠ‚debugï¼Œå…±debug1000æ¬¡

è§£å†³åŠžæ³•ï¼šéœ€è¦æ•èŽ·æ•°æ®ä¿¡æ¯â€”â€”åœ¨ä»£ç ä¸­æ·»åŠ æ—¥å¿—ã€‚åœ¨ä¼ ç»Ÿè½¯ä»¶å¼€å‘ä¸­ï¼Œåªéœ€è¦åœ¨ä»£ç ä¸­æ‰“logï¼Œä½†æ˜¯åœ¨agentä¸­ï¼Œè¿™æ˜¯ä¸åŒçš„ã€‚é€šå¸¸çš„åšæ³•æ˜¯åœ¨agentä¸­åŠ å…¥æ’ä»¶ã€‚

---

å¦‚ä½•åœ¨äº§å“ä¸­æ·»åŠ æ—¥å¿—åŠŸèƒ½

**æ’ä»¶**æ˜¯ä¸€ä¸ªè‡ªå®šä¹‰ä»£ç æ¨¡å—ï¼Œä¼šåœ¨æ™ºèƒ½ä½“ç”Ÿå‘½å‘¨æœŸçš„ä¸åŒé˜¶æ®µè‡ªåŠ¨è¿è¡Œã€‚æ’ä»¶ç”±"å›žè°ƒå‡½æ•°"æž„æˆï¼Œè¿™äº›å›žè°ƒæä¾›äº†æ‹¦æˆªæ™ºèƒ½ä½“æµç¨‹çš„é’©å­ã€‚å¯ä»¥è¿™æ ·ç†è§£ï¼š

- æ‚¨çš„æ™ºèƒ½ä½“å·¥ä½œæµç¨‹ï¼šç”¨æˆ·æ¶ˆæ¯ â†’ æ™ºèƒ½ä½“æ€è€ƒ â†’ è°ƒç”¨å·¥å…· â†’ è¿”å›žå“åº”

- æ’ä»¶å¯ä»‹å…¥æ­¤æµç¨‹ï¼šåœ¨æ™ºèƒ½ä½“å¯åŠ¨å‰ â†’ å·¥å…·è¿è¡ŒåŽ â†’ LLMå“åº”æ—¶ â†’ ç­‰å„ä¸ªé˜¶æ®µ

- æ’ä»¶åŒ…å«æ‚¨çš„è‡ªå®šä¹‰ä»£ç ï¼šæ—¥å¿—è®°å½•ã€è¿è¡Œç›‘æŽ§ã€å®‰å…¨æ£€æŸ¥ã€ç¼“å­˜å¤„ç†ç­‰ã€‚

![](./Image/plugins-callbacks.png)

**å›žè°ƒå‡½æ•°**

å›žè°ƒå‡½æ•°æ˜¯æ’ä»¶å†…éƒ¨çš„åŸºæœ¬ç»„æˆå•å…ƒâ€”â€”å®ƒä»¬åªæ˜¯ç®€å•çš„Pythonå‡½æ•°ï¼Œåœ¨æ™ºèƒ½ä½“ç”Ÿå‘½å‘¨æœŸçš„ç‰¹å®šæ—¶é—´ç‚¹æ‰§è¡Œï¼å¤šä¸ªå›žè°ƒå‡½æ•°ç»„åˆåœ¨ä¸€èµ·å°±æž„æˆäº†ä¸€ä¸ªæ’ä»¶ã€‚

å›žè°ƒå‡½æ•°ä¸»è¦æœ‰ä»¥ä¸‹å‡ ç§ç±»åž‹ï¼š

- **before/after_agent_callbacks** - åœ¨æ™ºèƒ½ä½“è¢«è°ƒç”¨**ä¹‹å‰/ä¹‹åŽ**æ‰§è¡Œ

- **before/after_tool_callbacks**  åœ¨å·¥å…·è¢«è°ƒç”¨**ä¹‹å‰/ä¹‹åŽ**æ‰§è¡Œ

- **before/after_model_callbacks** - ç±»ä¼¼åœ°ï¼Œåœ¨LLMæ¨¡åž‹è¢«è°ƒç”¨**ä¹‹å‰/ä¹‹åŽ**æ‰§è¡Œ

- **on_model_error_callback** - åœ¨é‡åˆ°æ¨¡åž‹é”™è¯¯æ—¶æ‰§è¡Œ

![](./Image/types_of_callbacks.png)

### Pluginå¦‚ä½•è®¾è®¡

```python
print("----- EXAMPLE PLUGIN - DOES NOTHING ----- ")

import logging
from google.adk.agents.base_agent import BaseAgent
from google.adk.agents.callback_context import CallbackContext
from google.adk.models.llm_request import LlmRequest
from google.adk.plugins.base_plugin import BasePlugin


# Applies to all agent and model calls
class CountInvocationPlugin(BasePlugin):
    """A custom plugin that counts agent and tool invocations."""

    def __init__(self) -> None:
        """Initialize the plugin with counters."""
        super().__init__(name="count_invocation")
        self.agent_count: int = 0
        self.tool_count: int = 0
        self.llm_request_count: int = 0

    # Callback 1: Runs before an agent is called. You can add any custom logic here.
    async def before_agent_callback(
        self, *, agent: BaseAgent, callback_context: CallbackContext
    ) -> None:
        """Count agent runs."""
        self.agent_count += 1
        logging.info(f"[Plugin] Agent run count: {self.agent_count}")

    # Callback 2: Runs before a model is called. You can add any custom logic here.
    async def before_model_callback(
        self, *, callback_context: CallbackContext, llm_request: LlmRequest
    ) -> None:
        """Count LLM requests."""
        self.llm_request_count += 1
        logging.info(f"[Plugin] LLM request count: {self.llm_request_count}")
```

![](./Image/count-invocation-plugin.png)

```py
from google.adk.agents import LlmAgent
from google.adk.models.google_llm import Gemini
from google.adk.tools.agent_tool import AgentTool
from google.adk.tools.google_search_tool import google_search

from google.genai import types
from typing import List

retry_config = types.HttpRetryOptions(
    attempts=5,  # Maximum retry attempts
    exp_base=7,  # Delay multiplier
    initial_delay=1,
    http_status_codes=[429, 500, 503, 504],  # Retry on these HTTP errors
)


def count_papers(papers: List[str]):
    """
    This function counts the number of papers in a list of strings.
    Args:
      papers: A list of strings, where each string is a research paper.
    Returns:
      The number of papers in the list.
    """
    return len(papers)


# Google search agent
google_search_agent = LlmAgent(
    name="google_search_agent",
    model=Gemini(model="gemini-2.5-flash-lite", retry_options=retry_config),
    description="Searches for information using Google search",
    instruction="Use the google_search tool to find information on the given topic. Return the raw search results.",
    tools=[google_search],
)

# Root agent
research_agent_with_plugin = LlmAgent(
    name="research_paper_finder_agent",
    model=Gemini(model="gemini-2.5-flash-lite", retry_options=retry_config),
    instruction="""Your task is to find research papers and count them. 
   
   You must follow these steps:
   1) Find research papers on the user provided topic using the 'google_search_agent'. 
   2) Then, pass the papers to 'count_papers' tool to count the number of papers returned.
   3) Return both the list of research papers and the total number of papers.
   """,
    tools=[AgentTool(agent=google_search_agent), count_papers],
)

print("âœ… Agent created")
```

**To use `LoggingPlugin` in the above research agent,**

1. Import the plugin
2. Add it when initializing the `InMemoryRunner`.

```py
from google.adk.runners import InMemoryRunner
from google.adk.plugins.logging_plugin import (
    LoggingPlugin,
)  # <---- 1. Import the Plugin
from google.genai import types
import asyncio

runner = InMemoryRunner(
    agent=research_agent_with_plugin,
    plugins=[
        LoggingPlugin()
    ],  # <---- 2. Add the plugin. Handles standard Observability logging across ALL agents
)

print("âœ… Runner configured")
```

```py
print("ðŸš€ Running agent with LoggingPlugin...")
print("ðŸ“Š Watch the comprehensive logging output below:\n")

response = await runner.run_debug("Find recent papers on quantum computing")
```



## Day4b Agent Evaluation

#### Interactive Evaluation with ADK Web UI

#### ç³»ç»Ÿæ€§è¯„ä¼°

å›žå½’æµ‹è¯•æ˜¯æŒ‡é‡æ–°è¿è¡ŒçŽ°æœ‰çš„æµ‹è¯•ï¼Œä»¥ç¡®ä¿æ–°çš„æ›´æ”¹æ²¡æœ‰ç ´åä¹‹å‰æ­£å¸¸å·¥ä½œçš„åŠŸèƒ½ã€‚

ADKæä¾›äº†ä¸¤ç§è‡ªåŠ¨è¿›è¡Œå›žå½’å’Œæ‰¹é‡æµ‹è¯•çš„æ–¹æ³•ï¼šä½¿ç”¨pytestå’Œ`adk eval`CLIå‘½ä»¤ã€‚åœ¨æœ¬èŠ‚ä¸­ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨CLIå‘½ä»¤ã€‚æœ‰å…³pytestæ–¹æ³•çš„æ›´å¤šä¿¡æ¯ï¼Œè¯·å‚é˜…æœ¬ç¬”è®°æœ¬æœ«å°¾èµ„æºéƒ¨åˆ†ä¸­çš„é“¾æŽ¥ã€‚

ä¸‹å›¾å±•ç¤ºäº†è¯„ä¼°çš„æ•´ä½“æµç¨‹ã€‚ä»Žé«˜å±‚æ¬¡æ¥çœ‹ï¼Œè¯„ä¼°åˆ†ä¸ºå››ä¸ªæ­¥éª¤ï¼š

1. **åˆ›å»ºè¯„ä¼°é…ç½®** - å®šä¹‰æŒ‡æ ‡æˆ–æ‚¨æƒ³è¦æµ‹é‡çš„å†…å®¹
2. **åˆ›å»ºæµ‹è¯•ç”¨ä¾‹** - ç”¨äºŽå¯¹æ¯”çš„æ ·æœ¬æµ‹è¯•ç”¨ä¾‹
3. **ä½¿ç”¨æµ‹è¯•æŸ¥è¯¢è¿è¡Œä»£ç†**
4. **æ¯”è¾ƒç»“æžœ**

![](./Image/evaluate_agent.png)

```python
import json

# Create evaluation configuration with basic criteria
eval_config = {
    "criteria": {
        "tool_trajectory_avg_score": 1.0,  # Perfect tool usage required
        "response_match_score": 0.8,  # 80% text similarity threshold
    }
}

with open("home_automation_agent/test_config.json", "w") as f:
    json.dump(eval_config, f, indent=2)

print("âœ… Evaluation configuration created!")
print("\nðŸ“Š Evaluation Criteria:")
print("â€¢ tool_trajectory_avg_score: 1.0 - Requires exact tool usage match")
print("â€¢ response_match_score: 0.8 - Requires 80% text similarity")
print("\nðŸŽ¯ What this evaluation will catch:")
print("âœ… Incorrect tool usage (wrong device, location, or status)")
print("âœ… Poor response quality and communication")
print("âœ… Deviations from expected behavior patterns")
```

```python
# Create evaluation test cases that reveal tool usage and response quality problems
test_cases = {
    "eval_set_id": "home_automation_integration_suite",
    "eval_cases": [
        {
            "eval_id": "living_room_light_on",
            "conversation": [
                {
                    "user_content": {
                        "parts": [
                            {"text": "Please turn on the floor lamp in the living room"}
                        ]
                    },
                    "final_response": {
                        "parts": [
                            {
                                "text": "Successfully set the floor lamp in the living room to on."
                            }
                        ]
                    },
                    "intermediate_data": {
                        "tool_uses": [
                            {
                                "name": "set_device_status",
                                "args": {
                                    "location": "living room",
                                    "device_id": "floor lamp",
                                    "status": "ON",
                                },
                            }
                        ]
                    },
                }
            ],
        },
        {
            "eval_id": "kitchen_on_off_sequence",
            "conversation": [
                {
                    "user_content": {
                        "parts": [{"text": "Switch on the main light in the kitchen."}]
                    },
                    "final_response": {
                        "parts": [
                            {
                                "text": "Successfully set the main light in the kitchen to on."
                            }
                        ]
                    },
                    "intermediate_data": {
                        "tool_uses": [
                            {
                                "name": "set_device_status",
                                "args": {
                                    "location": "kitchen",
                                    "device_id": "main light",
                                    "status": "ON",
                                },
                            }
                        ]
                    },
                }
            ],
        },
    ],
}
```



```python
import json

with open("home_automation_agent/integration.evalset.json", "w") as f:
    json.dump(test_cases, f, indent=2)

print("âœ… Evaluation test cases created")
print("\nðŸ§ª Test scenarios:")
for case in test_cases["eval_cases"]:
    user_msg = case["conversation"][0]["user_content"]["parts"][0]["text"]
    print(f"â€¢ {case['eval_id']}: {user_msg}")

print("\nðŸ“Š Expected results:")
print("â€¢ basic_device_control: Should pass both criteria")
print(
    "â€¢ wrong_tool_usage_test: May fail tool_trajectory if agent uses wrong parameters"
)
print(
    "â€¢ poor_response_quality_test: May fail response_match if response differs too much"
)
```

```python
print("ðŸš€ Run this command to execute evaluation:")
!adk eval home_automation_agent home_automation_agent/integration.evalset.json --config_file_path=home_automation_agent/test_config.json --print_detailed_results
```

## Day5a Agent2Agent Communication 

æœ¬æ–‡æ—¨åœ¨æ•™å­¦å¦‚ä½•æž„å»ºå¤šæ™ºèƒ½ä½“ç³»ç»Ÿï¼Œä¸åŒçš„æ™ºèƒ½ä½“ä¹‹é—´å¯ä»¥é€šè¿‡**A2A Protocol**ç›¸äº’äº¤æµã€‚

- ç†è§£A2A protocolä»¥åŠå¦‚ä½•æŠ‰æ‹©æ¬¡æ™ºèƒ½ä½“ä»¥åŠA2Açš„ä½¿ç”¨æ—¶é—´
- å­¦ä¹ å¸¸è§çš„A2Aæž¶æž„æ¨¡å¼ (cross-framework, cross-language, cross-organization)
- **ä½¿ç”¨ to_a2a() é€šè¿‡ A2A å…¬å¼€ ADK æ™ºèƒ½ä½“**

- **ä½¿ç”¨ RemoteA2aAgent è°ƒç”¨è¿œç¨‹æ™ºèƒ½ä½“**

- **æž„å»ºäº§å“ç›®å½•é›†æˆç³»ç»Ÿ**

---

**å¤æ‚æ™ºèƒ½ä½“é¢ä¸´çš„é—®é¢˜**ï¼š

- å•ä¸ªæ™ºèƒ½ä½“æ— æ³•å¤„ç†æ‰€æœ‰ä»»åŠ¡ - ä¸ºä¸åŒé¢†åŸŸè®¾è®¡çš„ä¸“ä¸šæ™ºèƒ½ä½“è¡¨çŽ°æ›´ä½³
- æ™ºèƒ½ä½“ä¹‹é—´éœ€è¦ååŒåˆä½œ - å®¢æˆ·æœåŠ¡éœ€è¦äº§å“æ•°æ®ï¼Œè®¢å•ç³»ç»Ÿéœ€è¦åº“å­˜ä¿¡æ¯
- ä¸åŒå›¢é˜Ÿå¼€å‘ä¸åŒçš„æ™ºèƒ½ä½“ - æ‚¨å¯èƒ½éœ€è¦é›†æˆå¤–éƒ¨ä¾›åº”å•†çš„æ™ºèƒ½ä½“
- æ™ºèƒ½ä½“å¯èƒ½ä½¿ç”¨ä¸åŒçš„è¯­è¨€/æ¡†æž¶ - æ‚¨éœ€è¦ä¸€ä¸ªæ ‡å‡†çš„é€šä¿¡åè®®

![](./Image/a2a_01.png)

- è·¨æ¡†æž¶é›†æˆï¼šADK æ™ºèƒ½ä½“ä¸Žå…¶ä»–æ™ºèƒ½ä½“æ¡†æž¶é€šä¿¡
- è·¨è¯­è¨€é€šä¿¡ï¼šPython æ™ºèƒ½ä½“è°ƒç”¨ Java æˆ– Node.js æ™ºèƒ½ä½“
- è·¨ç»„ç»‡è¾¹ç•Œï¼šæ‚¨çš„å†…éƒ¨æ™ºèƒ½ä½“ä¸Žå¤–éƒ¨ä¾›åº”å•†æœåŠ¡é›†æˆ

æˆ‘ä»¬å°†æž„å»ºä¸€ä¸ªå®žç”¨çš„ç”µå•†é›†æˆç³»ç»Ÿï¼š

1. **äº§å“ç›®å½•æ™ºèƒ½ä½“**ï¼ˆé€šè¿‡A2Aå…¬å¼€ï¼‰- å¤–éƒ¨ä¾›åº”å•†æœåŠ¡ï¼Œæä¾›äº§å“ä¿¡æ¯
2. **å®¢æˆ·æ”¯æŒæ™ºèƒ½ä½“**ï¼ˆæ¶ˆè´¹è€…ï¼‰- æ‚¨çš„å†…éƒ¨æ™ºèƒ½ä½“ï¼Œé€šè¿‡æŸ¥è¯¢äº§å“æ•°æ®å¸®åŠ©å®¢æˆ·

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ å®¢æˆ·æ”¯æŒæ™ºèƒ½ä½“         â”‚  â”€A2Aâ”€â”€â–¶  â”‚ äº§å“ç›®å½•æ™ºèƒ½ä½“         â”‚
â”‚ ï¼ˆæ¶ˆè´¹è€…ï¼‰            â”‚            â”‚ ï¼ˆä¾›åº”å•†ï¼‰            â”‚
â”‚ æ‚¨çš„å…¬å¸              â”‚           â”‚ å¤–éƒ¨æœåŠ¡              â”‚
â”‚ (localhost:8000)     â”‚           â”‚ (localhost:8001)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**ä¸ºä»€ä¹ˆé‡‡ç”¨A2Aï¼š**

- äº§å“ç›®å½•ç”±å¤–éƒ¨ä¾›åº”å•†ç»´æŠ¤ï¼ˆæ‚¨æ— æ³•ä¿®æ”¹å…¶ä»£ç ï¼‰
- ä¸åŒç»„ç»‡æ‹¥æœ‰ç‹¬ç«‹çš„ç³»ç»Ÿ
- æœåŠ¡ä¹‹é—´éœ€è¦æ­£å¼çš„å¥‘çº¦/åè®®
- äº§å“ç›®å½•å¯èƒ½ä½¿ç”¨ä¸åŒçš„è¯­è¨€/æ¡†æž¶

------

**ðŸ’¡ A2A VS æœ¬åœ°å­æ™ºèƒ½ä½“ï¼šå†³ç­–è¡¨**

==**A2AæœåŠ¡ä¸€èˆ¬ç”¨äºŽä¸åŒçš„ç»„ç»‡ã€æœåŠ¡ã€æ¡†æž¶ç­‰ç­‰ã€‚æœ¬åœ°å­æ™ºèƒ½ä½“æœåŠ¡éœ€è¦è¾ƒé«˜çš„ä¸€è‡´æ€§åŠä½Žå»¶è¿Ÿã€‚**==

| å› ç´        | ä½¿ç”¨ A2A             | ä½¿ç”¨æœ¬åœ°å­æ™ºèƒ½ä½“ |
| ---------- | -------------------- | ---------------- |
| æ™ºèƒ½ä½“ä½ç½® | å¤–éƒ¨æœåŠ¡ï¼Œä¸åŒä»£ç åº“ | åŒä¸€ä»£ç åº“ï¼Œå†…éƒ¨ |
| æ‰€æœ‰æƒ     | ä¸åŒå›¢é˜Ÿ/ç»„ç»‡        | æ‚¨çš„å›¢é˜Ÿ         |
| ç½‘ç»œ       | ä¸åŒæœºå™¨ä¸Šçš„æ™ºèƒ½ä½“   | åŒä¸€è¿›ç¨‹/æœºå™¨    |
| æ€§èƒ½       | ç½‘ç»œå»¶è¿Ÿå¯æŽ¥å—       | éœ€è¦ä½Žå»¶è¿Ÿ       |
| è¯­è¨€/æ¡†æž¶  | éœ€è¦è·¨è¯­è¨€/æ¡†æž¶      | ç›¸åŒè¯­è¨€         |
| å¥‘çº¦       | éœ€è¦æ­£å¼APIå¥‘çº¦      | å†…éƒ¨æŽ¥å£         |
| ç¤ºä¾‹       | å¤–éƒ¨ä¾›åº”å•†äº§å“ç›®å½•   | å†…éƒ¨è®¢å•å¤„ç†æ­¥éª¤ |

------

**ðŸ“ æ•™ç¨‹èƒŒæ™¯**

åœ¨æœ¬æ•™ç¨‹ä¸­ï¼Œä¸ºå­¦ä¹ ç›®çš„ï¼Œæˆ‘ä»¬å°†åœ¨æœ¬åœ°æ¨¡æ‹Ÿè¿™ä¸¤ä¸ªæ™ºèƒ½ä½“ï¼ˆéƒ½è¿è¡Œåœ¨æœ¬åœ°ä¸»æœºä¸Šï¼‰ã€‚åœ¨å®žé™…ç”Ÿäº§çŽ¯å¢ƒä¸­ï¼š

- äº§å“ç›®å½•æ™ºèƒ½ä½“ä¼šè¿è¡Œåœ¨ä¾›åº”å•†çš„åŸºç¡€è®¾æ–½ä¸Šï¼ˆä¾‹å¦‚ https://vendor.comï¼‰
- å®¢æˆ·æ”¯æŒæ™ºèƒ½ä½“ä¼šè¿è¡Œåœ¨æ‚¨çš„åŸºç¡€è®¾æ–½ä¸Š
- å®ƒä»¬å°†é€šè¿‡äº’è”ç½‘ä½¿ç”¨A2Aåè®®è¿›è¡Œé€šä¿¡

è¿™ç§æœ¬åœ°æ¨¡æ‹Ÿè®©æ‚¨æ— éœ€éƒ¨ç½²å®žé™…æœåŠ¡å°±èƒ½å­¦ä¹ A2Aï¼

![](./Image/a2a_02.png)

**å·¥ä½œåŽŸç†ï¼š**

1. **å®¢æˆ·å’¨è¯¢** â†’ å®¢æˆ·å‘æ‚¨çš„å®¢æˆ·æ”¯æŒæ™ºèƒ½ä½“æå‡ºäº§å“ç›¸å…³é—®é¢˜
2. **è¯†åˆ«éœ€æ±‚** â†’ æ”¯æŒæ™ºèƒ½ä½“æ„è¯†åˆ°éœ€è¦èŽ·å–äº§å“ä¿¡æ¯
3. **è¿œç¨‹è°ƒç”¨** â†’ æ”¯æŒæ™ºèƒ½ä½“é€šè¿‡A2Aåè®®è°ƒç”¨äº§å“ç›®å½•æ™ºèƒ½ä½“
4. **èŽ·å–æ•°æ®** â†’ äº§å“ç›®å½•æ™ºèƒ½ä½“ï¼ˆå¤–éƒ¨ä¾›åº”å•†ï¼‰è¿”å›žäº§å“æ•°æ®
5. **æ•´åˆå“åº”** â†’ æ”¯æŒæ™ºèƒ½ä½“æ•´åˆä¿¡æ¯å¹¶å½¢æˆæœ€ç»ˆå›žç­”
6. **å›žå¤å®¢æˆ·** â†’ æ”¯æŒæ™ºèƒ½ä½“å°†å›žç­”è¿”å›žç»™å®¢æˆ·

```py
å®¢æˆ·: "åŽä¸ºP70 Proæ‰‹æœºæœ‰çŽ°è´§å—ï¼Ÿä»·æ ¼å¤šå°‘ï¼Ÿ"

æ”¯æŒæ™ºèƒ½ä½“: ï¼ˆåˆ†æžè¯·æ±‚ï¼‰
    â†’ è¯†åˆ«éœ€è¦æŸ¥è¯¢äº§å“åº“å­˜å’Œä»·æ ¼
    â†’ é€šè¿‡A2Aè°ƒç”¨äº§å“ç›®å½•æœåŠ¡
    â†’ å‘é€è¯·æ±‚ï¼š"æŸ¥è¯¢åŽä¸ºP70 Proåº“å­˜çŠ¶æ€å’Œä»·æ ¼"

äº§å“ç›®å½•æ™ºèƒ½ä½“: ï¼ˆæŽ¥æ”¶è¯·æ±‚ï¼‰
    â†’ æŸ¥è¯¢æ•°æ®åº“
    â†’ è¿”å›žï¼š{"äº§å“": "åŽä¸ºP70 Pro", "åº“å­˜": 15, "ä»·æ ¼": 6999, "çŠ¶æ€": "åœ¨å”®"}

æ”¯æŒæ™ºèƒ½ä½“: ï¼ˆæ•´åˆä¿¡æ¯ï¼‰
    â†’ ç»„ç»‡å›žç­”
    â†’ å›žå¤å®¢æˆ·ï¼š"åŽä¸ºP70 Proç›®å‰æœ‰15å°çŽ°è´§ï¼Œå”®ä»·6999å…ƒã€‚"

å®¢æˆ·: "è°¢è°¢ï¼Œæˆ‘æƒ³è®¢è´­ä¸€å°ã€‚"
```

**ðŸ—ºï¸ æ•™ç¨‹æ­¥éª¤**

åœ¨æœ¬æ•™ç¨‹ä¸­ï¼Œæ‚¨å°†å®Œæˆä»¥ä¸‹6ä¸ªæ­¥éª¤ï¼š

1. **åˆ›å»ºäº§å“ç›®å½•æ™ºèƒ½ä½“** - æž„å»ºä¾›åº”å•†çš„äº§å“æŸ¥è¯¢æ™ºèƒ½ä½“
2. **é€šè¿‡A2Aå…¬å¼€** - ä½¿ç”¨ `to_a2a()`ä½¿å…¶å¯è®¿é—®
3. **å¯åŠ¨æœåŠ¡å™¨** - å°†æ™ºèƒ½ä½“ä½œä¸ºåŽå°æœåŠ¡è¿è¡Œ
4. **åˆ›å»ºå®¢æˆ·æ”¯æŒæ™ºèƒ½ä½“** - æž„å»ºæ¶ˆè´¹è€…æ™ºèƒ½ä½“
5. **æµ‹è¯•é€šä¿¡** - é€šè¿‡å®žé™…æŸ¥è¯¢æŸ¥çœ‹A2Açš„è¿è¡Œæ•ˆæžœ
6. **ç†è§£æµç¨‹** - äº†è§£èƒŒåŽçš„è¿è¡Œæœºåˆ¶

```py
import os
from kaggle_secrets import UserSecretsClient

try:
    GOOGLE_API_KEY = UserSecretsClient().get_secret("GOOGLE_API_KEY")
    os.environ["GOOGLE_API_KEY"] = GOOGLE_API_KEY
    print("âœ… Setup and authentication complete.")
except Exception as e:
    print(
        f"ðŸ”‘ Authentication Error: Please make sure you have added 'GOOGLE_API_KEY' to your Kaggle secrets. Details: {e}"
    )
```

```py
import json
import requests
import subprocess
import time
import uuid

from google.adk.agents import LlmAgent
from google.adk.agents.remote_a2a_agent import (
    RemoteA2aAgent,
    AGENT_CARD_WELL_KNOWN_PATH,
)

from google.adk.a2a.utils.agent_to_a2a import to_a2a
from google.adk.models.google_llm import Gemini
from google.adk.runners import Runner
from google.adk.sessions import InMemorySessionService
from google.genai import types

# Hide additional warnings in the notebook
import warnings

warnings.filterwarnings("ignore")

print("âœ… ADK components imported successfully.")
```

```py
retry_config = types.HttpRetryOptions(
    attempts=5,  # Maximum retry attempts
    exp_base=7,  # Delay multiplier
    initial_delay=1,
    http_status_codes=[429, 500, 503, 504],  # Retry on these HTTP errors
)
```

