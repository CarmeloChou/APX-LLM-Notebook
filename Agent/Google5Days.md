# Google 5 Days AI Agents Intensive Course

https://www.kaggle.com/code/kaggle5daysofai/day-2a-agent-tools

## Day1 ä»‹ç»ADKåŸºæœ¬è°ƒç”¨

ä¸»è¦ä»‹ç»apiè°ƒç”¨æ–¹æ³•ï¼Œå°è¯•ä½¿ç”¨google searchçš„toolæ¥è§£å†³å¤§æ¨¡åž‹çš„å®žæ—¶æ€§é—®é¢˜ã€‚

## Day1b agentæž¶æž„

å¤šagent ç³»ç»Ÿ

```python
# Research Agent: Its job is to use the google_search tool and present findings.
research_agent = Agent(
    name="ResearchAgent",
    model=Gemini(
        model="gemini-2.5-flash-lite",
        retry_options=retry_config
    ),
    instruction="""You are a specialized research agent. Your only job is to use the
    google_search tool to find 2-3 pieces of relevant information on the given topic and present the findings with citations.""",
    tools=[google_search],
    output_key="research_findings",  # The result of this agent will be stored in the session state with this key.
)

print("âœ… research_agent created.")
```

```python
# Summarizer Agent: Its job is to summarize the text it receives.
summarizer_agent = Agent(
    name="SummarizerAgent",
    model=Gemini(
        model="gemini-2.5-flash-lite",
        retry_options=retry_config
    ),
    # The instruction is modified to request a bulleted list for a clear output format.
    instruction="""Read the provided research findings: {research_findings}
Create a concise summary as a bulleted list with 3-5 key points.""",
    output_key="final_summary",
)

print("âœ… summarizer_agent created.")
```

æ ¹agent

```pyhton
# Root Coordinator: Orchestrates the workflow by calling the sub-agents as tools.
root_agent = Agent(
    name="ResearchCoordinator",
    model=Gemini(
        model="gemini-2.5-flash-lite",
        retry_options=retry_config
    ),
    # This instruction tells the root agent HOW to use its tools (which are the other agents).
    instruction="""You are a research coordinator. Your goal is to answer the user's query by orchestrating a workflow.
1. First, you MUST call the `ResearchAgent` tool to find relevant information on the topic provided by the user.
2. Next, after receiving the research findings, you MUST call the `SummarizerAgent` tool to create a concise summary.
3. Finally, present the final summary clearly to the user as your response.""",
    # We wrap the sub-agents in `AgentTool` to make them callable tools for the root agent.
    tools=[AgentTool(research_agent), AgentTool(summarizer_agent)],
)

print("âœ… root_agent created.")
```

### ä¸²è¡Œå·¥ä½œæµ

![](./Image/sequential-agent.png)

```py
# Outline Agent: Creates the initial blog post outline.
outline_agent = Agent(
    name="OutlineAgent",
    model=Gemini(
        model="gemini-2.5-flash-lite",
        retry_options=retry_config
    ),
    instruction="""Create a blog outline for the given topic with:
    1. A catchy headline
    2. An introduction hook
    3. 3-5 main sections with 2-3 bullet points for each
    4. A concluding thought""",
    output_key="blog_outline",  # The result of this agent will be stored in the session state with this key.
)

print("âœ… outline_agent created.")
```

```py
# Writer Agent: Writes the full blog post based on the outline from the previous agent.
writer_agent = Agent(
    name="WriterAgent",
    model=Gemini(
        model="gemini-2.5-flash-lite",
        retry_options=retry_config
    ),
    # The `{blog_outline}` placeholder automatically injects the state value from the previous agent's output.
    instruction="""Following this outline strictly: {blog_outline}
    Write a brief, 200 to 300-word blog post with an engaging and informative tone.""",
    output_key="blog_draft",  # The result of this agent will be stored with this key.
)

print("âœ… writer_agent created.")
```

```py
# Editor Agent: Edits and polishes the draft from the writer agent.
editor_agent = Agent(
    name="EditorAgent",
    model=Gemini(
        model="gemini-2.5-flash-lite",
        retry_options=retry_config
    ),
    # This agent receives the `{blog_draft}` from the writer agent's output.
    instruction="""Edit this draft: {blog_draft}
    Your task is to polish the text by fixing any grammatical errors, improving the flow and sentence structure, and enhancing overall clarity.""",
    output_key="final_blog",  # This is the final output of the entire pipeline.
)

print("âœ… editor_agent created.")
```

```py
root_agent = SequentialAgent(
    name="BlogPipeline",
    sub_agents=[outline_agent, writer_agent, editor_agent],
)

print("âœ… Sequential Agent created.")
```

```py
runner = InMemoryRunner(agent=root_agent)
response = await runner.run_debug(
    "Write a blog post about the benefits of multi-agent systems for software developers"
)
```



### å¹¶è¡Œå·¥ä½œæµ

![](./Image/parallel-agent.png)

```python
# Tech Researcher: Focuses on AI and ML trends.
tech_researcher = Agent(
    name="TechResearcher",
    model=Gemini(
        model="gemini-2.5-flash-lite",
        retry_options=retry_config
    ),
    instruction="""Research the latest AI/ML trends. Include 3 key developments,
the main companies involved, and the potential impact. Keep the report very concise (100 words).""",
    tools=[google_search],
    output_key="tech_research",  # The result of this agent will be stored in the session state with this key.
)

print("âœ… tech_researcher created.")
```

```py
# Health Researcher: Focuses on medical breakthroughs.
health_researcher = Agent(
    name="HealthResearcher",
    model=Gemini(
        model="gemini-2.5-flash-lite",
        retry_options=retry_config
    ),
    instruction="""Research recent medical breakthroughs. Include 3 significant advances,
their practical applications, and estimated timelines. Keep the report concise (100 words).""",
    tools=[google_search],
    output_key="health_research",  # The result will be stored with this key.
)

print("âœ… health_researcher created.")
```

```python
# Finance Researcher: Focuses on fintech trends.
finance_researcher = Agent(
    name="FinanceResearcher",
    model=Gemini(
        model="gemini-2.5-flash-lite",
        retry_options=retry_config
    ),
    instruction="""Research current fintech trends. Include 3 key trends,
their market implications, and the future outlook. Keep the report concise (100 words).""",
    tools=[google_search],
    output_key="finance_research",  # The result will be stored with this key.
)

print("âœ… finance_researcher created.")
```

```python
# The AggregatorAgent runs *after* the parallel step to synthesize the results.
aggregator_agent = Agent(
    name="AggregatorAgent",
    model=Gemini(
        model="gemini-2.5-flash-lite",
        retry_options=retry_config
    ),
    # It uses placeholders to inject the outputs from the parallel agents, which are now in the session state.
    instruction="""Combine these three research findings into a single executive summary:

    **Technology Trends:**
    {tech_research}
    
    **Health Breakthroughs:**
    {health_research}
    
    **Finance Innovations:**
    {finance_research}
    
    Your summary should highlight common themes, surprising connections, and the most important key takeaways from all three reports. The final summary should be around 200 words.""",
    output_key="executive_summary",  # This will be the final output of the entire system.
)

print("âœ… aggregator_agent created.")
```

### å¾ªçŽ¯å·¥ä½œæµ

![](./Image/loop-agent.png)

1. **Writer Agent** - Writes a draft of a short story
2. **Critic Agent** - Reviews and critiques the short story to suggest improvements

```py
# This agent runs ONCE at the beginning to create the first draft.
initial_writer_agent = Agent(
    name="InitialWriterAgent",
    model=Gemini(
        model="gemini-2.5-flash-lite",
        retry_options=retry_config
    ),
    instruction="""Based on the user's prompt, write the first draft of a short story (around 100-150 words).
    Output only the story text, with no introduction or explanation.""",
    output_key="current_story",  # Stores the first draft in the state.
)

print("âœ… initial_writer_agent created.")
```

```py
# This agent's only job is to provide feedback or the approval signal. It has no tools.
critic_agent = Agent(
    name="CriticAgent",
    model=Gemini(
        model="gemini-2.5-flash-lite",
        retry_options=retry_config
    ),
    instruction="""You are a constructive story critic. Review the story provided below.
    Story: {current_story}
    
    Evaluate the story's plot, characters, and pacing.
    - If the story is well-written and complete, you MUST respond with the exact phrase: "APPROVED"
    - Otherwise, provide 2-3 specific, actionable suggestions for improvement.""",
    output_key="critique",  # Stores the feedback in the state.
)

print("âœ… critic_agent created.")
```

```py
# This is the function that the RefinerAgent will call to exit the loop.
def exit_loop():
    """Call this function ONLY when the critique is 'APPROVED', indicating the story is finished and no more changes are needed."""
    return {"status": "approved", "message": "Story approved. Exiting refinement loop."}


print("âœ… exit_loop function created.")
```

```py
# This agent refines the story based on critique OR calls the exit_loop function.
refiner_agent = Agent(
    name="RefinerAgent",
    model=Gemini(
        model="gemini-2.5-flash-lite",
        retry_options=retry_config
    ),
    instruction="""You are a story refiner. You have a story draft and critique.
    
    Story Draft: {current_story}
    Critique: {critique}
    
    Your task is to analyze the critique.
    - IF the critique is EXACTLY "APPROVED", you MUST call the `exit_loop` function and nothing else.
    - OTHERWISE, rewrite the story draft to fully incorporate the feedback from the critique.""",
    output_key="current_story",  # It overwrites the story with the new, refined version.
    tools=[
        FunctionTool(exit_loop)
    ],  # The tool is now correctly initialized with the function reference.
)

print("âœ… refiner_agent created.")
```

```py
# The LoopAgent contains the agents that will run repeatedly: Critic -> Refiner.
story_refinement_loop = LoopAgent(
    name="StoryRefinementLoop",
    sub_agents=[critic_agent, refiner_agent],
    max_iterations=2,  # Prevents infinite loops
)

# The root agent is a SequentialAgent that defines the overall workflow: Initial Write -> Refinement Loop.
root_agent = SequentialAgent(
    name="StoryPipeline",
    sub_agents=[initial_writer_agent, story_refinement_loop],
)

print("âœ… Loop and Sequential Agents created.")
```

```py
runner = InMemoryRunner(agent=root_agent)
response = await runner.run_debug(
    "Write a short story about a lighthouse keeper who discovers a mysterious, glowing map"
)
```



## Day2 ä»‹ç»agent tools

Toolå®šä¹‰ï¼š

- python å‡½æ•°

  - å­—å…¸è¿”å›žå€¼ï¼š{â€œstatusâ€: â€œsuccessâ€, â€œdataâ€: ...} or {â€œstatusâ€: â€œerrorâ€, â€œerror_messageâ€:...}
  - æ¸…æ™°çš„æŒ‡ä»¤ï¼šllmä½¿ç”¨æ¸…æ™°çš„æŒ‡ä»¤åŽ»ç†è§£åº”è¯¥è°ƒç”¨ä»€ä¹ˆtools
  - æš—ç¤ºæŒ‡ä»¤ï¼šè®©adkç”Ÿæˆåˆé€‚çš„ç›®æ ‡æ ¼å¼ï¼ˆstrã€dictã€etcï¼‰
  - é”™è¯¯å¤„ç†ï¼šç»“æž„åŒ–é”™è¯¯å“åº”å¸®åŠ©LLMåˆé€‚å¤„ç†é”™è¯¯

  ```python
  def get_fee_for_payment_method(method: str) -> dict:
      fee_database = {
          "platinum credit card": 0.02,  # 2%
          "gold debit card": 0.035,  # 3.5%
          "bank transfer": 0.01,  # 1%
      }
      
      fee = fee_database.get(method.lower())
      if fee is not None:
          return {"status": "success", "fee_percentage": fee}
      else:`
          return {
              "status": "error",
              "error_message": f"Payment method '{method}' not found",
          }
          
  print("âœ… Fee lookup function created")
  print(f"ðŸ’³ Test: {get_fee_for_payment_method('platinum credit card')}")
  
  ```

  ```python
  def get_exchange_rate(base_currency: str, target_currency: str) -> dict:
      """Looks up and returns the exchange rate between two currencies.
  
      Args:
          base_currency: The ISO 4217 currency code of the currency you
                         are converting from (e.g., "USD").
          target_currency: The ISO 4217 currency code of the currency you
                           are converting to (e.g., "EUR").
  
      Returns:
          Dictionary with status and rate information.
          Success: {"status": "success", "rate": 0.93}
          Error: {"status": "error", "error_message": "Unsupported currency pair"}
      """
  
      # Static data simulating a live exchange rate API
      # In production, this would call something like: requests.get("api.exchangerates.com")
      rate_database = {
          "usd": {
              "eur": 0.93,  # Euro
              "jpy": 157.50,  # Japanese Yen
              "inr": 83.58,  # Indian Rupee
          }
      }
  
      # Input validation and processing
      base = base_currency.lower()
      target = target_currency.lower()
  
      # Return structured result with status
      rate = rate_database.get(base, {}).get(target)
      if rate is not None:
          return {"status": "success", "rate": rate}
      else:
          return {
              "status": "error",
              "error_message": f"Unsupported currency pair: {base_currency}/{target_currency}",
          }
  
  
  print("âœ… Exchange rate function created")
  print(f"ðŸ’± Test: {get_exchange_rate('USD', 'EUR')}")
  ```

  Now let's create our currency agent. Pay attention to how the agent's instructions reference the tools:

  **Key Points:**

  - The `tools=[]` list tells the agent which functions it can use
  - Instructions reference tools by their exact function names (e.g., `get_fee_for_payment_method()`)
  - The agent uses these names to decide when and how to call each tool

  ```python
  # Currency agent with custom function tools
  currency_agent = LlmAgent(
      name="currency_agent",
      model=Gemini(model="gemini-2.5-flash-lite", retry_options=retry_config),
      instruction="""You are a smart currency conversion assistant.
  
      For currency conversion requests:
      1. Use `get_fee_for_payment_method()` to find transaction fees
      2. Use `get_exchange_rate()` to get currency conversion rates
      3. Check the "status" field in each tool's response for errors
      4. Calculate the final amount after fees based on the output from `get_fee_for_payment_method` and `get_exchange_rate` methods and provide a clear breakdown.
      5. First, state the final converted amount.
          Then, explain how you got that result by showing the intermediate amounts. Your explanation must include: the fee percentage and its
          value in the original currency, the amount remaining after the fee, and the exchange rate used for the final conversion.
  
      If any tool returns status "error", explain the issue to the user clearly.
      """,
      tools=[get_fee_for_payment_method, get_exchange_rate],
  )
  
  print("âœ… Currency agent created with custom function tools")
  print("ðŸ”§ Available tools:")
  print("  â€¢ get_fee_for_payment_method - Looks up company fee structure")
  print("  â€¢ get_exchange_rate - Gets current exchange rates")
  ```

  LLMså¤§å¤šä¸æ“…é•¿è®¡ç®—ï¼Œéœ€è¦è°ƒç”¨python codeç¡®ä¿ç»“æžœæ­£ç¡®ã€‚

  ```python
  calculation_agent = LlmAgent(
      name="CalculationAgent",
      model=Gemini(model="gemini-2.5-flash-lite", retry_options=retry_config),
      instruction="""You are a specialized calculator that ONLY responds with Python code. You are forbidden from providing any text, explanations, or conversational responses.
   
       Your task is to take a request for a calculation and translate it into a single block of Python code that calculates the answer.
       
       **RULES:**
      1.  Your output MUST be ONLY a Python code block.
      2.  Do NOT write any text before or after the code block.
      3.  The Python code MUST calculate the result.
      4.  The Python code MUST print the final result to stdout.
      5.  You are PROHIBITED from performing the calculation yourself. Your only job is to generate the code that will perform the calculation.
     
      Failure to follow these rules will result in an error.
         """,
      code_executor=BuiltInCodeExecutor(),  # Use the built-in Code Executor Tool. This gives the agent code execution capabilities
  )
  ```

  Agent Tools å’Œ Sub-Agentsçš„åŒºåˆ«

  Agent Toolsï¼šAè°ƒç”¨Bä½œä¸ºå·¥å…·ï¼›Bçš„åº”ç­”è¿”å›žAï¼›Aä¿æŒåŽŸæœ‰å¯¹è¯ï¼›

  Sub-Agentsï¼šAå°†æŽ§åˆ¶æƒå®Œå…¨è½¬ç§»ç»™Bï¼›BæŽ¥æ”¶å¹¶å¤„ç†æœªæ¥çš„ç”¨æˆ·è¾“å…¥ï¼›Aé€€å‡ºå¾ªçŽ¯

### ADK tool ç±»åž‹

- è‡ªå®šä¹‰å·¥å…·ï¼šä¸ºç‰¹å®šéœ€è¦æž„å»ºçš„è‡ªå®šä¹‰å·¥å…·
  - å‡½æ•°å·¥å…·ï¼špythonå‡½æ•°
  - é•¿æœŸå‡½æ•°å·¥å…·ï¼šç‰¹å®šæ—¶é—´ä½¿ç”¨çš„å‡½æ•°æ“ä½œï¼Œå¦‚æ–‡ä»¶æ“ä½œ
  - ä»£ç†å·¥å…·ï¼šå…¶ä»–çš„ä»£ç†
  - MCPå·¥å…·ï¼šMCPæœåŠ¡ä¸­çš„å·¥å…·
  - OpenAPIå·¥å…·ï¼šç‰¹å®šAPIä¸­ç”Ÿæˆçš„å·¥å…·

![](D:\001-Coding\DATA\APX-LLM-Notebook\Agent\Image\custom_tool.JPG)

- åµŒå…¥å·¥å…·ï¼šADKä¸­å·²ç»åµŒå…¥çš„å·¥å…·
  - Gemini  Tools: æå‡Geminièƒ½åŠ›çš„å·¥å…·ï¼Œå¦‚google_research
  - è°·æ­Œäº‘å·¥å…·: google äº‘æ•´åˆçš„å·¥å…·
  - ç¬¬ä¸‰æ–¹å·¥å…·ï¼šçŽ°æœ‰çš„å·¥å…·ç”Ÿæ€ä½“ç³»

![](./Image/build_in.jpg)

### MCP

é“¾æŽ¥å¤–éƒ¨ç³»ç»Ÿçš„ç¤¾åŒºå·¥å…·é›†çš„å¼€æºæ ‡å‡†ã€‚å¯ä»¥å®žçŽ°ï¼š

- ä»Žæ•°æ®åº“ã€apisã€æœåŠ¡ä¸­è®¿é—®å®žæ—¶çš„å¤–éƒ¨æ•°æ®
- é€šè¿‡æ ‡å‡†æŽ¥å£ä½¿ç”¨ç¤¾åŒºæž„å»ºçš„å·¥å…·
- é€šè¿‡é“¾æŽ¥å¤šç§ç‰¹åˆ¶æœåŠ¡æ¥å¢žå¼ºæ¨¡åž‹èƒ½åŠ›

MCPå¦‚ä½•å‘æŒ¥ä½œç”¨ï¼šå°†è‡ªå·±çš„ä»£ç†è¿žæŽ¥åˆ°å¤–éƒ¨å¯æä¾›å·¥å…·çš„MCPæœåŠ¡ã€‚

- MCPæœåŠ¡ï¼šæä¾›ç‰¹å®šå·¥å…·ï¼Œå¦‚å›¾ç‰‡ç”Ÿæˆã€æ•°æ®åº“è®¿é—®
- MCPä»£ç†ï¼šä½¿ç”¨è¿™äº›å·¥å…·çš„è‡ªå·±çš„agent
- æ‰€æœ‰æœåŠ¡å·¥ä½œæ–¹å¼ç›¸åŒï¼šæ ‡å‡†äº¤äº’æŽ¥å£
- æ¨¡åž‹æž¶æž„![](./Image/MCP_architecture.jpg)

____

**1. æŒ‘é€‰MCPæœåŠ¡**

æœ¬æ¬¡demoä½¿ç”¨Everything MCP Serverâ€”â€”ä¸€ä¸ªä¸ºMCPè®¾è®¡çš„npmåº“ï¼Œæä¾›getTinyImageå·¥å…·ï¼Œè¿”å›žç®€å•çš„æµ‹è¯•å›¾åƒã€‚è¿˜å¯ä»¥ä½¿ç”¨å…¶ä»–çš„MCPæœåŠ¡ï¼Œæ¯”å¦‚è°·æ­Œåœ°å›¾ã€Slcakã€DIscordç­‰ç­‰ã€‚

**2. åˆ›å»ºMCPå·¥å…·é›†**

MCPå·¥å…·é›†ç”¨æ¥æ•´åˆä½¿ç”¨MCPæœåŠ¡çš„ADKä»£ç†ã€‚ä½¿ç”¨npxï¼ˆNode package runnerï¼‰è¿è¡ŒMCPæœåŠ¡ã€é“¾æŽ¥åˆ°@modelcontextprotocol/server-everythingã€ä»…ä½¿ç”¨getTInyImageå·¥å…·ã€‚

```python
# MCP integration with Everything Server
mcp_image_server = McpToolset(
    connection_params=StdioConnectionParams(
        server_params=StdioServerParameters(
            command="npx",  # Run MCP server via npx
            args=[
                "-y",  # Argument for npx to auto-confirm install
                "@modelcontextprotocol/server-everything",
            ],
            tool_filter=["getTinyImage"],
        ),
        timeout=30,
    )
)

print("âœ… MCP Tool created")
```

èƒŒåŽçš„é€»è¾‘ï¼š

1. æœåŠ¡å¯åŠ¨:ADK runs `npx -y @modelcontextprotocol/server-everything`
2. å»ºç«‹è¿žæŽ¥:Establishes stdio communication channel
3. å·¥å…·æ£€ç´¢:Server tells ADK: "I provide getTinyImage" functionality
4. æ•´åˆ:Tools appear in agent's tool list automatically
5. è¿è¡Œ: When agent calls `getTinyImage()`, ADK forwards to MCP server
6. åº”ç­”:Server result is returned to agent seamlessly

**3. å°†MCPå·¥å…·æ•´åˆåˆ°ä»£ç†ä¸­**

## DAY3 a-ä¼šè¯

ä¼šè¯æ˜¯å¯¹è¯çš„å®¹å™¨ï¼Œå®ƒä»¥**æ—¶é—´é¡ºåº**å°è£…å¯¹è¯åŽ†å²ï¼Œå¹¶è®°å½•å•ä¸ªè¿žç»­å¯¹è¯ä¸­çš„æ‰€æœ‰å·¥å…·äº¤äº’å’Œå“åº”ã€‚ä¼šè¯ä¸Ž**ç‰¹å®šç”¨æˆ·å’Œæ™ºèƒ½ä½“**ç»‘å®šï¼Œä¸ä¸Žå…¶ä»–ç”¨æˆ·å…±äº«ã€‚åŒæ ·ï¼Œä¸€ä¸ªæ™ºèƒ½ä½“çš„ä¼šè¯åŽ†å²ä¹Ÿ**ä¸ä¸Žå…¶ä»–æ™ºèƒ½ä½“å…±äº«**ã€‚

**ä¼šè¯äº‹ä»¶ï¼ˆSession.Eventsï¼‰**

è™½ç„¶ä¼šè¯æ˜¯å¯¹è¯çš„å®¹å™¨ï¼Œä½†**äº‹ä»¶**æ‰æ˜¯å¯¹è¯çš„æž„å»ºæ¨¡å—ã€‚

**äº‹ä»¶ç¤ºä¾‹**ï¼š

- **ç”¨æˆ·è¾“å…¥**ï¼šæ¥è‡ªç”¨æˆ·çš„æ¶ˆæ¯ï¼ˆæ–‡æœ¬ã€éŸ³é¢‘ã€å›¾åƒç­‰ï¼‰
- **æ™ºèƒ½ä½“å“åº”**ï¼šæ™ºèƒ½ä½“å¯¹ç”¨æˆ·çš„å›žå¤
- **å·¥å…·è°ƒç”¨**ï¼šæ™ºèƒ½ä½“å†³å®šä½¿ç”¨å¤–éƒ¨å·¥å…·æˆ– API
- **å·¥å…·è¾“å‡º**ï¼šä»Žå·¥å…·è°ƒç”¨è¿”å›žçš„æ•°æ®ï¼Œæ™ºèƒ½ä½“ç”¨å®ƒæ¥ç»§ç»­æŽ¨ç†

**{} ä¼šè¯çŠ¶æ€ï¼ˆSession.Stateï¼‰**

**session.state** æ˜¯æ™ºèƒ½ä½“çš„**è‰ç¨¿æœ¬**ï¼Œå®ƒå­˜å‚¨å’Œæ›´æ–°å¯¹è¯è¿‡ç¨‹ä¸­æ‰€éœ€çš„åŠ¨æ€ç»†èŠ‚ã€‚æ‚¨å¯ä»¥å°†å…¶è§†ä¸ºä¸€ä¸ªå…¨å±€çš„**{é”®, å€¼}** å¯¹å­˜å‚¨ï¼Œå¯¹æ‰€æœ‰**å­æ™ºèƒ½ä½“å’Œå·¥å…·**éƒ½å¯ç”¨ã€‚

------------

sessionå¯¹è¯å¹¶ä¸æ˜¯æ°¸ä¹…ä¿å­˜çš„ï¼Œå½“å¯¹è¯é—å¤±çš„æ—¶å€™ï¼Œæ¨¡åž‹ä¼šé—å¿˜è¿‡åŽ»çš„å¯¹è¯ã€‚ä¸ºå¼¥è¡¥è¿™ä¸ªé—®é¢˜ï¼Œéœ€è¦å€ŸåŠ©æ•°æ®åº“ã€‚ã€‚ã€‚

é€‰æ‹©æ­£ç¡®çš„sessionservice

| Service                    | Use Case              | Persistence         | Best For             |
| -------------------------- | --------------------- | ------------------- | -------------------- |
| **InMemorySessionService** | Development & Testing | âŒ Lost on restart   | Quick prototypes     |
| **DatabaseSessionService** | Self-managed apps     | âœ… Survives restarts | Small to medium apps |
| **Agent Engine Sessions**  | Production on GCP     | âœ… Fully managed     | Enterprise scale     |

ä½¿ç”¨sqliteå‡çº§databasesessionservice

```python
# Step 1: Create the same agent (notice we use LlmAgent this time)
chatbot_agent = LlmAgent(
    model=Gemini(model="gemini-2.5-flash-lite", retry_options=retry_config),
    name="text_chat_bot",
    description="A text chatbot with persistent memory",
)

# Step 2: Switch to DatabaseSessionService
# SQLite database will be created automatically
db_url = "sqlite:///my_agent_data.db"  # Local SQLite file
session_service = DatabaseSessionService(db_url=db_url)

# Step 3: Create a new runner with persistent storage
runner = Runner(agent=chatbot_agent, app_name=APP_NAME, session_service=session_service)

print("âœ… Upgraded to persistent sessions!")
print(f"   - Database: my_agent_data.db")
print(f"   - Sessions will survive restarts!")
```

ä½¿ç”¨æ•°æ®åº“ä¹‹åŽï¼Œagentå¯ä»¥è®°å½•å¯¹è¯ï¼Œä½†ä¸åŒäº‹ä»¶ä¹‹é—´ï¼Œå¯¹è¯ä¿¡æ¯æ˜¯ä¸å…±äº«ï¼Œç›¸äº’éš”ç¦»çš„

```python
await run_session(
    runner,
    ["What is the capital of India?", "Hello! What is my name?"],
    "test-db-session-01",
)
```

![](D:\001-Coding\DATA\APX-LLM-Notebook\Agent\Image\session1.JPG)

```python
await run_session(
    runner, ["Hello! What is my name?"], "test-db-session-02"
)  # Note, we are using new session name
```

![](D:\001-Coding\DATA\APX-LLM-Notebook\Agent\Image\session2.JPG)

ä¼šè¯æ•°æ®æ˜¯å¦‚ä½•å­˜å‚¨åœ¨æ•°æ®åº“ä¸­çš„ï¼Ÿ

```python
import sqlite3

def check_data_in_db():
    with sqlite3.connect("my_agent_data.db") as connection:
        cursor = connection.cursor()
        result = cursor.execute(
            "select app_name, session_id, author, content from events"
        )
        print([_[0] for _ in result.description])
        for each in result.fetchall():
            print(each)


check_data_in_db()
```

![](D:\001-Coding\DATA\APX-LLM-Notebook\Agent\Image\session3.JPG)

ä¹‹å‰çš„å¯¹è¯ä¿¡æ¯å¯ä»¥å¿«é€Ÿå­˜å‚¨åœ¨æ•°æ®åº“ä¸­ï¼Œå¯¹äºŽå¤æ‚çš„ä»»åŠ¡ï¼Œé•¿çš„ä¸Šä¸‹æ–‡å¯ä»¥å˜å¾—éžå¸¸å¤§ï¼Œå¯¼è‡´è¿è¡Œé€Ÿåº¦å‡æ…¢å¹¶ä¸”æ›´é«˜çš„è®¡ç®—å¼€é”€ã€‚æˆ‘ä»¬å¯ä»¥é€šè¿‡è‡ªåŠ¨æ€»ç»“è¿‡åŽ»çš„å†…å®¹ï¼Œå‡å°‘ä¸Šä¸‹æ–‡çš„å­˜å‚¨å¤æ‚åº¦ã€‚

ä¼šè¯é»˜è®¤éš”ç¦»ä¿¡æ¯å…±äº«ï¼Œä½†å¦‚æžœä½¿ç”¨useridåˆ™å¯ä»¥åœ¨ä¸åŒä¼šè¯ä¹‹é—´å½¢æˆä¿¡æ¯äº¤å‰ã€‚

```python
# Check the state of the new session
session = await session_service.get_session(
    app_name=APP_NAME, user_id=USER_ID, session_id="new-isolated-session"
)

print("New Session State:")
print(session.state)

# Note: Depending on implementation, you might see shared state here.
# This is where the distinction between session-specific and user-specific state becomes important.
```

## Day3b-ä»£ç†è®°å¿†

è®°å¿†æ˜¯ä¸€ç§ä¸ºä»£ç†æä¾›é•¿æœŸçŸ¥è¯†å­˜å‚¨çš„æœåŠ¡ï¼Œå…³é”®åŒºåˆ«åœ¨äºŽï¼š

- ä¼šè¯ï¼šçŸ­æœŸè®°å¿†ï¼Œå•ä¸€çš„å¯¹è¯
- è®°å¿†ï¼šé•¿æœŸçš„çŸ¥è¯†å‚¨å¤‡ï¼Œå¯åœ¨ä¸åŒå¯¹è¯ä¸­äº¤å‰ä½¿ç”¨

ä¼šè¯å°±åƒæ˜¯åº”ç”¨çŠ¶æ€ï¼Œæ˜¯æš‚æ—¶çš„ï¼›è€Œè®°å¿†åˆ™åƒæ˜¯æ•°æ®åº“ï¼Œæ˜¯æ°¸ä¹…çš„ã€‚

ä¸ºä»€ä¹ˆéœ€è¦è®°å¿†ï¼Ÿè®°å¿†æä¾›å¯¹è¯æ‰€æ²¡æœ‰çš„èƒ½åŠ›

| Capability                    | What It Means                                      | Example                                                      |
| :---------------------------- | :------------------------------------------------- | :----------------------------------------------------------- |
| **Cross-Conversation Recall** | Access information from any past conversation      | "What preferences has this user mentioned across all chats?" |
| **Intelligent Extraction**    | LLM-powered consolidation extracts key facts       | Stores "allergic to peanuts" instead of 50 raw messages      |
| **Semantic Search**           | Meaning-based retrieval, not just keyword matching | Query "preferred hue" matches "favorite color is blue"       |
| **Persistent Storage**        | Survives application restarts                      | Build knowledge that grows over time                         |

---

**åˆå§‹åŒ–è®°å¿†æœåŠ¡**

![](D:\001-Coding\DATA\APX-LLM-Notebook\Agent\Image\Memory.JPG)

```python
memory_service = (
    InMemoryMemoryService()
)  # ADK's built-in Memory Service for development and testing
```

æ·»åŠ è®°å¿†æœåŠ¡åˆ°agent

```python
# Define constants used throughout the notebook
APP_NAME = "MemoryDemoApp"
USER_ID = "demo_user"

# Create agent
user_agent = LlmAgent(
    model=Gemini(model="gemini-2.5-flash-lite", retry_options=retry_config),
    name="MemoryDemoAgent",
    instruction="Answer user questions in simple words.",
)

print("âœ… Agent created")
```

åˆ›å»ºrunner

```python
# Create Session Service
session_service = InMemorySessionService()  # Handles conversations

# Create runner with BOTH services
runner = Runner(
    agent=user_agent,
    app_name="MemoryDemoApp",
    session_service=session_service,
    memory_service=memory_service,  # Memory service is now available!
)

print("âœ… Agent and Runner created with memory support!")
```

å°†memory_service æ·»åŠ åˆ°Runnerä¸­ä½¿å¾—agentå¯ä»¥ä½¿ç”¨è®°å¿†åŠŸèƒ½ï¼Œä½†å¹¶éžè‡ªåŠ¨å®žçŽ°ï¼Œéœ€è¦æ˜¾å¼è°ƒç”¨ï¼š

1. **Ingest data** using `add_session_to_memory()`
2. **Enable retrieval** by giving your agent memory tools (`load_memory` or `preload_memory`)

ä½¿ç”¨è®°å¿†ç®¡ç†æœåŠ¡ï¼Œå¦‚Vertex AI Memory Bank å¯ä»¥è®©å¯¹è¯è¿›è¡Œæ™ºèƒ½æå–ä¿¡æ¯ï¼Œä»…ä»…InMemoryMemoryServiceä¸å…·æœ‰æå–åŠŸèƒ½

```python
# User tells agent about their favorite color
await run_session(
    runner,
    "My favorite color is blue-green. Can you write a Haiku about it?",
    "conversation-01",  # Session ID
)

session = await session_service.get_session(
    app_name=APP_NAME, user_id=USER_ID, session_id="conversation-01"
)

# Let's see what's in the session
print("ðŸ“ Session contains:")
for event in session.events:
    text = (
        event.content.parts[0].text[:60]
        if event.content and event.content.parts
        else "(empty)"
    )
    print(f"  {event.content.role}: {text}...")
# å°†ä¼šè¯æ·»åŠ åˆ°è®°å¿†    
# This is the key method!
await memory_service.add_session_to_memory(session)

print("âœ… Session added to memory!")
```

### **æ¿€æ´»agentçš„è®°å¿†æ£€ç´¢åŠŸèƒ½**

agentsä¸èƒ½ç›´æŽ¥è®¿é—®è®°å¿†æœåŠ¡ï¼Œä»–ä»¬éœ€è¦ä½¿ç”¨å·¥å…·æ¥è°ƒç”¨è®°å¿†æœåŠ¡ã€‚

ADKæä¾›ä¸¤ç§å†…åœ¨å·¥å…·æ¥ä½¿ç”¨è®°å¿†æ£€ç´¢ï¼š

- load_memory(Reactive)
  - Agent decides when to search memory
  - Only retrieves when the agent thinks it's needed
  - More efficient (saves tokens)
  - Risk: Agent might forget to search
- preload_memory(Proactive)
  - Automatically searches before every turn
  - Memory always available to the agent
  - Guaranteed context, but less efficient
  - Searches even when not needed

```python
# Create agent
user_agent = LlmAgent(
    model=Gemini(model="gemini-2.5-flash-lite", retry_options=retry_config),
    name="MemoryDemoAgent",
    instruction="Answer user questions in simple words. Use load_memory tool if you need to recall past conversations.",
    tools=[
        load_memory
    ],  # Agent now has access to Memory and can search it whenever it decides to!
)

print("âœ… Agent with load_memory tool created.")
```

```python
# Create a new runner with the updated agent
runner = Runner(
    agent=user_agent,
    app_name=APP_NAME,
    session_service=session_service,
    memory_service=memory_service,
)

await run_session(runner, "What is my favorite color?", "color-test")
```

sk-xVIOEZ266vo9ObNUOqRdBBfSgSYaVduCUoh2aZm3sbckXAVD

**è‡ªåŠ©è®°å¿†æ£€ç´¢åŠŸèƒ½**

è®°å¿†æ£€ç´¢åŠŸèƒ½å¯ä»¥ç›´æŽ¥åœ¨ä»£ç ä¸­å®žçŽ°ï¼Œä¸»è¦ç”¨äºŽï¼š

- debuggingä¸Šä¸‹æ–‡è®°å¿†
- ç®€åŽ†åˆ†æžé¢æ¿
- åˆ›å»ºè‡ªå®šä¹‰çš„è®°å¿†ç®¡ç†UIs

`search_memory()`æ–¹æ³•è¾“å…¥ä¸€ä¸ªæ–‡æœ¬è¯·æ±‚ï¼Œè¿”å›žä¸€ä¸ªè®°å¿†æœå¯»çš„åº”ç­”

```python
# Search for color preferences
search_response = await memory_service.search_memory(
    app_name=APP_NAME, user_id=USER_ID, query="joke"
)

print("ðŸ” Search Results:")
print(f"  Found {len(search_response.memories)} relevant memories")
print()

for memory in search_response.memories:
    if memory.content and memory.content.parts:
        text = memory.content.parts[0].text[:80]
        print(f"  [{memory.author}]: {text}...")
```

**è®°å¿†æ£€ç´¢æ˜¯å¦‚ä½•èµ·ä½œç”¨çš„**

**InMemoryMemoryService(æœ¬notebookä¸­):**

- **æ–¹æ³•**ï¼šå…³é”®è¯åŒ¹é…
- **ç¤ºä¾‹**ï¼š"favorite color"ï¼ˆæœ€å–œæ¬¢çš„é¢œè‰²ï¼‰èƒ½å¤ŸåŒ¹é…ï¼Œå› ä¸ºå­˜åœ¨è¿™äº›ç¡®åˆ‡çš„å•è¯
- **å±€é™æ€§**ï¼š"preferred hue"ï¼ˆåçˆ±çš„è‰²è°ƒï¼‰å°†æ— æ³•åŒ¹é…

**VertexAiMemoryBankServiceï¼ˆç¬¬5å¤©å°†ä»‹ç»çš„ï¼‰ï¼š**

- **æ–¹æ³•**ï¼šé€šè¿‡åµŒå…¥å‘é‡è¿›è¡Œè¯­ä¹‰æœç´¢
- **ç¤ºä¾‹**ï¼š"preferred hue"ï¼ˆåçˆ±çš„è‰²è°ƒï¼‰**èƒ½å¤Ÿ**åŒ¹é…"favorite color"ï¼ˆæœ€å–œæ¬¢çš„é¢œè‰²ï¼‰
- **ä¼˜åŠ¿**ï¼šç†è§£è¯­ä¹‰å«ä¹‰ï¼Œè€Œä¸ä»…ä»…æ˜¯å…³é”®è¯åŒ¹é…

### è‡ªåŠ¨è®°å¿†å­˜å‚¨

ç›®å‰æˆ‘ä»¬ä½¿ç”¨äº†`add_session_to_memory()`å°†æ•°æ®è½¬åŒ–ä¸ºé•¿æœŸè®°å¿†ã€‚ç”Ÿäº§ç³»ç»Ÿéœ€è¦å°†è¿™ä¸ªè¡Œä¸ºè‡ªåŠ¨åŒ–ã€‚

#### å›žè°ƒ

**æƒ³è±¡å›žè°ƒåŠŸèƒ½åœ¨ä»£ç†çš„ç”Ÿå‘½å‘¨æœŸä¸­æ˜¯äº‹ä»¶ç›‘å¬å™¨ã€‚**å½“ä¸€ä¸ªä»£ç†æŠ›å‡ºä¸€ä¸ªè¯·æ±‚ï¼Œå®ƒä¼šç»åŽ†ä¸åŒçš„é˜¶æ®µï¼šæŽ¥å—è¾“å…¥ï¼Œè°ƒç”¨llmï¼Œè°ƒç”¨å·¥å…·ï¼Œç”Ÿæˆå›žåº”ã€‚å¬å›žå¯ä»¥åœ¨æ¯ä¸ªé˜¶æ®µè‡ªå®šä¹‰é€»è¾‘è€Œä¸éœ€è¦ä¿®æ”¹ä»£ç†çš„æ ¸å¿ƒä»£ç 

å¯ç”¨çš„å›žè°ƒç±»åž‹ï¼š

- **before_agent_callback** â†’ åœ¨ä»£ç†å¼€å§‹å¤„ç†è¯·æ±‚**ä¹‹å‰**è¿è¡Œ
- **after_agent_callback** â†’ åœ¨ä»£ç†å®Œæˆæœ¬æ¬¡æ‰§è¡Œ**ä¹‹åŽ**è¿è¡Œ
- **before_tool_callback** / **after_tool_callback** â†’ å›´ç»•å·¥å…·è°ƒç”¨ï¼ˆè°ƒç”¨å‰/åŽï¼‰
- **before_model_callback** / **after_model_callback** â†’ å›´ç»• LLM è°ƒç”¨ï¼ˆè°ƒç”¨å‰/åŽï¼‰
- **on_model_error_callback** â†’ å½“å‘ç”Ÿé”™è¯¯æ—¶è¿è¡Œ

å¸¸è§ä½¿ç”¨åœºæ™¯ï¼š

- **æ—¥å¿—è®°å½•ä¸Žå¯è§‚æµ‹æ€§**ï¼ˆè¿½è¸ªä»£ç†è¡Œä¸ºï¼‰
- **è‡ªåŠ¨æ•°æ®æŒä¹…åŒ–**ï¼ˆå¦‚ä¿å­˜åˆ°è®°å¿†ç³»ç»Ÿï¼‰
- **è‡ªå®šä¹‰éªŒè¯æˆ–è¿‡æ»¤**
- **æ€§èƒ½ç›‘æŽ§**

**è‡ªåŠ¨è®°å¿†å­˜å‚¨çš„å›žè°ƒ**

```python
async def auto_save_to_memory(callback_context):
    """Automatically save session to memory after each agent turn."""
    await callback_context._invocation_context.memory_service.add_session_to_memory(
        callback_context._invocation_context.session
    )


print("âœ… Callback created.")
```

```python
# Agent with automatic memory saving
auto_memory_agent = LlmAgent(
    model=Gemini(model="gemini-2.5-flash-lite", retry_options=retry_config),
    name="AutoMemoryAgent",
    instruction="Answer user questions.",
    tools=[preload_memory],
    after_agent_callback=auto_save_to_memory,  # Saves after each turn!
)

print("âœ… Agent created with automatic memory saving!")
```

```python
# Create a runner for the auto-save agent
# This connects our automated agent to the session and memory services
auto_runner = Runner(
    agent=auto_memory_agent,  # Use the agent with callback + preload_memory
    app_name=APP_NAME,
    session_service=session_service,  # Same services from Section 3
    memory_service=memory_service,
)

print("âœ… Runner created.")
```

```python
# Test 1: Tell the agent about a gift (first conversation)
# The callback will automatically save this to memory when the turn completes
await run_session(
    auto_runner,
    "I gifted a new toy to my nephew on his 1st birthday!",
    "auto-save-test",
)

# Test 2: Ask about the gift in a NEW session (second conversation)
# The agent should retrieve the memory using preload_memory and answer correctly
await run_session(
    auto_runner,
    "What did I gift my nephew?",
    "auto-save-test-2",  # Different session ID - proves memory works across sessions!
)
```

ä½•æ—¶å­˜å‚¨ï¼Ÿ

| Timing                  | Implementation                | Best For                           |
| ----------------------- | ----------------------------- | ---------------------------------- |
| **After every turn**    | `after_agent_callback`        | Real-time memory updates           |
| **End of conversation** | Manual call when session ends | Batch processing, reduce API calls |
| **Periodic intervals**  | Timer-based background job    | Long-running conversations         |

### è®°å¿†æ•´åˆ

åŽŸå§‹å­˜å‚¨çš„å±€é™æ€§

æˆ‘ä»¬ç›®å‰å­˜å‚¨çš„å†…å®¹ï¼š

- æ¯æ¡ç”¨æˆ·æ¶ˆæ¯
- æ¯æ¡ä»£ç†å“åº”
- æ¯ä¸ªå·¥å…·è°ƒç”¨

å­˜åœ¨çš„é—®é¢˜ï¼š

```
ä¼šè¯ï¼š50æ¡æ¶ˆæ¯ = 10,000ä¸ªtoken
è®°å¿†ï¼šå­˜å‚¨æ‰€æœ‰50æ¡æ¶ˆæ¯
æœç´¢ï¼šè¿”å›žå…¨éƒ¨50æ¡æ¶ˆæ¯ â†’ ä»£ç†å¿…é¡»å¤„ç†10,000ä¸ªtoken
```

è¿™ç§æ–¹æ¡ˆä¸å¯æ‰©å±•ã€‚æˆ‘ä»¬éœ€è¦**è®°å¿†æ•´åˆ**ã€‚

#### ä»€ä¹ˆæ˜¯è®°å¿†æ•´åˆ

æŠ›å¼ƒå¯¹è¯å™ªéŸ³ï¼Œåªæå–æœ€é‡è¦çš„å› ç´ 

**efore (Raw Storage):**

```
User: "My favorite color is BlueGreen. I also like purple. 
       Actually, I prefer BlueGreen most of the time."
Agent: "Great! I'll remember that."
User: "Thanks!"
Agent: "You're welcome!"

â†’ Stores ALL 4 messages (redundant, verbose)
```

**After (Consolidation):**

```
Extracted Memory: "User's favorite color: BlueGreen"

â†’ Stores 1 concise fact
```

**Benefits:** Less storage, faster retrieval, more accurate answers.

#### è®°å¿†æ•´åˆå¦‚ä½•ç”Ÿæ•ˆ

**The pipeline:**

```
1. Raw Session Events
   â†“
2. LLM analyzes conversation
   â†“
3. Extracts key facts
   â†“
4. Stores concise memories
   â†“
5. Merges with existing memories (deduplication)
```

**Example transformation:**

```
Input:  "I'm allergic to peanuts. I can't eat anything with nuts."

Output: Memory {
  allergy: "peanuts, tree nuts"
  severity: "avoid completely"
}
```

Natural language â†’ Structured, actionable data.ç»“æž„åŒ–ã€å¯æ“ä½œçš„æ•°æ®

#### è®°å¿†æ•´åˆçš„è¿›é˜¶

**å…³é”®è¦ç‚¹ï¼šæ‰˜ç®¡è®°å¿†æœåŠ¡ä¼šè‡ªåŠ¨å¤„ç†è®°å¿†æ•´åˆã€‚**

**ä½ ä½¿ç”¨ç›¸åŒçš„APIï¼š**

```
add_session_to_memory() â† ç›¸åŒçš„æ–¹æ³•
search_memory() â† ç›¸åŒçš„æ–¹æ³•
```

**åŒºåˆ«åœ¨äºŽåŽå°å¤„ç†æ–¹å¼ï¼š**

- **InMemoryMemoryService**ï¼šå­˜å‚¨åŽŸå§‹äº‹ä»¶
- **VertexAiMemoryBankService**ï¼šå­˜å‚¨å‰æ™ºèƒ½æ•´åˆè®°å¿†

**ðŸ“š äº†è§£æ›´å¤šï¼š**

- Vertex AI Memory Bankï¼šè®°å¿†æ•´åˆæŒ‡å— â†’ ä½ å°†åœ¨ç¬¬5å¤©æŽ¢ç´¢è¿™ä¸ªåŠŸèƒ½ï¼

## Day4a Agent observability

- å­¦ä¹ å¦‚ä½•ç»™agentæ·»åŠ è§‚å¯Ÿèƒ½åŠ›
- å­¦ä¹ å¦‚ä½•è¯„ä¼°agentçš„å·¥ä½œçŠ¶å†µ

ä»€ä¹ˆæ˜¯agentè§‚å¯Ÿèƒ½åŠ›ï¼Ÿä¸Žå…¶ä»–çš„è½¯ä»¶ä¸åŒï¼Œai agentä¼šå‡ºä¸€äº›å¥‡æ€ªçš„é—®é¢˜ã€‚æ¯”å¦‚ï¼š

```
User: "Find quantum computing papers"
Agent: "I cannot help with that request."
You: ðŸ˜­ WHY?? Is it the prompt? Missing tools? API error?
```

agentè§‚å¯Ÿèƒ½åŠ›å¯ä»¥è®©ä½ çš„agentå†³ç­–å¯è§†åŒ–ï¼Œä½ å¯ä»¥çœ‹åˆ°å‘é€åˆ°llmçš„æŒ‡ä»¤ä»¥åŠæç¤ºè¯ï¼Œä»€ä¹ˆå·¥å…·æ˜¯å¯ç”¨çš„ï¼Œæ¨¡åž‹æ˜¯å¦‚ä½•ç”Ÿæ•ˆçš„ï¼Œä»¥åŠé”™è¯¯å‘ç”Ÿåœ¨å“ªé‡Œã€‚

```
DEBUG Log: LLM Request shows "Functions: []" (no tools!)
You: ðŸŽ¯ Aha! Missing google_search tool - easy fix!
```

Agent Observabilityçš„åŸºç¡€åŠŸèƒ½

- æ—¥å¿—ï¼šæ—¥å¿—æ˜¯å•ä¸ªäº‹ä»¶çš„è®°å½•ï¼Œå‘ŠçŸ¥åœ¨ç‰¹å®šæ—¶åˆ»å‘ç”Ÿäº†ä»€ä¹ˆã€‚

- è¿½è¸ªï¼šè¿½è¸ªå°†æ—¥å¿—ä¸²è”æˆå®Œæ•´æ•…äº‹ï¼Œé€šè¿‡æ­ç¤ºå…¨æ­¥éª¤åºåˆ—å±•ç¤ºæœ€ç»ˆç»“æžœçš„äº§ç”ŸåŽŸå› ã€‚

- æŒ‡æ ‡ï¼šæŒ‡æ ‡æ˜¯æ±‡æ€»æ€§æ•°å€¼ï¼ˆå¦‚å¹³å‡å€¼ä¸Žé”™è¯¯çŽ‡ï¼‰ï¼Œç”¨äºŽåæ˜ æ™ºèƒ½ä½“çš„æ•´ä½“è¿è¡ŒçŠ¶å†µã€‚

![](./Image/observability-intro.png)

- ä½¿ç”¨TraceåŠŸèƒ½debug
- ä½¿ç”¨æœ¬åœ°æ—¥å¿—debug

```python
import logging
import os

# Clean up any previous logs
for log_file in ["logger.log", "web.log", "tunnel.log"]:
    if os.path.exists(log_file):
        os.remove(log_file)
        print(f"ðŸ§¹ Cleaned up {log_file}")

# Configure logging with DEBUG log level.
logging.basicConfig(
    filename="logger.log",
    level=logging.DEBUG,
    format="%(filename)s:%(lineno)s %(levelname)s:%(message)s",
)

print("âœ… Logging configured")
```

### åœ¨äº§å“ä¸­è®°å½•

- é—®é¢˜1ï¼šäº§å“éƒ¨ç½²ã€‚å¦‚ä½•åœ¨å·²éƒ¨ç½²çš„äº§å“ä¸Šdebugï¼Ÿ
- é—®é¢˜2ï¼šè‡ªåŠ¨åŒ–ç³»ç»Ÿã€‚åœ¨çŽ°æœ‰ç®¡çº¿ä¸Šï¼Œagentä¸€å¤©è·‘1000æ¬¡ã€‚å¦‚ä½•è‡ªåŠ¨åŒ–æµ‹è¯•å„éƒ¨åˆ†çš„è€—æ—¶ï¼Ÿè€Œä¸æ˜¯å¯¹æ¯ä¸ªçŽ¯èŠ‚debugï¼Œå…±debug1000æ¬¡

è§£å†³åŠžæ³•ï¼šéœ€è¦æ•èŽ·æ•°æ®ä¿¡æ¯â€”â€”åœ¨ä»£ç ä¸­æ·»åŠ æ—¥å¿—ã€‚åœ¨ä¼ ç»Ÿè½¯ä»¶å¼€å‘ä¸­ï¼Œåªéœ€è¦åœ¨ä»£ç ä¸­æ‰“logï¼Œä½†æ˜¯åœ¨agentä¸­ï¼Œè¿™æ˜¯ä¸åŒçš„ã€‚é€šå¸¸çš„åšæ³•æ˜¯åœ¨agentä¸­åŠ å…¥æ’ä»¶ã€‚

---

å¦‚ä½•åœ¨äº§å“ä¸­æ·»åŠ æ—¥å¿—åŠŸèƒ½

**æ’ä»¶**æ˜¯ä¸€ä¸ªè‡ªå®šä¹‰ä»£ç æ¨¡å—ï¼Œä¼šåœ¨æ™ºèƒ½ä½“ç”Ÿå‘½å‘¨æœŸçš„ä¸åŒé˜¶æ®µè‡ªåŠ¨è¿è¡Œã€‚æ’ä»¶ç”±"å›žè°ƒå‡½æ•°"æž„æˆï¼Œè¿™äº›å›žè°ƒæä¾›äº†æ‹¦æˆªæ™ºèƒ½ä½“æµç¨‹çš„é’©å­ã€‚å¯ä»¥è¿™æ ·ç†è§£ï¼š

- æ‚¨çš„æ™ºèƒ½ä½“å·¥ä½œæµç¨‹ï¼šç”¨æˆ·æ¶ˆæ¯ â†’ æ™ºèƒ½ä½“æ€è€ƒ â†’ è°ƒç”¨å·¥å…· â†’ è¿”å›žå“åº”

- æ’ä»¶å¯ä»‹å…¥æ­¤æµç¨‹ï¼šåœ¨æ™ºèƒ½ä½“å¯åŠ¨å‰ â†’ å·¥å…·è¿è¡ŒåŽ â†’ LLMå“åº”æ—¶ â†’ ç­‰å„ä¸ªé˜¶æ®µ

- æ’ä»¶åŒ…å«æ‚¨çš„è‡ªå®šä¹‰ä»£ç ï¼šæ—¥å¿—è®°å½•ã€è¿è¡Œç›‘æŽ§ã€å®‰å…¨æ£€æŸ¥ã€ç¼“å­˜å¤„ç†ç­‰ã€‚

![](./Image/plugins-callbacks.png)

**å›žè°ƒå‡½æ•°**

å›žè°ƒå‡½æ•°æ˜¯æ’ä»¶å†…éƒ¨çš„åŸºæœ¬ç»„æˆå•å…ƒâ€”â€”å®ƒä»¬åªæ˜¯ç®€å•çš„Pythonå‡½æ•°ï¼Œåœ¨æ™ºèƒ½ä½“ç”Ÿå‘½å‘¨æœŸçš„ç‰¹å®šæ—¶é—´ç‚¹æ‰§è¡Œï¼å¤šä¸ªå›žè°ƒå‡½æ•°ç»„åˆåœ¨ä¸€èµ·å°±æž„æˆäº†ä¸€ä¸ªæ’ä»¶ã€‚

å›žè°ƒå‡½æ•°ä¸»è¦æœ‰ä»¥ä¸‹å‡ ç§ç±»åž‹ï¼š

- **before/after_agent_callbacks** - åœ¨æ™ºèƒ½ä½“è¢«è°ƒç”¨**ä¹‹å‰/ä¹‹åŽ**æ‰§è¡Œ

- **before/after_tool_callbacks**  åœ¨å·¥å…·è¢«è°ƒç”¨**ä¹‹å‰/ä¹‹åŽ**æ‰§è¡Œ

- **before/after_model_callbacks** - ç±»ä¼¼åœ°ï¼Œåœ¨LLMæ¨¡åž‹è¢«è°ƒç”¨**ä¹‹å‰/ä¹‹åŽ**æ‰§è¡Œ

- **on_model_error_callback** - åœ¨é‡åˆ°æ¨¡åž‹é”™è¯¯æ—¶æ‰§è¡Œ

![](./Image/types_of_callbacks.png)

### Pluginå¦‚ä½•è®¾è®¡

```python
print("----- EXAMPLE PLUGIN - DOES NOTHING ----- ")

import logging
from google.adk.agents.base_agent import BaseAgent
from google.adk.agents.callback_context import CallbackContext
from google.adk.models.llm_request import LlmRequest
from google.adk.plugins.base_plugin import BasePlugin


# Applies to all agent and model calls
class CountInvocationPlugin(BasePlugin):
    """A custom plugin that counts agent and tool invocations."""

    def __init__(self) -> None:
        """Initialize the plugin with counters."""
        super().__init__(name="count_invocation")
        self.agent_count: int = 0
        self.tool_count: int = 0
        self.llm_request_count: int = 0

    # Callback 1: Runs before an agent is called. You can add any custom logic here.
    async def before_agent_callback(
        self, *, agent: BaseAgent, callback_context: CallbackContext
    ) -> None:
        """Count agent runs."""
        self.agent_count += 1
        logging.info(f"[Plugin] Agent run count: {self.agent_count}")

    # Callback 2: Runs before a model is called. You can add any custom logic here.
    async def before_model_callback(
        self, *, callback_context: CallbackContext, llm_request: LlmRequest
    ) -> None:
        """Count LLM requests."""
        self.llm_request_count += 1
        logging.info(f"[Plugin] LLM request count: {self.llm_request_count}")
```

![](./Image/count-invocation-plugin.png)

```py
from google.adk.agents import LlmAgent
from google.adk.models.google_llm import Gemini
from google.adk.tools.agent_tool import AgentTool
from google.adk.tools.google_search_tool import google_search

from google.genai import types
from typing import List

retry_config = types.HttpRetryOptions(
    attempts=5,  # Maximum retry attempts
    exp_base=7,  # Delay multiplier
    initial_delay=1,
    http_status_codes=[429, 500, 503, 504],  # Retry on these HTTP errors
)


def count_papers(papers: List[str]):
    """
    This function counts the number of papers in a list of strings.
    Args:
      papers: A list of strings, where each string is a research paper.
    Returns:
      The number of papers in the list.
    """
    return len(papers)


# Google search agent
google_search_agent = LlmAgent(
    name="google_search_agent",
    model=Gemini(model="gemini-2.5-flash-lite", retry_options=retry_config),
    description="Searches for information using Google search",
    instruction="Use the google_search tool to find information on the given topic. Return the raw search results.",
    tools=[google_search],
)

# Root agent
research_agent_with_plugin = LlmAgent(
    name="research_paper_finder_agent",
    model=Gemini(model="gemini-2.5-flash-lite", retry_options=retry_config),
    instruction="""Your task is to find research papers and count them. 
   
   You must follow these steps:
   1) Find research papers on the user provided topic using the 'google_search_agent'. 
   2) Then, pass the papers to 'count_papers' tool to count the number of papers returned.
   3) Return both the list of research papers and the total number of papers.
   """,
    tools=[AgentTool(agent=google_search_agent), count_papers],
)

print("âœ… Agent created")
```

**To use `LoggingPlugin` in the above research agent,**

1. Import the plugin
2. Add it when initializing the `InMemoryRunner`.

```py
from google.adk.runners import InMemoryRunner
from google.adk.plugins.logging_plugin import (
    LoggingPlugin,
)  # <---- 1. Import the Plugin
from google.genai import types
import asyncio

runner = InMemoryRunner(
    agent=research_agent_with_plugin,
    plugins=[
        LoggingPlugin()
    ],  # <---- 2. Add the plugin. Handles standard Observability logging across ALL agents
)

print("âœ… Runner configured")
```

```py
print("ðŸš€ Running agent with LoggingPlugin...")
print("ðŸ“Š Watch the comprehensive logging output below:\n")

response = await runner.run_debug("Find recent papers on quantum computing")
```



## Day4b Agent Evaluation

#### Interactive Evaluation with ADK Web UI

#### ç³»ç»Ÿæ€§è¯„ä¼°

å›žå½’æµ‹è¯•æ˜¯æŒ‡é‡æ–°è¿è¡ŒçŽ°æœ‰çš„æµ‹è¯•ï¼Œä»¥ç¡®ä¿æ–°çš„æ›´æ”¹æ²¡æœ‰ç ´åä¹‹å‰æ­£å¸¸å·¥ä½œçš„åŠŸèƒ½ã€‚

ADKæä¾›äº†ä¸¤ç§è‡ªåŠ¨è¿›è¡Œå›žå½’å’Œæ‰¹é‡æµ‹è¯•çš„æ–¹æ³•ï¼šä½¿ç”¨pytestå’Œ`adk eval`CLIå‘½ä»¤ã€‚åœ¨æœ¬èŠ‚ä¸­ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨CLIå‘½ä»¤ã€‚æœ‰å…³pytestæ–¹æ³•çš„æ›´å¤šä¿¡æ¯ï¼Œè¯·å‚é˜…æœ¬ç¬”è®°æœ¬æœ«å°¾èµ„æºéƒ¨åˆ†ä¸­çš„é“¾æŽ¥ã€‚

ä¸‹å›¾å±•ç¤ºäº†è¯„ä¼°çš„æ•´ä½“æµç¨‹ã€‚ä»Žé«˜å±‚æ¬¡æ¥çœ‹ï¼Œè¯„ä¼°åˆ†ä¸ºå››ä¸ªæ­¥éª¤ï¼š

1. **åˆ›å»ºè¯„ä¼°é…ç½®** - å®šä¹‰æŒ‡æ ‡æˆ–æ‚¨æƒ³è¦æµ‹é‡çš„å†…å®¹
2. **åˆ›å»ºæµ‹è¯•ç”¨ä¾‹** - ç”¨äºŽå¯¹æ¯”çš„æ ·æœ¬æµ‹è¯•ç”¨ä¾‹
3. **ä½¿ç”¨æµ‹è¯•æŸ¥è¯¢è¿è¡Œä»£ç†**
4. **æ¯”è¾ƒç»“æžœ**

![](./Image/evaluate_agent.png)

```python
import json

# Create evaluation configuration with basic criteria
eval_config = {
    "criteria": {
        "tool_trajectory_avg_score": 1.0,  # Perfect tool usage required
        "response_match_score": 0.8,  # 80% text similarity threshold
    }
}

with open("home_automation_agent/test_config.json", "w") as f:
    json.dump(eval_config, f, indent=2)

print("âœ… Evaluation configuration created!")
print("\nðŸ“Š Evaluation Criteria:")
print("â€¢ tool_trajectory_avg_score: 1.0 - Requires exact tool usage match")
print("â€¢ response_match_score: 0.8 - Requires 80% text similarity")
print("\nðŸŽ¯ What this evaluation will catch:")
print("âœ… Incorrect tool usage (wrong device, location, or status)")
print("âœ… Poor response quality and communication")
print("âœ… Deviations from expected behavior patterns")
```

```python
# Create evaluation test cases that reveal tool usage and response quality problems
test_cases = {
    "eval_set_id": "home_automation_integration_suite",
    "eval_cases": [
        {
            "eval_id": "living_room_light_on",
            "conversation": [
                {
                    "user_content": {
                        "parts": [
                            {"text": "Please turn on the floor lamp in the living room"}
                        ]
                    },
                    "final_response": {
                        "parts": [
                            {
                                "text": "Successfully set the floor lamp in the living room to on."
                            }
                        ]
                    },
                    "intermediate_data": {
                        "tool_uses": [
                            {
                                "name": "set_device_status",
                                "args": {
                                    "location": "living room",
                                    "device_id": "floor lamp",
                                    "status": "ON",
                                },
                            }
                        ]
                    },
                }
            ],
        },
        {
            "eval_id": "kitchen_on_off_sequence",
            "conversation": [
                {
                    "user_content": {
                        "parts": [{"text": "Switch on the main light in the kitchen."}]
                    },
                    "final_response": {
                        "parts": [
                            {
                                "text": "Successfully set the main light in the kitchen to on."
                            }
                        ]
                    },
                    "intermediate_data": {
                        "tool_uses": [
                            {
                                "name": "set_device_status",
                                "args": {
                                    "location": "kitchen",
                                    "device_id": "main light",
                                    "status": "ON",
                                },
                            }
                        ]
                    },
                }
            ],
        },
    ],
}
```



```python
import json

with open("home_automation_agent/integration.evalset.json", "w") as f:
    json.dump(test_cases, f, indent=2)

print("âœ… Evaluation test cases created")
print("\nðŸ§ª Test scenarios:")
for case in test_cases["eval_cases"]:
    user_msg = case["conversation"][0]["user_content"]["parts"][0]["text"]
    print(f"â€¢ {case['eval_id']}: {user_msg}")

print("\nðŸ“Š Expected results:")
print("â€¢ basic_device_control: Should pass both criteria")
print(
    "â€¢ wrong_tool_usage_test: May fail tool_trajectory if agent uses wrong parameters"
)
print(
    "â€¢ poor_response_quality_test: May fail response_match if response differs too much"
)
```

```python
print("ðŸš€ Run this command to execute evaluation:")
!adk eval home_automation_agent home_automation_agent/integration.evalset.json --config_file_path=home_automation_agent/test_config.json --print_detailed_results
```

## Day5a Agent2Agent Communication 

æœ¬æ–‡æ—¨åœ¨æ•™å­¦å¦‚ä½•æž„å»ºå¤šæ™ºèƒ½ä½“ç³»ç»Ÿï¼Œä¸åŒçš„æ™ºèƒ½ä½“ä¹‹é—´å¯ä»¥é€šè¿‡**A2A Protocol**ç›¸äº’äº¤æµã€‚

- ç†è§£A2A protocolä»¥åŠå¦‚ä½•æŠ‰æ‹©æ¬¡æ™ºèƒ½ä½“ä»¥åŠA2Açš„ä½¿ç”¨æ—¶é—´
- å­¦ä¹ å¸¸è§çš„A2Aæž¶æž„æ¨¡å¼ (cross-framework, cross-language, cross-organization)
- **ä½¿ç”¨ to_a2a() é€šè¿‡ A2A å…¬å¼€ ADK æ™ºèƒ½ä½“**

- **ä½¿ç”¨ RemoteA2aAgent è°ƒç”¨è¿œç¨‹æ™ºèƒ½ä½“**

- **æž„å»ºäº§å“ç›®å½•é›†æˆç³»ç»Ÿ**

---

**å¤æ‚æ™ºèƒ½ä½“é¢ä¸´çš„é—®é¢˜**ï¼š

- å•ä¸ªæ™ºèƒ½ä½“æ— æ³•å¤„ç†æ‰€æœ‰ä»»åŠ¡ - ä¸ºä¸åŒé¢†åŸŸè®¾è®¡çš„ä¸“ä¸šæ™ºèƒ½ä½“è¡¨çŽ°æ›´ä½³
- æ™ºèƒ½ä½“ä¹‹é—´éœ€è¦ååŒåˆä½œ - å®¢æˆ·æœåŠ¡éœ€è¦äº§å“æ•°æ®ï¼Œè®¢å•ç³»ç»Ÿéœ€è¦åº“å­˜ä¿¡æ¯
- ä¸åŒå›¢é˜Ÿå¼€å‘ä¸åŒçš„æ™ºèƒ½ä½“ - æ‚¨å¯èƒ½éœ€è¦é›†æˆå¤–éƒ¨ä¾›åº”å•†çš„æ™ºèƒ½ä½“
- æ™ºèƒ½ä½“å¯èƒ½ä½¿ç”¨ä¸åŒçš„è¯­è¨€/æ¡†æž¶ - æ‚¨éœ€è¦ä¸€ä¸ªæ ‡å‡†çš„é€šä¿¡åè®®

![](./Image/a2a_01.png)

- è·¨æ¡†æž¶é›†æˆï¼šADK æ™ºèƒ½ä½“ä¸Žå…¶ä»–æ™ºèƒ½ä½“æ¡†æž¶é€šä¿¡
- è·¨è¯­è¨€é€šä¿¡ï¼šPython æ™ºèƒ½ä½“è°ƒç”¨ Java æˆ– Node.js æ™ºèƒ½ä½“
- è·¨ç»„ç»‡è¾¹ç•Œï¼šæ‚¨çš„å†…éƒ¨æ™ºèƒ½ä½“ä¸Žå¤–éƒ¨ä¾›åº”å•†æœåŠ¡é›†æˆ

æˆ‘ä»¬å°†æž„å»ºä¸€ä¸ªå®žç”¨çš„ç”µå•†é›†æˆç³»ç»Ÿï¼š

1. **äº§å“ç›®å½•æ™ºèƒ½ä½“**ï¼ˆé€šè¿‡A2Aå…¬å¼€ï¼‰- å¤–éƒ¨ä¾›åº”å•†æœåŠ¡ï¼Œæä¾›äº§å“ä¿¡æ¯
2. **å®¢æˆ·æ”¯æŒæ™ºèƒ½ä½“**ï¼ˆæ¶ˆè´¹è€…ï¼‰- æ‚¨çš„å†…éƒ¨æ™ºèƒ½ä½“ï¼Œé€šè¿‡æŸ¥è¯¢äº§å“æ•°æ®å¸®åŠ©å®¢æˆ·

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ å®¢æˆ·æ”¯æŒæ™ºèƒ½ä½“         â”‚  â”€A2Aâ”€â”€â–¶  â”‚ äº§å“ç›®å½•æ™ºèƒ½ä½“         â”‚
â”‚ ï¼ˆæ¶ˆè´¹è€…ï¼‰            â”‚            â”‚ ï¼ˆä¾›åº”å•†ï¼‰            â”‚
â”‚ æ‚¨çš„å…¬å¸              â”‚           â”‚ å¤–éƒ¨æœåŠ¡              â”‚
â”‚ (localhost:8000)     â”‚           â”‚ (localhost:8001)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**ä¸ºä»€ä¹ˆé‡‡ç”¨A2Aï¼š**

- äº§å“ç›®å½•ç”±å¤–éƒ¨ä¾›åº”å•†ç»´æŠ¤ï¼ˆæ‚¨æ— æ³•ä¿®æ”¹å…¶ä»£ç ï¼‰
- ä¸åŒç»„ç»‡æ‹¥æœ‰ç‹¬ç«‹çš„ç³»ç»Ÿ
- æœåŠ¡ä¹‹é—´éœ€è¦æ­£å¼çš„å¥‘çº¦/åè®®
- äº§å“ç›®å½•å¯èƒ½ä½¿ç”¨ä¸åŒçš„è¯­è¨€/æ¡†æž¶

------

**ðŸ’¡ A2A VS æœ¬åœ°å­æ™ºèƒ½ä½“ï¼šå†³ç­–è¡¨**

==**A2AæœåŠ¡ä¸€èˆ¬ç”¨äºŽä¸åŒçš„ç»„ç»‡ã€æœåŠ¡ã€æ¡†æž¶ç­‰ç­‰ã€‚æœ¬åœ°å­æ™ºèƒ½ä½“æœåŠ¡éœ€è¦è¾ƒé«˜çš„ä¸€è‡´æ€§åŠä½Žå»¶è¿Ÿã€‚**==

| å› ç´        | ä½¿ç”¨ A2A             | ä½¿ç”¨æœ¬åœ°å­æ™ºèƒ½ä½“ |
| ---------- | -------------------- | ---------------- |
| æ™ºèƒ½ä½“ä½ç½® | å¤–éƒ¨æœåŠ¡ï¼Œä¸åŒä»£ç åº“ | åŒä¸€ä»£ç åº“ï¼Œå†…éƒ¨ |
| æ‰€æœ‰æƒ     | ä¸åŒå›¢é˜Ÿ/ç»„ç»‡        | æ‚¨çš„å›¢é˜Ÿ         |
| ç½‘ç»œ       | ä¸åŒæœºå™¨ä¸Šçš„æ™ºèƒ½ä½“   | åŒä¸€è¿›ç¨‹/æœºå™¨    |
| æ€§èƒ½       | ç½‘ç»œå»¶è¿Ÿå¯æŽ¥å—       | éœ€è¦ä½Žå»¶è¿Ÿ       |
| è¯­è¨€/æ¡†æž¶  | éœ€è¦è·¨è¯­è¨€/æ¡†æž¶      | ç›¸åŒè¯­è¨€         |
| å¥‘çº¦       | éœ€è¦æ­£å¼APIå¥‘çº¦      | å†…éƒ¨æŽ¥å£         |
| ç¤ºä¾‹       | å¤–éƒ¨ä¾›åº”å•†äº§å“ç›®å½•   | å†…éƒ¨è®¢å•å¤„ç†æ­¥éª¤ |

------

**ðŸ“ æ•™ç¨‹èƒŒæ™¯**

åœ¨æœ¬æ•™ç¨‹ä¸­ï¼Œä¸ºå­¦ä¹ ç›®çš„ï¼Œæˆ‘ä»¬å°†åœ¨æœ¬åœ°æ¨¡æ‹Ÿè¿™ä¸¤ä¸ªæ™ºèƒ½ä½“ï¼ˆéƒ½è¿è¡Œåœ¨æœ¬åœ°ä¸»æœºä¸Šï¼‰ã€‚åœ¨å®žé™…ç”Ÿäº§çŽ¯å¢ƒä¸­ï¼š

- äº§å“ç›®å½•æ™ºèƒ½ä½“ä¼šè¿è¡Œåœ¨ä¾›åº”å•†çš„åŸºç¡€è®¾æ–½ä¸Šï¼ˆä¾‹å¦‚ https://vendor.comï¼‰
- å®¢æˆ·æ”¯æŒæ™ºèƒ½ä½“ä¼šè¿è¡Œåœ¨æ‚¨çš„åŸºç¡€è®¾æ–½ä¸Š
- å®ƒä»¬å°†é€šè¿‡äº’è”ç½‘ä½¿ç”¨A2Aåè®®è¿›è¡Œé€šä¿¡

è¿™ç§æœ¬åœ°æ¨¡æ‹Ÿè®©æ‚¨æ— éœ€éƒ¨ç½²å®žé™…æœåŠ¡å°±èƒ½å­¦ä¹ A2Aï¼

![](./Image/a2a_02.png)

**å·¥ä½œåŽŸç†ï¼š**

1. **å®¢æˆ·å’¨è¯¢** â†’ å®¢æˆ·å‘æ‚¨çš„å®¢æˆ·æ”¯æŒæ™ºèƒ½ä½“æå‡ºäº§å“ç›¸å…³é—®é¢˜
2. **è¯†åˆ«éœ€æ±‚** â†’ æ”¯æŒæ™ºèƒ½ä½“æ„è¯†åˆ°éœ€è¦èŽ·å–äº§å“ä¿¡æ¯
3. **è¿œç¨‹è°ƒç”¨** â†’ æ”¯æŒæ™ºèƒ½ä½“é€šè¿‡A2Aåè®®è°ƒç”¨äº§å“ç›®å½•æ™ºèƒ½ä½“
4. **èŽ·å–æ•°æ®** â†’ äº§å“ç›®å½•æ™ºèƒ½ä½“ï¼ˆå¤–éƒ¨ä¾›åº”å•†ï¼‰è¿”å›žäº§å“æ•°æ®
5. **æ•´åˆå“åº”** â†’ æ”¯æŒæ™ºèƒ½ä½“æ•´åˆä¿¡æ¯å¹¶å½¢æˆæœ€ç»ˆå›žç­”
6. **å›žå¤å®¢æˆ·** â†’ æ”¯æŒæ™ºèƒ½ä½“å°†å›žç­”è¿”å›žç»™å®¢æˆ·

```py
å®¢æˆ·: "åŽä¸ºP70 Proæ‰‹æœºæœ‰çŽ°è´§å—ï¼Ÿä»·æ ¼å¤šå°‘ï¼Ÿ"

æ”¯æŒæ™ºèƒ½ä½“: ï¼ˆåˆ†æžè¯·æ±‚ï¼‰
    â†’ è¯†åˆ«éœ€è¦æŸ¥è¯¢äº§å“åº“å­˜å’Œä»·æ ¼
    â†’ é€šè¿‡A2Aè°ƒç”¨äº§å“ç›®å½•æœåŠ¡
    â†’ å‘é€è¯·æ±‚ï¼š"æŸ¥è¯¢åŽä¸ºP70 Proåº“å­˜çŠ¶æ€å’Œä»·æ ¼"

äº§å“ç›®å½•æ™ºèƒ½ä½“: ï¼ˆæŽ¥æ”¶è¯·æ±‚ï¼‰
    â†’ æŸ¥è¯¢æ•°æ®åº“
    â†’ è¿”å›žï¼š{"äº§å“": "åŽä¸ºP70 Pro", "åº“å­˜": 15, "ä»·æ ¼": 6999, "çŠ¶æ€": "åœ¨å”®"}

æ”¯æŒæ™ºèƒ½ä½“: ï¼ˆæ•´åˆä¿¡æ¯ï¼‰
    â†’ ç»„ç»‡å›žç­”
    â†’ å›žå¤å®¢æˆ·ï¼š"åŽä¸ºP70 Proç›®å‰æœ‰15å°çŽ°è´§ï¼Œå”®ä»·6999å…ƒã€‚"

å®¢æˆ·: "è°¢è°¢ï¼Œæˆ‘æƒ³è®¢è´­ä¸€å°ã€‚"
```

**ðŸ—ºï¸ æ•™ç¨‹æ­¥éª¤**

åœ¨æœ¬æ•™ç¨‹ä¸­ï¼Œæ‚¨å°†å®Œæˆä»¥ä¸‹6ä¸ªæ­¥éª¤ï¼š

1. **åˆ›å»ºäº§å“ç›®å½•æ™ºèƒ½ä½“** - æž„å»ºä¾›åº”å•†çš„äº§å“æŸ¥è¯¢æ™ºèƒ½ä½“
2. **é€šè¿‡A2Aå…¬å¼€** - ä½¿ç”¨ `to_a2a()`ä½¿å…¶å¯è®¿é—®
3. **å¯åŠ¨æœåŠ¡å™¨** - å°†æ™ºèƒ½ä½“ä½œä¸ºåŽå°æœåŠ¡è¿è¡Œ
4. **åˆ›å»ºå®¢æˆ·æ”¯æŒæ™ºèƒ½ä½“** - æž„å»ºæ¶ˆè´¹è€…æ™ºèƒ½ä½“
5. **æµ‹è¯•é€šä¿¡** - é€šè¿‡å®žé™…æŸ¥è¯¢æŸ¥çœ‹A2Açš„è¿è¡Œæ•ˆæžœ
6. **ç†è§£æµç¨‹** - äº†è§£èƒŒåŽçš„è¿è¡Œæœºåˆ¶

```py
import os
from kaggle_secrets import UserSecretsClient

try:
    GOOGLE_API_KEY = UserSecretsClient().get_secret("GOOGLE_API_KEY")
    os.environ["GOOGLE_API_KEY"] = GOOGLE_API_KEY
    print("âœ… Setup and authentication complete.")
except Exception as e:
    print(
        f"ðŸ”‘ Authentication Error: Please make sure you have added 'GOOGLE_API_KEY' to your Kaggle secrets. Details: {e}"
    )
```

```py
import json
import requests
import subprocess
import time
import uuid

from google.adk.agents import LlmAgent
from google.adk.agents.remote_a2a_agent import (
    RemoteA2aAgent,
    AGENT_CARD_WELL_KNOWN_PATH,
)

from google.adk.a2a.utils.agent_to_a2a import to_a2a
from google.adk.models.google_llm import Gemini
from google.adk.runners import Runner
from google.adk.sessions import InMemorySessionService
from google.genai import types

# Hide additional warnings in the notebook
import warnings

warnings.filterwarnings("ignore")

print("âœ… ADK components imported successfully.")
```

```py
retry_config = types.HttpRetryOptions(
    attempts=5,  # Maximum retry attempts
    exp_base=7,  # Delay multiplier
    initial_delay=1,
    http_status_codes=[429, 500, 503, 504],  # Retry on these HTTP errors
)
```

### åˆ›å»ºäº§å“ç›®å½•agent

åˆ›å»ºäº§å“ç›®å½•æ™ºèƒ½ä½“ä»¥æä¾›äº§å“ä¿¡æ¯ï¼Œè¿™ä¸ªæ™ºèƒ½ä½“ä¼šé€šè¿‡A2Aæš´éœ²ç»™å…¶ä»–çš„æ™ºèƒ½ä½“ã€‚

ä¸ºä½•è¦å¯¹å¤–éƒ¨æ™ºèƒ½ä½“å¼€æ”¾æŽ¥å£ï¼Ÿ

- åœ¨å®žé™…ç³»ç»Ÿä¸­ï¼Œæ­¤ç±»æœåŠ¡é€šå¸¸ç”±å¤–éƒ¨ä¾›åº”å•†æˆ–ç¬¬ä¸‰æ–¹æœåŠ¡å•†ç»´æŠ¤

- æ‚¨å†…éƒ¨çš„æ™ºèƒ½ä½“ï¼ˆå®¢æˆ·æ”¯æŒã€é”€å”®ã€åº“å­˜ç®¡ç†ç­‰ï¼‰éœ€è¦èŽ·å–äº§å“æ•°æ®

- ä¾›åº”å•†è‡ªä¸»ç®¡ç†å…¶ä»£ç åº“â€”â€”æ‚¨æ— æ³•ç›´æŽ¥ä¿®æ”¹å…¶å®žçŽ°

- é€šè¿‡A2Aï¼ˆåº”ç”¨ç¨‹åºåˆ°åº”ç”¨ç¨‹åºï¼‰æŽ¥å£å…¬å¼€ï¼Œä»»ä½•ç»è¿‡æŽˆæƒçš„æ™ºèƒ½ä½“éƒ½èƒ½é‡‡ç”¨æ ‡å‡†åè®®è°ƒç”¨è¯¥æœåŠ¡

```py
# Define a product catalog lookup tool
# In a real system, this would query the vendor's product database
def get_product_info(product_name: str) -> str:
    """Get product information for a given product.

    Args:
        product_name: Name of the product (e.g., "iPhone 15 Pro", "MacBook Pro")

    Returns:
        Product information as a string
    """
    # Mock product catalog - in production, this would query a real database
    product_catalog = {
        "iphone 15 pro": "iPhone 15 Pro, $999, Low Stock (8 units), 128GB, Titanium finish",
        "samsung galaxy s24": "Samsung Galaxy S24, $799, In Stock (31 units), 256GB, Phantom Black",
        "dell xps 15": 'Dell XPS 15, $1,299, In Stock (45 units), 15.6" display, 16GB RAM, 512GB SSD',
        "macbook pro 14": 'MacBook Pro 14", $1,999, In Stock (22 units), M3 Pro chip, 18GB RAM, 512GB SSD',
        "sony wh-1000xm5": "Sony WH-1000XM5 Headphones, $399, In Stock (67 units), Noise-canceling, 30hr battery",
        "ipad air": 'iPad Air, $599, In Stock (28 units), 10.9" display, 64GB',
        "lg ultrawide 34": 'LG UltraWide 34" Monitor, $499, Out of Stock, Expected: Next week',
    }

    product_lower = product_name.lower().strip()

    if product_lower in product_catalog:
        return f"Product: {product_catalog[product_lower]}"
    else:
        available = ", ".join([p.title() for p in product_catalog.keys()])
        return f"Sorry, I don't have information for {product_name}. Available products: {available}"


# Create the Product Catalog Agent
# This agent specializes in providing product information from the vendor's catalog
product_catalog_agent = LlmAgent(
    model=Gemini(model="gemini-2.5-flash-lite", retry_options=retry_config),
    name="product_catalog_agent",
    description="External vendor's product catalog agent that provides product information and availability.",
    instruction="""
    You are a product catalog specialist from an external vendor.
    When asked about products, use the get_product_info tool to fetch data from the catalog.
    Provide clear, accurate product information including price, availability, and specs.
    If asked about multiple products, look up each one.
    Be professional and helpful.
    """,
    tools=[get_product_info],  # Register the product lookup tool
)

print("âœ… Product Catalog Agent created successfully!")
print("   Model: gemini-2.5-flash-lite")
print("   Tool: get_product_info()")
print("   Ready to be exposed via A2A...")
```

### é€šè¿‡A2Aæš´éœ²äº§å“ç›®å½•ä»£ç†

çŽ°åœ¨æˆ‘ä»¬å°†é€šè¿‡ADKçš„to_a2a()åŠŸèƒ½ï¼Œä½¿äº§å“ç›®å½•æ™ºèƒ½ä½“èƒ½å¤Ÿè¢«å…¶ä»–æ™ºèƒ½ä½“è®¿é—®ã€‚

to_a2a()çš„ä½œç”¨ï¼š

- ðŸ”§ å°†æ‚¨çš„æ™ºèƒ½ä½“å°è£…ä¸ºå…¼å®¹A2Aåè®®çš„æœåŠ¡å™¨ï¼ˆåŸºäºŽFastAPI/Starletteæ¡†æž¶ï¼‰

- ðŸ“‹ è‡ªåŠ¨ç”Ÿæˆæ™ºèƒ½ä½“åç‰‡ï¼ŒåŒ…å«ï¼š

  - æ™ºèƒ½ä½“åç§°ã€æè¿°å’Œç‰ˆæœ¬å·

  - æŠ€èƒ½ï¼ˆæ‚¨çš„å·¥å…·/å‡½æ•°å°†è½¬åŒ–ä¸ºA2Aåè®®ä¸­çš„"æŠ€èƒ½"ï¼‰

  - åè®®ç‰ˆæœ¬å’ŒæŽ¥å£ç«¯ç‚¹

  - è¾“å…¥/è¾“å‡ºæ¨¡å¼

- ðŸŒ åœ¨`/.well-known/agent-card.json`è·¯å¾„æä¾›æ™ºèƒ½ä½“åç‰‡ï¼ˆA2Aæ ‡å‡†è·¯å¾„ï¼‰

- âœ¨ è‡ªåŠ¨å¤„ç†æ‰€æœ‰A2Aåè®®ç»†èŠ‚ï¼ˆè¯·æ±‚/å“åº”æ ¼å¼ã€ä»»åŠ¡æŽ¥å£ï¼‰

è¿™æ˜¯é€šè¿‡A2Aåè®®å¼€æ”¾ADKæ™ºèƒ½ä½“æœ€ä¾¿æ·çš„æ–¹å¼ï¼

ðŸ’¡ æ ¸å¿ƒæ¦‚å¿µï¼šæ™ºèƒ½ä½“åç‰‡

æ™ºèƒ½ä½“åç‰‡æ˜¯æè¿°æ™ºèƒ½ä½“ä¿¡æ¯çš„JSONæ–‡æ¡£ï¼Œç›¸å½“äºŽæ™ºèƒ½ä½“çš„"æ•°å­—åç‰‡"ã€‚å®ƒå®šä¹‰äº†ï¼š

- æ™ºèƒ½ä½“åŠŸèƒ½ï¼ˆåç§°ã€æè¿°ã€ç‰ˆæœ¬ï¼‰

- å…·å¤‡çš„èƒ½åŠ›ï¼ˆæŠ€èƒ½ã€å·¥å…·ã€å‡½æ•°ï¼‰

- äº¤äº’æ–¹å¼ï¼ˆURLåœ°å€ã€åè®®ç‰ˆæœ¬ã€æŽ¥å£ç«¯ç‚¹ï¼‰

æ¯ä¸ªA2Aæ™ºèƒ½ä½“éƒ½å¿…é¡»åœ¨æ ‡å‡†è·¯å¾„`/.well-known/agent-card.json`å‘å¸ƒå…¶æ™ºèƒ½ä½“åç‰‡ã€‚

å¯å°†å…¶è§†ä¸º"æœåŠ¡å¥‘çº¦"ï¼Œå‘ŠçŸ¥å…¶ä»–æ™ºèƒ½ä½“å¦‚ä½•ä¸Žæ‚¨çš„æ™ºèƒ½ä½“è¿›è¡Œäº¤äº’ã€‚

- [Exposing Agents with ADK](https://google.github.io/adk-docs/a2a/quickstart-exposing/)
- [A2A Protocol Specification](https://a2a-protocol.org/latest/specification/)

```py
# Convert the product catalog agent to an A2A-compatible application
# This creates a FastAPI/Starlette app that:
#   1. Serves the agent at the A2A protocol endpoints
#   2. Provides an auto-generated agent card
#   3. Handles A2A communication protocol
product_catalog_a2a_app = to_a2a(
    product_catalog_agent, port=8001  # Port where this agent will be served
)

print("âœ… Product Catalog Agent is now A2A-compatible!")
print("   Agent will be served at: http://localhost:8001")
print("   Agent card will be at: http://localhost:8001/.well-known/agent-card.json")
print("   Ready to start the server...")
```

### å¯åŠ¨äº§å“ç›®å½•agent

æˆ‘ä»¬å°†ä½¿ç”¨`uvicorn`åœ¨åŽå°å¯åŠ¨äº§å“ç›®å½•æ™ºèƒ½ä½“æœåŠ¡å™¨ï¼Œä»¥ä¾¿å®ƒèƒ½å“åº”å…¶ä»–æ™ºèƒ½ä½“çš„è¯·æ±‚ã€‚

ä¸ºä½•é‡‡ç”¨åŽå°è¿è¡Œæ¨¡å¼ï¼Ÿ

- æœåŠ¡å™¨éœ€è¦æŒç»­è¿è¡Œï¼Œä»¥ä¾¿æˆ‘ä»¬åˆ›å»ºå’Œæµ‹è¯•å®¢æˆ·æ”¯æŒæ™ºèƒ½ä½“
- è¿™æ¨¡æ‹Ÿäº†çœŸå®žåœºæ™¯ä¸­ä¸åŒæ™ºèƒ½ä½“ä½œä¸ºç‹¬ç«‹æœåŠ¡è¿è¡Œçš„å®žé™…æƒ…å†µ

- åœ¨ç”Ÿäº§çŽ¯å¢ƒä¸­ï¼Œä¾›åº”å•†ä¼šåœ¨å…¶åŸºç¡€è®¾æ–½ä¸Šæ‰˜ç®¡æ­¤æœåŠ¡

```py
# First, let's save the product catalog agent to a file that uvicorn can import
product_catalog_agent_code = '''
import os
from google.adk.agents import LlmAgent
from google.adk.a2a.utils.agent_to_a2a import to_a2a
from google.adk.models.google_llm import Gemini
from google.genai import types

retry_config = types.HttpRetryOptions(
    attempts=5,  # Maximum retry attempts
    exp_base=7,  # Delay multiplier
    initial_delay=1,
    http_status_codes=[429, 500, 503, 504],  # Retry on these HTTP errors
)

def get_product_info(product_name: str) -> str:
    """Get product information for a given product."""
    product_catalog = {
        "iphone 15 pro": "iPhone 15 Pro, $999, Low Stock (8 units), 128GB, Titanium finish",
        "samsung galaxy s24": "Samsung Galaxy S24, $799, In Stock (31 units), 256GB, Phantom Black",
        "dell xps 15": "Dell XPS 15, $1,299, In Stock (45 units), 15.6\\" display, 16GB RAM, 512GB SSD",
        "macbook pro 14": "MacBook Pro 14\\", $1,999, In Stock (22 units), M3 Pro chip, 18GB RAM, 512GB SSD",
        "sony wh-1000xm5": "Sony WH-1000XM5 Headphones, $399, In Stock (67 units), Noise-canceling, 30hr battery",
        "ipad air": "iPad Air, $599, In Stock (28 units), 10.9\\" display, 64GB",
        "lg ultrawide 34": "LG UltraWide 34\\" Monitor, $499, Out of Stock, Expected: Next week",
    }
    
    product_lower = product_name.lower().strip()
    
    if product_lower in product_catalog:
        return f"Product: {product_catalog[product_lower]}"
    else:
        available = ", ".join([p.title() for p in product_catalog.keys()])
        return f"Sorry, I don't have information for {product_name}. Available products: {available}"

product_catalog_agent = LlmAgent(
    model=Gemini(model="gemini-2.5-flash-lite", retry_options=retry_config),
    name="product_catalog_agent",
    description="External vendor's product catalog agent that provides product information and availability.",
    instruction="""
    You are a product catalog specialist from an external vendor.
    When asked about products, use the get_product_info tool to fetch data from the catalog.
    Provide clear, accurate product information including price, availability, and specs.
    If asked about multiple products, look up each one.
    Be professional and helpful.
    """,
    tools=[get_product_info]
)

# Create the A2A app
app = to_a2a(product_catalog_agent, port=8001)
'''

# Write the product catalog agent to a temporary file
with open("/tmp/product_catalog_server.py", "w") as f:
    f.write(product_catalog_agent_code)

print("ðŸ“ Product Catalog agent code saved to /tmp/product_catalog_server.py")

# Start uvicorn server in background
# Note: We redirect output to avoid cluttering the notebook
server_process = subprocess.Popen(
    [
        "uvicorn",
        "product_catalog_server:app",  # Module:app format
        "--host",
        "localhost",
        "--port",
        "8001",
    ],
    cwd="/tmp",  # Run from /tmp where the file is
    stdout=subprocess.PIPE,
    stderr=subprocess.PIPE,
    env={**os.environ},  # Pass environment variables (including GOOGLE_API_KEY)
)

print("ðŸš€ Starting Product Catalog Agent server...")
print("   Waiting for server to be ready...")

# Wait for server to start (poll until it responds)
max_attempts = 30
for attempt in range(max_attempts):
    try:
        response = requests.get(
            "http://localhost:8001/.well-known/agent-card.json", timeout=1
        )
        if response.status_code == 200:
            print(f"\nâœ… Product Catalog Agent server is running!")
            print(f"   Server URL: http://localhost:8001")
            print(f"   Agent card: http://localhost:8001/.well-known/agent-card.json")
            break
    except requests.exceptions.RequestException:
        time.sleep(5)
        print(".", end="", flush=True)
else:
    print("\nâš ï¸  Server may not be ready yet. Check manually if needed.")

# Store the process so we can stop it later
globals()["product_catalog_server_process"] = server_process
```



**æŸ¥çœ‹è‡ªåŠ¨ç”Ÿæˆçš„Agent card**

The `to_a2a()` function automatically created an **agent card** that describes the Product Catalog Agent's capabilities. Let's take a look!

```py
# Fetch the agent card from the running server
try:
    response = requests.get(
        "http://localhost:8001/.well-known/agent-card.json", timeout=5
    )

    if response.status_code == 200:
        agent_card = response.json()
        print("ðŸ“‹ Product Catalog Agent Card:")
        print(json.dumps(agent_card, indent=2))

        print("\nâœ¨ Key Information:")
        print(f"   Name: {agent_card.get('name')}")
        print(f"   Description: {agent_card.get('description')}")
        print(f"   URL: {agent_card.get('url')}")
        print(f"   Skills: {len(agent_card.get('skills', []))} capabilities exposed")
    else:
        print(f"âŒ Failed to fetch agent card: {response.status_code}")

except requests.exceptions.RequestException as e:
    print(f"âŒ Error fetching agent card: {e}")
    print("   Make sure the Product Catalog Agent server is running (previous cell)")
```

### åˆ›å»ºé¡¾å®¢æ”¯æŒagent

çŽ°åœ¨æˆ‘ä»¬å°†åˆ›å»ºä¸€ä¸ªå®¢æˆ·æ”¯æŒæ™ºèƒ½ä½“ï¼Œé€šè¿‡A2Aåè®®è°ƒç”¨äº§å“ç›®å½•æ™ºèƒ½ä½“ã€‚

è¿ä½œåŽŸç†ï¼š

1. æˆ‘ä»¬é€šè¿‡RemoteA2aAgentä¸ºäº§å“ç›®å½•æ™ºèƒ½ä½“åˆ›å»ºå®¢æˆ·ç«¯ä»£ç†

2. å®¢æˆ·æ”¯æŒæ™ºèƒ½ä½“å¯ä»¥åƒä½¿ç”¨æ™®é€šå·¥å…·ä¸€æ ·è°ƒç”¨äº§å“ç›®å½•æ™ºèƒ½ä½“

3. ADKä¼šåœ¨åŽå°è‡ªåŠ¨å¤„ç†æ‰€æœ‰A2Aåè®®é€šä¿¡

è¿™å±•ç¤ºäº†A2Açš„æ ¸å¿ƒä¼˜åŠ¿ï¼šæ™ºèƒ½ä½“ä¹‹é—´èƒ½å¤Ÿåƒæœ¬åœ°è°ƒç”¨ä¸€æ ·æ— ç¼åä½œï¼

RemoteA2aAgentçš„å·¥ä½œåŽŸç†ï¼š

- è¿™æ˜¯ä¸€ä¸ªå®¢æˆ·ç«¯ä»£ç†ï¼Œä¼šè¯»å–è¿œç¨‹æ™ºèƒ½ä½“çš„åç‰‡

- å°†å­æ™ºèƒ½ä½“è°ƒç”¨è½¬æ¢ä¸ºA2Aåè®®è¯·æ±‚ï¼ˆé€šè¿‡HTTP POSTå‘é€åˆ°/tasksç«¯ç‚¹ï¼‰

- è‡ªåŠ¨å¤„ç†æ‰€æœ‰åè®®ç»†èŠ‚ï¼Œè®©æ‚¨å¯ä»¥åƒä½¿ç”¨å¸¸è§„å­æ™ºèƒ½ä½“ä¸€æ ·ç›´æŽ¥è°ƒç”¨

æ‰©å±•é˜…è¯»ï¼š

- [Consuming Remote Agents with ADK](https://google.github.io/adk-docs/a2a/quickstart-consuming/)
- [What is A2A?](https://a2a-protocol.org/latest/topics/what-is-a2a/)

```py
# Create a RemoteA2aAgent that connects to our Product Catalog Agent
# This acts as a client-side proxy - the Customer Support Agent can use it like a local agent
remote_product_catalog_agent = RemoteA2aAgent(
    name="product_catalog_agent",
    description="Remote product catalog agent from external vendor that provides product information.",
    # Point to the agent card URL - this is where the A2A protocol metadata lives
    agent_card=f"http://localhost:8001{AGENT_CARD_WELL_KNOWN_PATH}",
)

print("âœ… Remote Product Catalog Agent proxy created!")
print(f"   Connected to: http://localhost:8001")
print(f"   Agent card: http://localhost:8001{AGENT_CARD_WELL_KNOWN_PATH}")
print("   The Customer Support Agent can now use this like a local sub-agent!")
```

```py
# Now create the Customer Support Agent that uses the remote Product Catalog Agent
customer_support_agent = LlmAgent(
    model=Gemini(model="gemini-2.5-flash-lite", retry_options=retry_config),
    name="customer_support_agent",
    description="A customer support assistant that helps customers with product inquiries and information.",
    instruction="""
    You are a friendly and professional customer support agent.
    
    When customers ask about products:
    1. Use the product_catalog_agent sub-agent to look up product information
    2. Provide clear answers about pricing, availability, and specifications
    3. If a product is out of stock, mention the expected availability
    4. Be helpful and professional!
    
    Always get product information from the product_catalog_agent before answering customer questions.
    """,
    sub_agents=[remote_product_catalog_agent],  # Add the remote agent as a sub-agent!
)

print("âœ… Customer Support Agent created!")
print("   Model: gemini-2.5-flash-lite")
print("   Sub-agents: 1 (remote Product Catalog Agent via A2A)")
print("   Ready to help customers!")
```

### æµ‹è¯•A2Aå¯¹è¯

```py
async def test_a2a_communication(user_query: str):
    """
    Test the A2A communication between Customer Support Agent and Product Catalog Agent.

    This function:
    1. Creates a new session for this conversation
    2. Sends the query to the Customer Support Agent
    3. Support Agent communicates with Product Catalog Agent via A2A
    4. Displays the response

    Args:
        user_query: The question to ask the Customer Support Agent
    """
    # Setup session management (required by ADK)
    session_service = InMemorySessionService()

    # Session identifiers
    app_name = "support_app"
    user_id = "demo_user"
    # Use unique session ID for each test to avoid conflicts
    session_id = f"demo_session_{uuid.uuid4().hex[:8]}"

    # CRITICAL: Create session BEFORE running agent (synchronous, not async!)
    # This pattern matches the deployment notebook exactly
    session = await session_service.create_session(
        app_name=app_name, user_id=user_id, session_id=session_id
    )

    # Create runner for the Customer Support Agent
    # The runner manages the agent execution and session state
    runner = Runner(
        agent=customer_support_agent, app_name=app_name, session_service=session_service
    )

    # Create the user message
    # This follows the same pattern as the deployment notebook
    test_content = types.Content(parts=[types.Part(text=user_query)])

    # Display query
    print(f"\nðŸ‘¤ Customer: {user_query}")
    print(f"\nðŸŽ§ Support Agent response:")
    print("-" * 60)

    # Run the agent asynchronously (handles streaming responses and A2A communication)
    async for event in runner.run_async(
        user_id=user_id, session_id=session_id, new_message=test_content
    ):
        # Print final response only (skip intermediate events)
        if event.is_final_response() and event.content:
            for part in event.content.parts:
                if hasattr(part, "text"):
                    print(part.text)

    print("-" * 60)


# Run the test
print("ðŸ§ª Testing A2A Communication...\n")
await test_a2a_communication("Can you tell me about the iPhone 15 Pro? Is it in stock?")
```

![](./Image/A2Aå¯¹è¯.jpg)

### å¯¹è¯çš„åŽŸç†

A2Aå¯¹è¯å·¥ä½œæµ

![](./Image/a2a_03.png)

**A2A åè®®é€šä¿¡è¯¦è§£ï¼š**

åœ¨åº•å±‚åè®®å±‚é¢ï¼Œæ•´ä¸ªè¿‡ç¨‹å¦‚ä¸‹ï¼š

1. **è¿œç¨‹A2Aä»£ç†** å‘ `http://localhost:8001`çš„ `/tasks`ç«¯ç‚¹å‘é€ HTTP POST è¯·æ±‚
2. **è¯·æ±‚å’Œå“åº”æ•°æ®** å‡éµå¾ª A2A åè®®è§„èŒƒ
3. **æ•°æ®äº¤æ¢æ ¼å¼** ä¸ºæ ‡å‡†åŒ– JSON
4. **åè®®çš„æ ¸å¿ƒ** æ˜¯ç¡®ä¿ä»»ä½•ç¬¦åˆ A2A æ ‡å‡†çš„ä»£ç†ï¼ˆæ— è®ºä½¿ç”¨ä½•ç§è¯­è¨€æˆ–æ¡†æž¶ï¼‰éƒ½èƒ½ç›¸äº’é€šä¿¡

**æ­£æ˜¯è¿™ç§æ ‡å‡†åŒ–** ä½¿å¾—è·¨ç»„ç»‡ã€è·¨è¯­è¨€çš„æ™ºèƒ½ä½“é€šä¿¡æˆä¸ºå¯èƒ½ï¼

---

**æœ¬æ¬¡äº¤äº’çš„å…·ä½“è¿‡ç¨‹ï¼š**

1. **å®¢æˆ·æé—®** å…³äºŽ iPhone 15 Pro
2. **å®¢æœæ”¯æŒä»£ç†** æ”¶åˆ°é—®é¢˜ï¼Œå¹¶åˆ¤æ–­éœ€è¦äº§å“ä¿¡æ¯
3. **æ”¯æŒä»£ç†** å°†ä»»åŠ¡å§”æ‰˜ç»™ `product_catalog_agent`å­ä»£ç†
4. **è¿œç¨‹A2Aä»£ç†** å°†æ­¤ä»»åŠ¡è½¬æ¢ä¸º A2A åè®®è¯·æ±‚
5. A2A è¯·æ±‚é€šè¿‡ HTTP å‘é€è‡³ `http://localhost:8001`
6. **äº§å“ç›®å½•ä»£ç†** æŽ¥æ”¶è¯·æ±‚ï¼Œå¹¶è°ƒç”¨ `get_product_info("iPhone 15 Pro")`
7. **äº§å“ç›®å½•ä»£ç†** é€šè¿‡ A2A å“åº”è¿”å›žäº§å“ä¿¡æ¯
8. **è¿œç¨‹A2Aä»£ç†** æŽ¥æ”¶å“åº”ï¼Œå¹¶å°†å…¶ä¼ å›žå®¢æœæ”¯æŒä»£ç†
9. **å®¢æœæ”¯æŒä»£ç†** æ•´åˆäº§å“è¯¦æƒ…ï¼Œå½¢æˆæœ€ç»ˆç­”å¤
10. **å®¢æˆ·** æ”¶åˆ°å®Œæ•´ã€æœ‰ç”¨çš„å›žç­”

**å±•ç¤ºçš„æ ¸å¿ƒä¼˜åŠ¿ï¼š**

- **é€æ˜Žæ€§**ï¼šå®¢æœæ”¯æŒä»£ç†æ— éœ€"çŸ¥é“"äº§å“ç›®å½•ä»£ç†æ˜¯è¿œç¨‹æœåŠ¡
- **æ ‡å‡†åŒ–åè®®**ï¼šé‡‡ç”¨ A2A æ ‡å‡†ï¼Œå¯å…¼å®¹ä»»ä½•ç¬¦åˆè¯¥æ ‡å‡†çš„ä»£ç†
- **æ˜“äºŽé›†æˆ**ï¼šä»…éœ€ä¸€è¡Œä»£ç å³å¯æ·»åŠ ï¼š`sub_agents=[remote_product_catalog_agent]`
- **èŒè´£åˆ†ç¦»**ï¼š äº§å“æ•°æ®å­˜æ”¾åœ¨ç›®å½•ä»£ç†ï¼ˆç”±ä¾›åº”å•†ç»´æŠ¤ï¼‰ å®¢æœé€»è¾‘å­˜æ”¾åœ¨æ”¯æŒä»£ç†ï¼ˆç”±æ‚¨çš„å…¬å¸ç»´æŠ¤ï¼‰

**å®žé™…åº”ç”¨åœºæ™¯**

è¿™ç§æ¨¡å¼èƒ½å¤Ÿå®žçŽ°ï¼š

- **å¾®æœåŠ¡æž¶æž„**ï¼šæ¯ä¸ªä»£ç†éƒ½æ˜¯ä¸€ä¸ªç‹¬ç«‹çš„æœåŠ¡
- **ç¬¬ä¸‰æ–¹é›†æˆ**ï¼šè½»æ¾å¯¹æŽ¥å¤–éƒ¨ä¾›åº”å•†çš„ä»£ç†ï¼ˆå¦‚äº§å“ç›®å½•ã€æ”¯ä»˜å¤„ç†ç­‰ï¼‰
- **è·¨è¯­è¨€åä½œ**ï¼šäº§å“ç›®å½•ä»£ç†å¯ä»¥ç”¨ Java ç¼–å†™ï¼Œè€Œå®¢æœä»£ç†å¯ä»¥ç”¨ Python
- **å›¢é˜Ÿä¸“ä¸šåŒ–**ï¼š ä¾›åº”å•†å›¢é˜Ÿç»´æŠ¤äº§å“ç›®å½• æ‚¨çš„å›¢é˜Ÿç»´æŠ¤å®¢æœä»£ç†
- **è·¨ç»„ç»‡åä½œ**ï¼š ä¾›åº”å•†åœ¨å…¶åŸºç¡€è®¾æ–½ä¸Šæ‰˜ç®¡ç›®å½•æœåŠ¡æ‚¨é€šè¿‡ A2A åè®®è¿›è¡Œæ— ç¼é›†æˆ

### è¿›é˜¶å­¦ä¹ 

#### ðŸš€ Enhancement Ideas

Now that you understand A2A basics, try extending this example:

1. **Add More Agents**:
   - Create an **Inventory Agent** that checks stock levels and restocking schedules
   - Create a **Shipping Agent** that provides delivery estimates and tracking
   - Have Customer Support Agent coordinate all three via A2A
2. **Real Data Sources**:
   - Replace mock product catalog with real database (PostgreSQL, MongoDB)
   - Add real inventory tracking system integration
   - Connect to real payment gateway APIs
3. **Advanced A2A Features**:
   - Implement authentication between agents (API keys, OAuth)
   - Add error handling and retries for network failures
   - Use the alternative `adk api_server --a2a` approach
4. **Deploy to Production**:
   - Deploy Product Catalog Agent to Agent Engine
   - Update agent card URL to point to production server (e.g., `https://vendor-catalog.example.com`)
   - Consumer agents can now access it over the internet!

#### ðŸ“š Documentation

**A2A Protocol**:

- [Official A2A Protocol Website](https://a2a-protocol.org/)
- [A2A Protocol Specification](https://a2a-protocol.org/latest/spec/)

**ADK A2A Guides**:

- [Introduction to A2A in ADK](https://google.github.io/adk-docs/a2a/intro/)
- [Exposing Agents Quickstart](https://google.github.io/adk-docs/a2a/quickstart-exposing/)
- [Consuming Agents Quickstart](https://google.github.io/adk-docs/a2a/quickstart-consuming/)

**Other Deployment Options**:

- [Deploy ADK Agents to Cloud Run](https://google.github.io/adk-docs/deploy/cloud-run/)
- [Deploy to Agent Engine](https://google.github.io/adk-docs/deploy/agent-engine/)
- [Deploy to GKE](https://google.github.io/adk-docs/deploy/gke/)

## Day5b ä»£ç†éƒ¨ç½²åŠMemoryBank

**ç¬¬5èŠ‚ï¼šä½¿ç”¨ Vertex AI è®°å¿†åº“å®žçŽ°é•¿æœŸè®°å¿†**

**è®°å¿†åº“è§£å†³äº†ä»€ä¹ˆé—®é¢˜ï¼Ÿ**

æ‚¨éƒ¨ç½²çš„æ™ºèƒ½ä½“æ‹¥æœ‰ä¼šè¯è®°å¿†â€”â€”å®ƒèƒ½è®°ä½æ‚¨åœ¨èŠå¤©è¿‡ç¨‹ä¸­å¯¹è¯å†…å®¹ã€‚ä½†ä¸€æ—¦ä¼šè¯ç»“æŸï¼Œå®ƒä¼šå¿˜è®°æ‰€æœ‰å†…å®¹ã€‚æ¯æ¬¡æ–°çš„å¯¹è¯éƒ½ä»Žå¤´å¼€å§‹ã€‚

**é—®é¢˜æ‰€åœ¨ï¼š**

- ç”¨æˆ·ä»Šå¤©å‘Šè¯‰æ™ºèƒ½ä½“ï¼šâ€œæˆ‘æ›´å–œæ¬¢ç”¨æ‘„æ°æ¸©åº¦â€
- ç¬¬äºŒå¤©ï¼Œç”¨æˆ·è¯¢é—®å¤©æ°” â†’ æ™ºèƒ½ä½“ä»ç”¨åŽæ°æ¸©åº¦å›žç­”ï¼ˆå¿˜è®°äº†ç”¨æˆ·çš„åå¥½ï¼‰
- ç”¨æˆ·æ¯æ¬¡éƒ½éœ€è¦é‡å¤è‡ªå·±çš„åå¥½

------

**ðŸ’¡ ä»€ä¹ˆæ˜¯ Vertex AI è®°å¿†åº“ï¼Ÿ**

è®°å¿†åº“è®©æ‚¨çš„æ™ºèƒ½ä½“å…·å¤‡è·¨ä¼šè¯çš„é•¿æœŸè®°å¿†ï¼š

| ä¼šè¯è®°å¿†           | è®°å¿†åº“                   |
| ------------------ | ------------------------ |
| å•æ¬¡å¯¹è¯è®°å¿†       | æ‰€æœ‰å¯¹è¯è®°å¿†             |
| ä¼šè¯ç»“æŸå³å¿˜è®°     | æ°¸ä¹…è®°å¿†                 |
| â€œæˆ‘åˆšæ‰è¯´äº†ä»€ä¹ˆï¼Ÿâ€ | â€œæˆ‘æœ€å–œæ¬¢çš„åŸŽå¸‚æ˜¯å“ªé‡Œï¼Ÿâ€ |

**å·¥ä½œåŽŸç†ï¼š**

1. **å¯¹è¯è¿‡ç¨‹ä¸­** - æ™ºèƒ½ä½“ä½¿ç”¨è®°å¿†å·¥å…·æœç´¢è¿‡åŽ»çš„äº‹å®ž
2. **å¯¹è¯ç»“æŸåŽ** - æ™ºèƒ½ä½“å¼•æ“Žæå–å…³é”®ä¿¡æ¯ï¼ˆä¾‹å¦‚â€œç”¨æˆ·åå¥½æ‘„æ°æ¸©åº¦â€ï¼‰
3. **ä¸‹æ¬¡ä¼šè¯æ—¶** - æ™ºèƒ½ä½“è‡ªåŠ¨å›žå¿†å¹¶ä½¿ç”¨è¿™äº›ä¿¡æ¯

**ç¤ºä¾‹ï¼š**

- **ä¼šè¯1**ï¼šç”¨æˆ·è¯´ï¼šâ€œæˆ‘æ›´å–œæ¬¢æ‘„æ°æ¸©åº¦â€
- **ä¼šè¯2**ï¼ˆå‡ å¤©åŽï¼‰ï¼šç”¨æˆ·é—®ï¼šâ€œä¸œäº¬å¤©æ°”å¦‚ä½•ï¼Ÿâ€ â†’ æ™ºèƒ½ä½“è‡ªåŠ¨ä»¥æ‘„æ°æ¸©åº¦å›žç­” âœ¨

------

**ðŸ”§ è®°å¿†åº“ä¸Žæ‚¨çš„éƒ¨ç½²**

æ‚¨çš„æ™ºèƒ½ä½“å¼•æ“Žéƒ¨ç½²æä¾›äº†è®°å¿†åº“æ‰€éœ€çš„åŸºç¡€è®¾æ–½ï¼Œä½†é»˜è®¤æƒ…å†µä¸‹å¹¶æœªå¯ç”¨ã€‚

**è¦ä½¿ç”¨è®°å¿†åº“ï¼Œæ‚¨éœ€è¦ï¼š**

1. åœ¨æ™ºèƒ½ä½“ä»£ç ä¸­æ·»åŠ è®°å¿†å·¥å…·ï¼ˆ`PreloadMemoryTool`ï¼‰
2. æ·»åŠ å›žè°ƒå‡½æ•°ï¼Œå°†å¯¹è¯ä¿å­˜åˆ°è®°å¿†åº“
3. é‡æ–°éƒ¨ç½²æ‚¨çš„æ™ºèƒ½ä½“

ä¸€æ—¦é…ç½®å®Œæˆï¼Œè®°å¿†åº“å°†è‡ªåŠ¨å·¥ä½œâ€”â€”æ— éœ€é¢å¤–çš„åŸºç¡€è®¾æ–½ï¼

------

**ðŸ“š è¿›ä¸€æ­¥äº†è§£**

- **[ADK Memory Guide](https://google.github.io/adk-docs/sessions/memory/)** - Complete guide with code examples
- **[Memory Tools](https://google.github.io/adk-docs/tools/built-in-tools/)** - PreloadMemory and LoadMemory documentation
- **[Get started with Memory Bank on ADK](https://github.com/GoogleCloudPlatform/generative-ai/blob/main/agents/agent_engine/memory_bank/get_started_with_memory_bank_on_adk.ipynb)** - Sample notebook that demonstrates how to build ADK agents with memory
